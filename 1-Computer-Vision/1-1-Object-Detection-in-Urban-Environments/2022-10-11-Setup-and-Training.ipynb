{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1.1: Object Detection in Urban Environments\n",
    "## Model Setup and Training\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip uninstall -y protobuf\n",
    "!sudo pip uninstall -y google\n",
    "!sudo pip install google\n",
    "!sudo pip install protobuf\n",
    "!sudo pip install google-cloud\n",
    "!pip install ray\n",
    "!pip install omegaconf\n",
    "!pip install hydra-core\n",
    "!pip install packaging\n",
    "!pip install importlib-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install waymo-open-dataset-tf-2-3-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emaXw1WU7yi4"
   },
   "outputs": [],
   "source": [
    "### Importing the required modules\n",
    "# Doing this here to test installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ef1oC32J7ydQ"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import google.protobuf\n",
    "import hydra\n",
    "import numpy as np\n",
    "import os\n",
    "import ray\n",
    "import sys\n",
    "from tensorboard import notebook\n",
    "import tensorflow as tf\n",
    "import waymo_open_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "ZwVscjHKRHMJ",
    "outputId": "a159ed0d-2a31-4da4-c8fe-425a0fa399a6"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "2-zlG-v8UMN_",
    "outputId": "51800c7c-bf7b-40aa-d042-6ae6e1a5a4b5"
   },
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4lcBVzY7gjR"
   },
   "outputs": [],
   "source": [
    "### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8EYVzwH7p58"
   },
   "outputs": [],
   "source": [
    "ENV_COLAB = False               # True if running in Google Colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxl6nJIX7p1o"
   },
   "outputs": [],
   "source": [
    "# Root directory\n",
    "DIR_BASE = '' if not ENV_COLAB else '/content/1-1-Object-Detection-in-Urban-Environments'\n",
    "DIR_BASE = os.path.abspath(DIR_BASE)\n",
    "DIR_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5wue9dL7pwk"
   },
   "outputs": [],
   "source": [
    "# Subdirectory to save output files\n",
    "DIR_OUT = os.path.join(DIR_BASE, 'out')\n",
    "# Subdirectory pointing to input data\n",
    "DIR_SRC = os.path.join(DIR_BASE, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bR_S9A3m765m"
   },
   "outputs": [],
   "source": [
    "### Creating subdirectories (if not exists)\n",
    "os.makedirs(DIR_SRC, exist_ok=True)\n",
    "os.makedirs(DIR_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-pE_CxiMYXi"
   },
   "outputs": [],
   "source": [
    "# Subdirectory to model folder\n",
    "DIR_MODEL = os.path.join(DIR_BASE, 'experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUPEotHEkjE3"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension (if using Colab)\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Downloading the Google Cloud CLI (if folder doesn't already exist)\n",
    "if not os.path.exists(os.path.join(DIR_BASE, 'addons/google-cloud-sdk')):\n",
    "    # Download Cloud CLI tools from Google\n",
    "    !curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-405.0.0-linux-x86_64.tar.gz\n",
    "    # Unzip to addons folder\n",
    "    !tar -xf google-cloud-cli-405.0.0-linux-x86_64.tar.gz -C addons/\n",
    "### Setting up Google Cloud CLI tools (run commands inside interactive shell)\n",
    "# ./addons/google-cloud-sdk/install.sh\n",
    "# ./gcloud init\n",
    "### Authenticate the service account\n",
    "# ./gcloud auth activate-service-account [service-email] --key-file\"[path/to/key-file]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sweeping the working directory for Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --editable {DIR_BASE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Setup and Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook we will be fetching the Waymo Open Dataset files from their Google Cloud Storage bucket locations. To view the file paths we will be downloading, see `filenames.txt` inside the `data/waymo_open_dataset` folder.\n",
    "\n",
    "\n",
    "#### Environment setup\n",
    "The Python files inside `/scripts/..` have been modified to work on the Linux Ubuntu VM provided in the Udacity workspace. Please see previous commits of this repository to obtain script files suited for macOS and Google Colab. As of now, the Ubuntu VM is running Python version 3.7.3, TensorFlow 2.3.0 and Waymo Open Dataset version `tf-2-3-0==1.4.0`. The other dependency versions should be checked for conflicts on any other machine.\n",
    "\n",
    "Running the `!pip install --editable setup.py` command will add all modules from this project repository onto the Python path. This is the recommended way to resolve `PYTHONPATH` issues, preferred to updating the `/.bashrc` file or `os.environ['PYTHONPATH']`/`sys.path` variables.\n",
    "\n",
    "#### Data acquisition\n",
    "\n",
    "The `download_process.py` script will fetch the `.tfrecord` files from GCS and store them locally in the `data/waymo_open_dataset/raw` subdirectory to be processed. The raw `.tfrecord` files are parsed in `process_tfr`; the images, bounding box labels and attribute data are stored in a dictionary-like object and converted to `tf.data.TFRecordDataset` instances. After the files have been converted, their originals are deleted from inside the `raw` folder.\n",
    "\n",
    "Lastly, we will split the data we have collected into train, test and validation subsets. The default split sizes were selected to be 80%/20% on train/test and from the remaining train data 20% is witheld for the validation set. The split sizes can be customised inside the `configs/dataset/waymo_open_dataset.yaml` configuration file.\n",
    "\n",
    "\n",
    "**Disclaimer**: A lot of effort has been put in by me (the author of this notebook, Jonathan L. Moran) to mitigate platform issues between macOS/Ubuntu/Google Colab instances. Many hurdles prevent one from currently utilising the Udacity VM to carry out the full extent of this project. I'm doing my best to work with the Udacity mentors/staff to resolve these issues as they come up. If you are able to execute the project on a local setup with GPU/TPU hardware acceleration, please let me know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiZEL5fg9VC2"
   },
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fHBhbd7hqf4",
    "outputId": "11c332e9-efa7-44c8-d1db-1bcbd7d5fa9b"
   },
   "outputs": [],
   "source": [
    "!python3 experiments/testing_configs.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you see the above help message/welcome screen -- congratulations! You've compiled the project successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0R1HV9W9jkv"
   },
   "source": [
    "#### Downloading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pxyD62g_OvE"
   },
   "source": [
    "To download and process the `.tfrecord` files from Google Cloud Storage into `tf.data.TFRecordDataset` instances, run:\n",
    "\n",
    "    ```python\n",
    "    python3 download_process.py\n",
    "    ```\n",
    "with none/any/all of the following parameters:\n",
    "```\n",
    "        DATA_DIR:        str         Path to the `data` directory to download files to.\n",
    "        LABEL_MAP_PATH:  str         Path to the dataset `label_map.pbtxt` file.\n",
    "        SIZE:            int         Number of `.tfrecord` files to download from GCS.\n",
    "```\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 download_process.py \\\n",
    "        dataset.data_dir={DATA_DIR} \\\n",
    "        dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "        dataset.size={SIZE}\n",
    "    ```\n",
    "See `configs/dataset/` for additional details on preconfigured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhfckQUH_rXJ"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = DIR_SRC\n",
    "LABEL_MAP_PATH = os.path.join(DIR_SRC, 'waymo_open_dataset/label_map.pbtxt')\n",
    "SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2kfDzrg-ByU"
   },
   "outputs": [],
   "source": [
    "!python3 scripts/preprocessing/download_process.py \\\n",
    "    dataset.data_dir=\"{DATA_DIR}/waymo_open_dataset\" \\\n",
    "    dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "    dataset.size={SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_klbe-Ao9mc-"
   },
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4uM7ae6AMzQ"
   },
   "source": [
    "To split the downloaded data into three subsets `train`, `val`, and `test`, run:\n",
    "    \n",
    "    ```python\n",
    "    python3 create_splits.py\n",
    "    ```\n",
    "\n",
    "with none/any/all of the following:\n",
    "```\n",
    "        DATA_DIR:           str         Path to the source `data` directory.\n",
    "        TRAIN:              str         Path to the `train` data directory.\n",
    "        TEST:               str         Path to the `test` data directory.\n",
    "        VAL:                str         Path to the `val` data directory.\n",
    "        TRAIN_TEST_SPLIT:   float       Percent as [0, 1] to split train/test.\n",
    "        TRAIN_VAL_SPLIT:    float       Percent as [0, 1] to split train/val.\n",
    "```\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 create_splits.py \\\n",
    "        dataset.data_dir={DATA_DIR} \\\n",
    "        dataset.train={TRAIN} dataset.test={TEST} dataset.val={VAL} \\\n",
    "        dataset.train_test_split={TRAIN_TEST_SPLIT} \\\n",
    "        dataset.train_val_split={TRAIN_VAL_SPLIT}\n",
    "    ```\n",
    "See `configs/dataset/` for additional details on preconfigured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0V8g8UfAdfg"
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join(DIR_SRC, 'waymo_open_dataset/split/train')\n",
    "TEST = os.path.join(DIR_SRC, 'waymo_open_dataset/split/test')\n",
    "VAL = os.path.join(DIR_SRC, 'waymo_open_dataset/split/val')\n",
    "TRAIN_TEST_SPLIT = 0.8    # 80/20 train/test split\n",
    "TRAIN_VAL_SPLIT = 0.8     # 80/20 train/val split (performed on split train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvSEOqWgAdHF"
   },
   "outputs": [],
   "source": [
    "!python3 create_splits.py \\\n",
    "    dataset.train={TRAIN} \\\n",
    "    dataset.test={TEST} \\\n",
    "    dataset.val={VAL} \\\n",
    "    dataset.train_test_split={TRAIN_TEST_SPLIT} \\\n",
    "    dataset.train_val_split={TRAIN_VAL_SPLIT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: we will be skipping the data acquisition step for now, since the processed `.tfrecord` files have been provided to us in the `/home/workspace/data` folder.\n",
    "\n",
    "Let's see how many files we have in each subset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAULbUrzEKTO"
   },
   "outputs": [],
   "source": [
    "N_TRAIN = len(glob.glob(f\"{TRAIN}/*.tfrecord\"))\n",
    "N_TEST = len(glob.glob(f\"{TEST}/*.tfrecord\"))\n",
    "N_VAL = len(glob.glob(f\"{VAL}/*.tfrecord\"))\n",
    "print('Number of training `segment` files:  ', N_TRAIN, \n",
    "      '\\nNumber of testing `segment` files:   ', N_TEST,\n",
    "      '\\nNumber of validation `segment` files:', N_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NsUDjAQ9W9A"
   },
   "source": [
    "### 2.2. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl7iVVvX9axz"
   },
   "source": [
    "#### Modifying the config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VwwA66WBh8C"
   },
   "source": [
    "To configure the model for training, run:\n",
    "\n",
    "    ```python\n",
    "    python3 edit_config.py\n",
    "    ```\n",
    "\n",
    "with none/any/all of the following parameters:\n",
    "```\n",
    "    TRAIN:                                  str         Path to the `train` data directory.\n",
    "    TEST:                                   str         Path to the `test` data directory.\n",
    "    VAL:                                    str         Path to the `val` data directory.\n",
    "    BATCH_SIZE:                             int         Number of examples to process per iteration.\n",
    "    CHECKPOINT_DIR:                         str         Path to the pre-trained `checkpoint` folder.\n",
    "    LABEL_MAP_PATH:                         str         Path to the dataset `label_map.pbtxt` file.\n",
    "    PIPELINE_CONFIG_PATH:                   str         Path to the `pipeline.config` file to modify.\n",
    "```\n",
    "\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 edit_config.py \\\n",
    "        dataset.train={TRAIN} dataset.test={TEST} dataset.val={VAL} \\\n",
    "        dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "        hyperparameters.batch_size={BATCH_SIZE} \\\n",
    "        model.checkpoint_dir={CHECKPOINT_DIR} \\\n",
    "        model.pipeline_config_path={PIPELINE_CONFIG_PATH}\n",
    "    ```\n",
    "See `configs/model/` for additional details on preconfigured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyE0eJoS93D1"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2     # Modify to something reasonable for your training setup\n",
    "CHECKPOINT_DIR = os.path.join(DIR_MODEL, 'tmp/model_outputs/ckpt-2')   # Starting with pre-trained weights checkpoint\n",
    "PIPELINE_CONFIG_PATH = os.path.join(DIR_MODEL, 'pipeline.config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfimzciXC-Sf"
   },
   "outputs": [],
   "source": [
    "!python3 scripts/training/edit_config.py \\\n",
    "    dataset.train={TRAIN} dataset.test={TEST} dataset.val={VAL} \\\n",
    "    dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "    hyperparameters.batch_size={BATCH_SIZE} \\\n",
    "    model.checkpoint_dir={CHECKPOINT_DIR} \\\n",
    "    model.pipeline_config_path={PIPELINE_CONFIG_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCaz-zRi93c0"
   },
   "source": [
    "#### Running the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKIWjfIpDZEr"
   },
   "source": [
    "For local training/evaluation run:\n",
    "\n",
    "    ```python\n",
    "    python3 model_main_tf2.py\n",
    "    ```\n",
    "\n",
    "with none/any/all of the following parameters:\n",
    "```\n",
    "    DIR_BASE:                               str         Path to the current `model` subdirectory.\n",
    "    MODEL_OUT:                              str         Path to the `/tmp/model_outputs` folder.\n",
    "    CHECKPOINT_DIR:                         str         Path to the pretrained weights/variables saved in `checkpoint` folder.\n",
    "    PIPELINE_CONFIG_PATH:                   str         Path to the `pipeline_new.config` file.\n",
    "    NUM_TRAIN_STEPS:                        int         Number of training steps (batch iterations) to perform. \n",
    "    EVAL_ON_TRAIN_DATA:                     bool        If True, will evaluate on training data (only supported in distributed training).\n",
    "    SAMPLE_1_OF_N_EVAL_EXAMPLES:            int         Number of evaluation samples to skip (will sample 1 of every n samples per batch).\n",
    "    SAMPLE_1_OF_N_EVAL_ON_TRAIN_EXAMPLES:   int         Number of training samples to skip (only used if `eval_on_train_data` is True).\n",
    "    EVAL_TIMEOUT:                           int         Number of seconds to wait for an evaluation checkpoint before exiting.\n",
    "    USE_TPU:                                bool        Whether or not the job is executing on a TPU.\n",
    "    TPU_NAME:                               str         Name of the Cloud TPU for Cluster Resolvers.\n",
    "    CHECKPOINT_EVERY_N:                     int         Defines how often to checkpoint (every n steps).\n",
    "    RECORD_SUMMARIES:                       bool        Whether or not to record summaries defined by the model or training pipeline.\n",
    "    NUM_WORKERS:                            int         When `num_workers` > 1, training uses 'MultiWorkerMirroredStrategy',\n",
    "                                                        When `num_workers` = 1, training uses 'MirroredStrategy'.\n",
    "```\n",
    "\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 model_main_tf2.py \\\n",
    "        model.pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
    "        model.model_out={MODEL_OUT} model.num_train_steps={NUM_TRAIN_STEPS} \\\n",
    "        model.sample_1_of_n_eval_examples={SAMPLE_1_OF_N_EVAL_EXAMPLES} \\\n",
    "        ...\n",
    "    ```\n",
    "See `configs/model/` for additional details on preconfigured values if running without parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMs_qdceDjly"
   },
   "outputs": [],
   "source": [
    "DIR_BASE = DIR_MODEL\n",
    "MODEL_OUT = os.path.join(DIR_BASE, '/tmp/model_outputs')\n",
    "PIPELINE_CONFIG_PATH = os.path.join(DIR_BASE, 'pipeline_new.config')\n",
    "EPOCHS = 450\n",
    "NUM_TRAIN_STEPS = N_TRAIN // BATCH_SIZE * EPOCHS\n",
    "EVAL_ON_TRAIN_DATA = False\n",
    "SAMPLE_1_OF_N_EVAL_EXAMPLES = 1\n",
    "EVAL_TIMEOUT = 5000    # NOTE: should be sufficiently long to wait until each training checkpoint is complete\n",
    "USE_TPU = False\n",
    "TPU_NAME = None\n",
    "RECORD_SUMMARIES = False\n",
    "NUM_WORKERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtZsaD5WNhkH"
   },
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSLCIq1LH6D5"
   },
   "outputs": [],
   "source": [
    "if USE_TPU:\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "    except ValueError:\n",
    "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "    TPU_NAME = os.environ['COLAB_TPU_ADDR']\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    ### Updating training parameters to be multiples of TPU cores\n",
    "    BATCH_SIZE = BATCH_SIZE * tpu_strategy.num_replicas_in_sync\n",
    "    NUM_WORKERS = len(tf.config.list_logical_devices('TPU'))\n",
    "    ### Check if batch size and learning rate are auto updated with USE_TPU\n",
    "    ### Check if dataset call uses `prefetch` with AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k24e-tKN8Zma",
    "outputId": "99b7a354-54aa-4241-8543-93015c730931"
   },
   "outputs": [],
   "source": [
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjSeqf9y8Xla"
   },
   "outputs": [],
   "source": [
    "### Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 experiments/model_main_tf2.py \\\n",
    "    --model_dir {MODEL_OUT} \\\n",
    "    --pipeline_config_path {PIPELINE__NEW_CONFIG_PATH} \\\n",
    "    #--checkpoint_dir {TRAINED_CHECKPOINT_DIR} \\    # NOTE: only uncomment for continuous evaluation\n",
    "    --num_train_steps NUM_TRAIN_STEPS \\\n",
    "    --eval_on_train_data False \\\n",
    "    --sample_1_of_n_eval_examples 1 \\\n",
    "    --eval_timeout EVAL_TIMEOUT \\                   # NOTE: should be sufficiently long for continuous evaluation\n",
    "    --use_tpu False \\\n",
    "    --tpu_name None \\\n",
    "    --record_summaries False \\\n",
    "    --num_workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWP-PePT7pSm"
   },
   "outputs": [],
   "source": [
    "# Control TensorBoard display. If no port is provided, \n",
    "# the most recently launched TensorBoard is used\n",
    "notebook.display(height=1000)\n",
    "# Can also use:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {MODEL_OUT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By9XHEA396GM"
   },
   "source": [
    "#### Exporting the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsOoovjO7pPM"
   },
   "outputs": [],
   "source": [
    "!python experiments/exporter_main_v2.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path {PIPELINE_NEW_CONFIG_PATH} \\\n",
    "    --trained_checkpoint_dir {MODEL_OUT} \\\n",
    "    --output_directory {DIR_BASE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpReuZND99Gz"
   },
   "source": [
    "### 2.3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running inference on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference_video.py \\\n",
    "    --labelmap_path {LABEL_MAP_PATH} \\\n",
    "    --model_path {EXPORTED_MODEL_DIR} \\\n",
    "    --tf_record_path {TF_RECORD_PATH} \\\n",
    "    --config_path {PIPELINE_NEW_CONFIG_PATH} \\\n",
    "    --output_path {INFERENCE_OUTPUT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternatives\n",
    "* Run `download_process` script in different environments (e.g., Ubuntu, Google Colab, Google Compute Engine instance);\n",
    "* Skip `download_process` and instead use the provided `.tfrecord` data to train model (see caveats [here](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/issues/21));\n",
    "* Balance dataset classes ('pedestrian' and 'cyclist' classes -- see [`2022-10-16-Report.md`]()).\n",
    "\n",
    "##### Extensions of task\n",
    "* Train model on additional data (more than 100 `.tfrecord` files);\n",
    "* Compare pre-trained model performance against other models on TensorFlow's [Object Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md);\n",
    "* Customise the `pipeline.config` file to include e.g., additional [data augmentation](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) strategies (see [Exercise 1.4.3](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/934e20c38832186c534846ba1eaaaa3abdead499/1-Computer-Vision/Exercises/1-4-3-Image-Augmentations/2022-09-19-Image-Augmentations.ipynb) for domain-specific examples), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Future Work\n",
    "* ✅ Train model and evaluate using the Udacity provided `.tfrecord` data;\n",
    "* ⬜️ Address model under-performance on the 'pedestrian' and 'cyclist' classes;\n",
    "* ⬜️ Compare training and inference times between Udacity VM GPU and Google TPU cluster (5 v3.8 and v2.8 nodes, 100 v2.8 nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment was prepared by Thomas Hossler, Michael Virgo et al., Winter 2021 (link [here](https://github.com/udacity/nd013-c1-vision-starter)).\n",
    "\n",
    "\n",
    "References\n",
    "* [1] Huang, J. et al., Speed/accuracy trade-offs for modern convolutional object detectors. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2017. [doi: 10.48550/arXiv.1611.10012](https://arxiv.org/abs/1611.10012).\n",
    "\n",
    "* [2] Sun, Pei, et al., Scalability in Perception for Autonomous Driving: Waymo Open Dataset. arXiv. 2019. [doi: 10.48550/ARXIV.1912.04838](https://arxiv.org/abs/1912.04838).\n",
    "\n",
    "\n",
    "Helpful explanations:\n",
    "* [Training Custom Object Detector by L. Vladimirov | TensorFlow 2 Object Detection API tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
