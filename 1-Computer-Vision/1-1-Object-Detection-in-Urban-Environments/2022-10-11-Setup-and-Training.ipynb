{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1.1: Object Detection in Urban Environments\n",
    "## Model Setup and Training\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip uninstall -y protobuf\n",
    "!sudo pip uninstall -y google\n",
    "!sudo pip install google\n",
    "!sudo pip install protobuf\n",
    "!sudo pip install google-cloud\n",
    "!pip install ray\n",
    "!pip install omegaconf\n",
    "!pip install hydra-core\n",
    "!pip install packaging\n",
    "!pip install importlib-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install waymo-open-dataset-tf-2-3-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "emaXw1WU7yi4"
   },
   "outputs": [],
   "source": [
    "### Importing the required modules\n",
    "# Doing this here to test installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ef1oC32J7ydQ"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import google.protobuf\n",
    "import hydra\n",
    "import numpy as np\n",
    "import os\n",
    "import ray\n",
    "import sys\n",
    "from tensorboard import notebook\n",
    "import tensorflow as tf\n",
    "import waymo_open_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.7'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "ZwVscjHKRHMJ",
    "outputId": "a159ed0d-2a31-4da4-c8fe-425a0fa399a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "2-zlG-v8UMN_",
    "outputId": "51800c7c-bf7b-40aa-d042-6ae6e1a5a4b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I4lcBVzY7gjR"
   },
   "outputs": [],
   "source": [
    "### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "M8EYVzwH7p58"
   },
   "outputs": [],
   "source": [
    "ENV_COLAB = False               # True if running in Google Colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sxl6nJIX7p1o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace/1-1-Object-Detection-in-Urban-Environments'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Root directory\n",
    "DIR_BASE = '' if not ENV_COLAB else '/content/1-1-Object-Detection-in-Urban-Environments'\n",
    "DIR_BASE = os.path.abspath(DIR_BASE)\n",
    "DIR_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "K5wue9dL7pwk"
   },
   "outputs": [],
   "source": [
    "# Subdirectory to save output files\n",
    "DIR_OUT = os.path.join(DIR_BASE, 'out')\n",
    "# Subdirectory pointing to input data\n",
    "DIR_SRC = os.path.join(DIR_BASE, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bR_S9A3m765m"
   },
   "outputs": [],
   "source": [
    "### Creating subdirectories (if not exists)\n",
    "os.makedirs(DIR_SRC, exist_ok=True)\n",
    "os.makedirs(DIR_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Z-pE_CxiMYXi"
   },
   "outputs": [],
   "source": [
    "# Subdirectory to model folder\n",
    "DIR_MODEL = os.path.join(DIR_BASE, 'experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NUPEotHEkjE3"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension (if using Colab)\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Downloading the Google Cloud CLI (if folder doesn't already exist)\n",
    "if not os.path.exists(os.path.join(DIR_BASE, 'addons/google-cloud-sdk')):\n",
    "    # Download Cloud CLI tools from Google\n",
    "    !curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-405.0.0-linux-x86_64.tar.gz\n",
    "    # Unzip to addons folder\n",
    "    !tar -xf google-cloud-cli-405.0.0-linux-x86_64.tar.gz -C addons/\n",
    "### Setting up Google Cloud CLI tools (run commands inside interactive shell)\n",
    "# ./addons/google-cloud-sdk/install.sh\n",
    "# ./gcloud init\n",
    "### Authenticate the service account\n",
    "# ./gcloud auth activate-service-account [service-email] --key-file\"[path/to/key-file]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sweeping the working directory for Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Obtaining file:///home/workspace/1-1-Object-Detection-in-Urban-Environments\n",
      "Installing collected packages: 1-1-Object-Detection-in-Urban-Environments\n",
      "  Running setup.py develop for 1-1-Object-Detection-in-Urban-Environments\n",
      "Successfully installed 1-1-Object-Detection-in-Urban-Environments\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/root/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --editable {DIR_BASE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Setup and Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook we will be fetching the Waymo Open Dataset files from their Google Cloud Storage bucket locations. To view the file paths we will be downloading, see `filenames.txt` inside the `data/waymo_open_dataset` folder.\n",
    "\n",
    "\n",
    "#### Environment setup\n",
    "The Python files inside `/scripts/..` have been modified to work on the Linux Ubuntu VM provided in the Udacity workspace. Please see previous commits of this repository to obtain script files suited for macOS and Google Colab. As of now, the Ubuntu VM is running Python version 3.7.3, TensorFlow 2.3.0 and Waymo Open Dataset version `tf-2-3-0==1.4.0`. The other dependency versions should be checked for conflicts on any other machine.\n",
    "\n",
    "Running the `!pip install --editable setup.py` command will add all modules from this project repository onto the Python path. This is the recommended way to resolve `PYTHONPATH` issues, preferred to updating the `/.bashrc` file or `os.environ['PYTHONPATH']`/`sys.path` variables.\n",
    "\n",
    "#### Data acquisition\n",
    "\n",
    "The `download_process.py` script will fetch the `.tfrecord` files from GCS and store them locally in the `data/waymo_open_dataset/raw` subdirectory to be processed. The raw `.tfrecord` files are parsed in `process_tfr`; the images, bounding box labels and attribute data are stored in a dictionary-like object and converted to `tf.data.TFRecordDataset` instances. After the files have been converted, their originals are deleted from inside the `raw` folder.\n",
    "\n",
    "Lastly, we will split the data we have collected into train, test and validation subsets. The default split sizes were selected to be 80%/20% on train/test and from the remaining train data 20% is witheld for the validation set. The split sizes can be customised inside the `configs/dataset/waymo_open_dataset.yaml` configuration file.\n",
    "\n",
    "\n",
    "**Disclaimer**: A lot of effort has been put in by me (the author of this notebook, Jonathan L. Moran) to mitigate platform issues between macOS/Ubuntu/Google Colab instances. Many hurdles prevent one from currently utilising the Udacity VM to carry out the full extent of this project. I'm doing my best to work with the Udacity mentors/staff to resolve these issues as they come up. If you are able to execute the project on a local setup with GPU/TPU hardware acceleration, please let me know. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiZEL5fg9VC2"
   },
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fHBhbd7hqf4",
    "outputId": "11c332e9-efa7-44c8-d1db-1bcbd7d5fa9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\r\n",
      "                    TensorFlow Object Detection API\r\n",
      "---------------------------------------------------------------------------\r\n",
      "Packaged with <3 by Jonathan L. Moran (jonathan.moran107@gmail.com).\r\n",
      "Intended for use on the Waymo Open Dataset for the Perception-Sensor 2D task.\r\n",
      "\r\n",
      "\r\n",
      "Training/evaluation\r\n",
      "--------------------\r\n",
      "For local training/evaluation run:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 model_main_tf2.py\r\n",
      "```\r\n",
      "\r\n",
      "with none/any/all of the following parameters:\r\n",
      "```\r\n",
      "DIR_BASE:                               str         Path to the current `model` subdirectory.\r\n",
      "MODEL_OUT:                              str         Path to the `/tmp/model_outputs` folder.\r\n",
      "CHECKPOINT_DIR:                         str         Path to the pretrained weights/variables saved in `checkpoint` folder.\r\n",
      "PIPELINE_CONFIG_PATH:                   str         Path to the `pipeline.config` file.\r\n",
      "NUM_TRAIN_STEPS:                        int         Number of training steps (batch iterations) to perform. \r\n",
      "EVAL_ON_TRAIN_DATA:                     bool        If True, will evaluate on training data (only supported in distributed training).\r\n",
      "SAMPLE_1_OF_N_EVAL_EXAMPLES:            int         Number of evaluation samples to skip (will sample 1 of every n samples per batch).\r\n",
      "SAMPLE_1_OF_N_EVAL_ON_TRAIN_EXAMPLES:   int         Number of training samples to skip (only used if `eval_on_train_data` is True).\r\n",
      "EVAL_TIMEOUT:                           int         Number of seconds to wait for an evaluation checkpoint before exiting.\r\n",
      "USE_TPU:                                bool        Whether or not the job is executing on a TPU.\r\n",
      "TPU_NAME:                               str         Name of the Cloud TPU for Cluster Resolvers.\r\n",
      "CHECKPOINT_EVERY_N:                     int         Defines how often to checkpoint (every n steps).\r\n",
      "RECORD_SUMMARIES:                       bool        Whether or not to record summaries defined by the model or training pipeline.\r\n",
      "NUM_WORKERS:                            int         When `num_workers` > 1, training uses 'MultiWorkerMirroredStrategy',\r\n",
      "                                                    When `num_workers` = 1, training uses 'MirroredStrategy'.\r\n",
      "\r\n",
      "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 model_main_tf2.py \\\r\n",
      "    model.pipeline_config_path=PIPELINE_CONFIG_PATH \\\r\n",
      "    model.model_out=MODEL_OUT model.num_train_steps=NUM_TRAIN_STEPS \\\r\n",
      "    model.sample_1_of_n_eval_examples=SAMPLE_1_OF_N_EVAL_EXAMPLES \\\r\n",
      "    ...\r\n",
      "```\r\n",
      "See `configs/model/` for additional details on preconfigured values if running without parameters.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Configuration\r\n",
      "--------------\r\n",
      "To configure the model for training, run:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 edit_config.py\r\n",
      "```\r\n",
      "\r\n",
      "with none/any/all of the following parameters:\r\n",
      "TRAIN:                                  str         Path to the `train` data directory.\r\n",
      "TEST:                                   str         Path to the `test` data directory.\r\n",
      "VAL:                                    str         Path to the `val` data directory.\r\n",
      "BATCH_SIZE:                             int         Number of examples to process per iteration.\r\n",
      "CHECKPOINT_DIR:                         str         Path to the pre-trained `checkpoint` folder.\r\n",
      "LABEL_MAP_PATH:                         str         Path to the dataset `label_map.pbtxt` file.\r\n",
      "PIPELINE_CONFIG_PATH:                   str         Path to the `pipeline.config` file to modify.\r\n",
      "\r\n",
      "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 edit_config.py \\\r\n",
      "    dataset.train=TRAIN dataset.test=TEST dataset.val=VAL \\\r\n",
      "    dataset.label_map_path=LABEL_MAP_PATH \\\r\n",
      "    hyperparameters.batch_size=BATCH_SIZE \\\r\n",
      "    model.checkpoint_dir=CHECKPOINT_DIR \\\r\n",
      "    model.pipeline_config_path=PIPELINE_CONFIG_PATH\r\n",
      "```\r\n",
      "See `configs/model/` for additional details on preconfigured values.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Utilities\r\n",
      "---------\r\n",
      "\r\n",
      "1. Downloading and Processing:\r\n",
      "\r\n",
      "To download and process the `.tfrecord` files from Google Cloud Storage into `tf.data.TFRecordDataset` instances, run:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 download_process.py\r\n",
      "```\r\n",
      "\r\n",
      "with none/any/all of the following parameters:\r\n",
      "    DATA_DIR:        str         Path to the `data` directory to download files to.\r\n",
      "    LABEL_MAP_PATH:  str         Path to the dataset `label_map.pbtxt` file.\r\n",
      "    SIZE:            str         Number of `.tfrecord` files to download from GCS.\r\n",
      "\r\n",
      "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 download_process.py \\\r\n",
      "    dataset.data_dir=DATA_DIR \\\r\n",
      "    dataset.label_map_path=LABEL_MAP_PATH \\\r\n",
      "    dataset.size=SIZE\r\n",
      "```\r\n",
      "See `configs/dataset/` for additional details on preconfigured values.\r\n",
      "\r\n",
      "\r\n",
      "2. Creating Dataset Splits:\r\n",
      "\r\n",
      "To split the downloaded data into three subsets `train`, `val`, and `test`, run:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 create_splits.py\r\n",
      "```\r\n",
      "\r\n",
      "with none/any/all of the following:\r\n",
      "    DATA_DIR:           str         Path to the source `data` directory.\r\n",
      "    TRAIN:              str         Path to the `train` data directory.\r\n",
      "    TEST:               str         Path to the `test` data directory.\r\n",
      "    VAL:                str         Path to the `val` data directory.\r\n",
      "    TRAIN_TEST_SPLIT:   float       Percent as [0, 1] to split train/test.\r\n",
      "    TRAIN_VAL_SPLIT:    float       Percent as [0, 1] to split train/val.\r\n",
      "\r\n",
      "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\r\n",
      "\r\n",
      "```python\r\n",
      "python3 create_splits.py \\\r\n",
      "    dataset.data_dir=DATA_DIR \\\r\n",
      "    dataset.train=TRAIN dataset.test=TEST dataset.val=VAL \\\r\n",
      "    dataset.train_test_split=TRAIN_TEST_SPLIT \\\r\n",
      "    dataset.train_val_split=TRAIN_VAL_SPLIT\r\n",
      "```\r\n",
      "See `configs/dataset/` for additional details on preconfigured values.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Additional Resources\r\n",
      "--------------------\r\n",
      "For help with the TensorFlow Object Detection API, see: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/.\r\n",
      "For help with the Waymo Open Dataset, see: https://waymo.com/open or https://github.com/waymo-research/waymo-open-dataset.\r\n",
      "For all other inquiries, please open an issue on the GitHub repository: https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/issues.\r\n"
     ]
    }
   ],
   "source": [
    "!python3 experiments/testing_configs.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you see the above help message/welcome screen -- congratulations! You've compiled the project successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0R1HV9W9jkv"
   },
   "source": [
    "#### Downloading and processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pxyD62g_OvE"
   },
   "source": [
    "To download and process the `.tfrecord` files from Google Cloud Storage into `tf.data.TFRecordDataset` instances, run:\n",
    "\n",
    "    ```python\n",
    "    python3 download_process.py\n",
    "    ```\n",
    "with none/any/all of the following parameters:\n",
    "```\n",
    "        DATA_DIR:        str         Path to the `data` directory to download files to.\n",
    "        LABEL_MAP_PATH:  str         Path to the dataset `label_map.pbtxt` file.\n",
    "        SIZE:            int         Number of `.tfrecord` files to download from GCS.\n",
    "```\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 download_process.py \\\n",
    "        dataset.data_dir={DATA_DIR} \\\n",
    "        dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "        dataset.size={SIZE}\n",
    "    ```\n",
    "See `configs/dataset/` for additional details on preconfigured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vhfckQUH_rXJ"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = DIR_SRC\n",
    "LABEL_MAP_PATH = os.path.join(DIR_SRC, 'waymo_open_dataset/label_map.pbtxt')\n",
    "SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "b2kfDzrg-ByU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-13 22:59:35.676931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-13 22:59:39,392 INFO     Downloading 1 files. Be patient, this will take a long time.\n",
      "2022-10-13 22:59:39,393 INFO     Downloading segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/preprocessing/download_process.py\", line 340, in <module>\n",
      "    main()\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/main.py\", line 95, in decorated_main\n",
      "    config_name=config_name,\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 396, in _run_hydra\n",
      "    overrides=overrides,\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 453, in _run_app\n",
      "    lambda: hydra.run(\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 213, in run_and_report\n",
      "    return func()\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 456, in <lambda>\n",
      "    overrides=overrides,\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 127, in run\n",
      "    configure_logging=with_log_configuration,\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"scripts/preprocessing/download_process.py\", line 333, in main\n",
      "    download_and_process(file_path, cfg['dataset'].data_dir)\n",
      "  File \"scripts/preprocessing/download_process.py\", line 283, in download_and_process\n",
      "    local_path = download_tfr(file_path, data_raw_dir)\n",
      "  File \"scripts/preprocessing/download_process.py\", line 212, in download_tfr\n",
      "    res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
      "  File \"/root/miniconda3/lib/python3.7/subprocess.py\", line 474, in run\n",
      "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
      "  File \"/root/miniconda3/lib/python3.7/subprocess.py\", line 939, in communicate\n",
      "    stdout, stderr = self._communicate(input, endtime, timeout)\n",
      "  File \"/root/miniconda3/lib/python3.7/subprocess.py\", line 1681, in _communicate\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/miniconda3/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/preprocessing/download_process.py \\\n",
    "    dataset.data_dir=\"{DATA_DIR}/waymo_open_dataset\" \\\n",
    "    dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "    dataset.size={SIZE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_klbe-Ao9mc-"
   },
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4uM7ae6AMzQ"
   },
   "source": [
    "To split the downloaded data into three subsets `train`, `val`, and `test`, run:\n",
    "    \n",
    "    ```python\n",
    "    python3 create_splits.py\n",
    "    ```\n",
    "\n",
    "with none/any/all of the following:\n",
    "```\n",
    "        DATA_DIR:           str         Path to the source `data` directory.\n",
    "        TRAIN:              str         Path to the `train` data directory.\n",
    "        TEST:               str         Path to the `test` data directory.\n",
    "        VAL:                str         Path to the `val` data directory.\n",
    "        TRAIN_TEST_SPLIT:   float       Percent as [0, 1] to split train/test.\n",
    "        TRAIN_VAL_SPLIT:    float       Percent as [0, 1] to split train/val.\n",
    "```\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 create_splits.py \\\n",
    "        dataset.data_dir={DATA_DIR} \\\n",
    "        dataset.train={TRAIN} dataset.test={TEST} dataset.val={VAL} \\\n",
    "        dataset.train_test_split={TRAIN_TEST_SPLIT} \\\n",
    "        dataset.train_val_split={TRAIN_VAL_SPLIT}\n",
    "    ```\n",
    "See `configs/dataset/` for additional details on preconfigured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "M0V8g8UfAdfg"
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join(DIR_SRC, 'waymo_open_dataset/split/train')\n",
    "TEST = os.path.join(DIR_SRC, 'waymo_open_dataset/split/test')\n",
    "VAL = os.path.join(DIR_SRC, 'waymo_open_dataset/split/val')\n",
    "TRAIN_TEST_SPLIT = 0.8    # 80/20 train/test split\n",
    "TRAIN_VAL_SPLIT = 0.8     # 80/20 train/val split (performed on split train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvSEOqWgAdHF"
   },
   "outputs": [],
   "source": [
    "!python3 create_splits.py \\\n",
    "    dataset.train={TRAIN} \\\n",
    "    dataset.test={TEST} \\\n",
    "    dataset.val={VAL} \\\n",
    "    dataset.train_test_split={TRAIN_TEST_SPLIT} \\\n",
    "    dataset.train_val_split={TRAIN_VAL_SPLIT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: we will be skipping the data acquisition step for now, since the processed `.tfrecord` files have been provided to us in the `/home/workspace/data` folder.\n",
    "\n",
    "Let's see how many files we have in each subset.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sAULbUrzEKTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training `segment` files:   86 \n",
      "Number of testing `segment` files:    3 \n",
      "Number of validation `segment` files: 10\n"
     ]
    }
   ],
   "source": [
    "N_TRAIN = len(glob.glob(f\"{TRAIN}/*.tfrecord\"))\n",
    "N_TEST = len(glob.glob(f\"{TEST}/*.tfrecord\"))\n",
    "N_VAL = len(glob.glob(f\"{VAL}/*.tfrecord\"))\n",
    "print('Number of training `segment` files:  ', N_TRAIN, \n",
    "      '\\nNumber of testing `segment` files:   ', N_TEST,\n",
    "      '\\nNumber of validation `segment` files:', N_VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NsUDjAQ9W9A"
   },
   "source": [
    "### 2.2. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl7iVVvX9axz"
   },
   "source": [
    "#### Modifying the config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VwwA66WBh8C"
   },
   "source": [
    "To configure the model for training, run:\n",
    "\n",
    "    ```python\n",
    "    python3 edit_config.py\n",
    "    ```\n",
    "\n",
    "with none/any/all of the following parameters:\n",
    "```\n",
    "    TRAIN:                                  str         Path to the `train` data directory.\n",
    "    TEST:                                   str         Path to the `test` data directory.\n",
    "    VAL:                                    str         Path to the `val` data directory.\n",
    "    BATCH_SIZE:                             int         Number of examples to process per iteration.\n",
    "    CHECKPOINT_DIR:                         str         Path to the pre-trained `checkpoint` folder.\n",
    "    LABEL_MAP_PATH:                         str         Path to the dataset `label_map.pbtxt` file.\n",
    "    PIPELINE_CONFIG_PATH:                   str         Path to the `pipeline.config` file to modify.\n",
    "```\n",
    "\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 edit_config.py \\\n",
    "        dataset.train={TRAIN} dataset.test={TEST} dataset.val={VAL} \\\n",
    "        dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "        hyperparameters.batch_size={BATCH_SIZE} \\\n",
    "        model.checkpoint_dir={CHECKPOINT_DIR} \\\n",
    "        model.pipeline_config_path={PIPELINE_CONFIG_PATH}\n",
    "    ```\n",
    "See `configs/model/` for additional details on preconfigured values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SyE0eJoS93D1"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2     # Modify to something reasonable for your training setup\n",
    "CHECKPOINT_DIR = os.path.join(DIR_MODEL, 'checkpoint')\n",
    "PIPELINE_CONFIG_PATH = os.path.join(DIR_MODEL, 'pipeline.config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace/1-1-Object-Detection-in-Urban-Environments/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPELINE_CONFIG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BfimzciXC-Sf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-14 19:32:31.523677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/training/edit_config.py \\\n",
    "    dataset.label_map_path={LABEL_MAP_PATH} \\\n",
    "    hyperparameters.batch_size={BATCH_SIZE} \\\n",
    "    model.checkpoint_dir={CHECKPOINT_DIR} \\\n",
    "    model.pipeline_config_path={PIPELINE_CONFIG_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCaz-zRi93c0"
   },
   "source": [
    "#### Running the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKIWjfIpDZEr"
   },
   "source": [
    "For local training/evaluation run:\n",
    "\n",
    "    ```python\n",
    "    python3 model_main_tf2.py\n",
    "    ```\n",
    "\n",
    "with none/any/all of the following parameters:\n",
    "```\n",
    "    DIR_BASE:                               str         Path to the current `model` subdirectory.\n",
    "    MODEL_OUT:                              str         Path to the `/tmp/model_outputs` folder.\n",
    "    CHECKPOINT_DIR:                         str         Path to the pretrained weights/variables saved in `checkpoint` folder.\n",
    "    PIPELINE_CONFIG_PATH:                   str         Path to the `pipeline.config` file.\n",
    "    NUM_TRAIN_STEPS:                        int         Number of training steps (batch iterations) to perform. \n",
    "    EVAL_ON_TRAIN_DATA:                     bool        If True, will evaluate on training data (only supported in distributed training).\n",
    "    SAMPLE_1_OF_N_EVAL_EXAMPLES:            int         Number of evaluation samples to skip (will sample 1 of every n samples per batch).\n",
    "    SAMPLE_1_OF_N_EVAL_ON_TRAIN_EXAMPLES:   int         Number of training samples to skip (only used if `eval_on_train_data` is True).\n",
    "    EVAL_TIMEOUT:                           int         Number of seconds to wait for an evaluation checkpoint before exiting.\n",
    "    USE_TPU:                                bool        Whether or not the job is executing on a TPU.\n",
    "    TPU_NAME:                               str         Name of the Cloud TPU for Cluster Resolvers.\n",
    "    CHECKPOINT_EVERY_N:                     int         Defines how often to checkpoint (every n steps).\n",
    "    RECORD_SUMMARIES:                       bool        Whether or not to record summaries defined by the model or training pipeline.\n",
    "    NUM_WORKERS:                            int         When `num_workers` > 1, training uses 'MultiWorkerMirroredStrategy',\n",
    "                                                        When `num_workers` = 1, training uses 'MirroredStrategy'.\n",
    "```\n",
    "\n",
    "Overriding parameters globally is accomplished at runtime using the Basic Override syntax provided by Hydra:\n",
    "\n",
    "    ```python\n",
    "    python3 model_main_tf2.py \\\n",
    "        model.pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
    "        model.model_out={MODEL_OUT} model.num_train_steps={NUM_TRAIN_STEPS} \\\n",
    "        model.sample_1_of_n_eval_examples={SAMPLE_1_OF_N_EVAL_EXAMPLES} \\\n",
    "        ...\n",
    "    ```\n",
    "See `configs/model/` for additional details on preconfigured values if running without parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "TMs_qdceDjly"
   },
   "outputs": [],
   "source": [
    "DIR_BASE = DIR_MODEL\n",
    "MODEL_OUT = os.path.join(DIR_BASE, '/tmp/model_outputs')\n",
    "#EPOCHS = 25\n",
    "#NUM_TRAIN_STEPS = N_TRAIN // BATCH_SIZE * EPOCHS\n",
    "NUM_TRAIN_STEPS = 1    # Testing with 1 iteration right now\n",
    "EVAL_ON_TRAIN_DATA = False\n",
    "SAMPLE_1_OF_N_EVAL_EXAMPLES = 1\n",
    "EVAL_TIMEOUT = 100\n",
    "USE_TPU = False\n",
    "TPU_NAME = None\n",
    "RECORD_SUMMARIES = True\n",
    "NUM_WORKERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RtZsaD5WNhkH"
   },
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XSLCIq1LH6D5"
   },
   "outputs": [],
   "source": [
    "if USE_TPU:\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "        print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "    except ValueError:\n",
    "        raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "    TPU_NAME = os.environ['COLAB_TPU_ADDR']\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    ### Updating training parameters to be multiples of TPU cores\n",
    "    BATCH_SIZE = BATCH_SIZE * tpu_strategy.num_replicas_in_sync\n",
    "    NUM_WORKERS = len(tf.config.list_logical_devices('TPU'))\n",
    "    ### Check if batch size and learning rate are auto updated with USE_TPU\n",
    "    ### Check if dataset call uses `prefetch` with AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k24e-tKN8Zma",
    "outputId": "99b7a354-54aa-4241-8543-93015c730931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No known TensorBoard instances running.\n"
     ]
    }
   ],
   "source": [
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LTQjLuxt8kJq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace/1-1-Object-Detection-in-Urban-Environments/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/tmp/out/20221014-193250'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Setting the logs directory for TensorBoard\n",
    "logs_dir = os.path.join(DIR_MODEL, f\"tmp/out/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
    "logs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(logs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yjSeqf9y8Xla"
   },
   "outputs": [],
   "source": [
    "### Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OC_CAUSE']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "19CY2Z5Z8jpZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-14 19:57:15.358405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "['experiments/model_main_tf2.py', 'model.dir_base=/home/workspace/1-1-Object-Detection-in-Urban-Environments/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8', 'model.model_out=/tmp/model_outputs', 'model.checkpoint_dir=/home/workspace/1-1-Object-Detection-in-Urban-Environments/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint', 'model.pipeline_config_path=/home/workspace/1-1-Object-Detection-in-Urban-Environments/experiments/pretrained_model/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config', 'model.num_train_steps=1', 'model.eval_on_train_data=False', 'model.sample_1_of_n_eval_examples=1', 'model.eval_timeout=100', 'model.use_tpu=False', 'model.tpu_name=', 'model.record_summaries=True', 'model.num_workers=1']\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/listconfig.py\", line 193, in __getitem__\n",
      "    self._validate_get(index, None)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/listconfig.py\", line 87, in _validate_get\n",
      "    \"ListConfig indices must be integers or slices, not $KEY_TYPE\"\n",
      "omegaconf.errors.KeyValidationError: ListConfig indices must be integers or slices, not $KEY_TYPE\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"experiments/model_main_tf2.py\", line 128, in <module>\n",
      "    tf.compat.v1.app.run(main=sys.modules['__main__'].main)\n",
      "  File \"/data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/absl/app.py\", line 300, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/hydra/main.py\", line 79, in decorated_main\n",
      "    return task_function(cfg_passthrough)\n",
      "  File \"experiments/model_main_tf2.py\", line 90, in main\n",
      "    if cfg['model'].checkpoint_dir:\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/listconfig.py\", line 218, in __getitem__\n",
      "    self._format_and_raise(key=index, value=None, cause=e)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/base.py\", line 237, in _format_and_raise\n",
      "    type_override=type_override,\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/_utils.py\", line 900, in format_and_raise\n",
      "    _raise(ex, cause)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/_utils.py\", line 798, in _raise\n",
      "    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/listconfig.py\", line 193, in __getitem__\n",
      "    self._validate_get(index, None)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/omegaconf/listconfig.py\", line 87, in _validate_get\n",
      "    \"ListConfig indices must be integers or slices, not $KEY_TYPE\"\n",
      "omegaconf.errors.KeyValidationError: ListConfig indices must be integers or slices, not str\n",
      "    full_key: [model]\n",
      "    object_type=list\n"
     ]
    }
   ],
   "source": [
    "#%tensorboard --logdir logs_dir\n",
    "!python3 experiments/model_main_tf2.py \\\n",
    "    model.dir_base={DIR_BASE} \\\n",
    "    model.model_out={MODEL_OUT} \\\n",
    "    model.checkpoint_dir={CHECKPOINT_DIR} \\\n",
    "    model.pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
    "    model.num_train_steps={NUM_TRAIN_STEPS} \\\n",
    "    model.eval_on_train_data={EVAL_ON_TRAIN_DATA} \\\n",
    "    model.sample_1_of_n_eval_examples={SAMPLE_1_OF_N_EVAL_EXAMPLES} \\\n",
    "    model.eval_timeout={EVAL_TIMEOUT} \\\n",
    "    model.use_tpu={USE_TPU} \\\n",
    "    model.tpu_name={TPU_NAME} \\\n",
    "    model.record_summaries={RECORD_SUMMARIES} \\\n",
    "    model.num_workers={NUM_WORKERS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jWP-PePT7pSm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-152b58ad10878770\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-152b58ad10878770\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Control TensorBoard display. If no port is provided, \n",
    "# the most recently launched TensorBoard is used\n",
    "notebook.display(port=6006, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8Jdbpkp7pWH"
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By9XHEA396GM"
   },
   "source": [
    "#### Exporting the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EsOoovjO7pPM"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpReuZND99Gz"
   },
   "source": [
    "### 2.3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternatives\n",
    "* Run `download_process` script in different environments (e.g., Ubuntu, Google Colab, Google Compute Engine instance);\n",
    "* Skip `download_process` and instead use the provided `.tfrecord` data to train model (see caveats [here](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/issues/21));\n",
    "\n",
    "##### Extensions of task\n",
    "* Train model on additional data (more than 100 `.tfrecord` files);\n",
    "* Compare pre-trained model performance against other models on TensorFlow's [Object Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md);\n",
    "* Customise the `pipeline.config` file to include e.g., additional [data augmentation](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) strategies (see [Exercise 1.4.3](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/934e20c38832186c534846ba1eaaaa3abdead499/1-Computer-Vision/Exercises/1-4-3-Image-Augmentations/2022-09-19-Image-Augmentations.ipynb) for domain-specific examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Future Work\n",
    "- [ ] Train model and evaluate using the Udacity provided `.tfrecord` data;\n",
    "- [ ] Compare training and inference times between Udacity VM GPU and Google TPU cluster (5 v3.8 and v2.8 nodes, 100 v2.8 nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment was prepared by Thomas Hossler, Michael Virgo et al., Winter 2021 (link [here](https://github.com/udacity/nd013-c1-vision-starter)).\n",
    "\n",
    "\n",
    "References\n",
    "* [1] Sun, Pei, et al., Scalability in Perception for Autonomous Driving: Waymo Open Dataset. arXiv. 2019. [doi: 10.48550/ARXIV.1912.04838](https://arxiv.org/abs/1912.04838).\n",
    "\n",
    "\n",
    "Helpful explanations:\n",
    "* [Training Custom Object Detector by L. Vladimirov | TensorFlow 2 Object Detection API tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
