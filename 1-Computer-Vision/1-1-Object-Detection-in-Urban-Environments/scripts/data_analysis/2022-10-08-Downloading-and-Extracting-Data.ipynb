{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1.1: Object Detection in Urban Environments\n",
    "## Behind the Scenes: Downloading and Extracting Data for Analysis\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be fetching the first 100 `segment` files of the Waymo Open Dataset [1]. The version 1.2 of this dataset is hosted on a private Google Cloud Storage bucket. To request access to the dataset, visit https://waymo.com/open. \n",
    "\n",
    "Each segment is a 20-second long clip of images and corresponding label annotations. Images in this dataset were captured at 10 Hz intervals and are said to cover a diverse set of driving conditions, weather patterns, time-of-day ranges and locations. In their [introduction paper](https://paperswithcode.com/dataset/waymo-open-dataset), Sun et al., claim a total of 1950 segments. In this notebook, we will only be fetching the first 100. Each segment is stored as a `.tfrecord`-formatted file with a serialised data structure described in the corresponding [`dataset.proto`](https://github.com/waymo-research/waymo-open-dataset/blob/master/waymo_open_dataset/dataset.proto) and [`label.proto`](https://github.com/waymo-research/waymo-open-dataset/blob/master/waymo_open_dataset/label.proto). Contained in the segment files are sensor data collected from a multi-camera, multi-sensor rig attached to the ego vehicle (the Waymo Driver). \n",
    "\n",
    "The sensor data includes:\n",
    "* 1 mid-range LiDAR;\n",
    "* 4 short-range LiDAR;\n",
    "* 5 cameras (front and sides);\n",
    "* Synchronised LiDAR and camera data;\n",
    "* Sensor calibrations and vehicle poses.\n",
    "\n",
    "In addition to the sensor data, Waymo also includes ground-truth annotations for a variety of classes covering both LiDAR and camera data.\n",
    "\n",
    "The labelled data includes:\n",
    "* Labels for 4 object classes — _Vehicles_, _Pedestrians_, _Cyclists_, and _Signs_;\n",
    "* High-quality labels for LiDAR data in 1200 segments;\n",
    "* 12,6M 3D bounding box labels with tracking ID:s on LiDAR data;\n",
    "* High-quality labels for camera data in 1000 segments;\n",
    "* 11,8M 2D bounding box labels with tracking ID:s on camera data.\n",
    "\n",
    "In our analysis, we will only be considering the LiDAR (\"`LASER`\") and camera (\"`CAMERA`\") labels. Specifically, in this notebook, we will download and process the first 100 `.tfrecord` files, extract their attribute data (the object counts per-image), and store the results in a Pandas DataFrame. From there, we'll export the data into a CSV file to be used in later analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Installing the APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing the Waymo Open Dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKEhjONUBOAM",
    "outputId": "096bb2ca-8a8a-4f16-8fc9-98bc354a2e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'waymo-od'...\n",
      "remote: Enumerating objects: 1718, done.\u001b[K\n",
      "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
      "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
      "remote: Total 1718 (delta 69), reused 124 (delta 54), pack-reused 1575\u001b[K\n",
      "Receiving objects: 100% (1718/1718), 42.15 MiB | 18.44 MiB/s, done.\n",
      "Resolving deltas: 100% (1088/1088), done.\n",
      "* \u001b[32mmaster\u001b[m\n",
      "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/master\n",
      "  \u001b[31mremotes/origin/master\u001b[m\n",
      "  \u001b[31mremotes/origin/om2\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.0\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.0-tf1.15\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.0-tf2.0\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.2\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.3\u001b[m\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 2.2 MB/s \n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.2 which is incompatible.\n",
      "tensorflow 2.8.2+zzzcolab20220929150707 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.\n",
      "jaxlib 0.3.20+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.\n",
      "jax 0.3.21 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.\n",
      "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.4/564.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.2 which is incompatible.\n",
      "jaxlib 0.3.20+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.\n",
      "jax 0.3.21 requires numpy>=1.20, but you have numpy 1.19.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
    "!cd waymo-od && git branch -a\n",
    "### Installing the Waymo Open Dataset API and dependencies\n",
    "!pip3 install --quiet --upgrade pip\n",
    "!pip3 install --quiet numpy==1.19.2\n",
    "!pip3 install --quiet waymo-open-dataset-tf-2-6-0==1.4.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8ykgJBBmBlXw"
   },
   "outputs": [],
   "source": [
    "#### Importing the TensorFlow and Waymo Open Dataset APIs\n",
    "import google.protobuf\n",
    "import tensorflow as tf\n",
    "import waymo_open_dataset\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V46paMl9EPmn",
    "outputId": "37c579e1-bb50-4df7-d76f-c47c9b1fc738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "--2022-10-08 19:27:47--  https://github.com/bazelbuild/bazel/releases/download/3.1.0/bazel-3.1.0-installer-linux-x86_64.sh\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/8fc26a80-8498-11ea-9e50-7ebe8da61dc0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221008%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221008T192747Z&X-Amz-Expires=300&X-Amz-Signature=3b00714a612a87384b8356009209c3415a54866cad2c88548c4f9bdc4d4a02f6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.1.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-10-08 19:27:47--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/8fc26a80-8498-11ea-9e50-7ebe8da61dc0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221008%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221008T192747Z&X-Amz-Expires=300&X-Amz-Signature=3b00714a612a87384b8356009209c3415a54866cad2c88548c4f9bdc4d4a02f6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.1.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43120099 (41M) [application/octet-stream]\n",
      "Saving to: ‘bazel-3.1.0-installer-linux-x86_64.sh’\n",
      "\n",
      "bazel-3.1.0-install 100%[===================>]  41.12M  16.1MB/s    in 2.5s    \n",
      "\n",
      "2022-10-08 19:27:51 (16.1 MB/s) - ‘bazel-3.1.0-installer-linux-x86_64.sh’ saved [43120099/43120099]\n",
      "\n",
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install --assume-yes pkg-config zip g++ zlib1g-dev unzip python3 python3-pip > /dev/null\n",
    "!wget https://github.com/bazelbuild/bazel/releases/download/3.1.0/bazel-3.1.0-installer-linux-x86_64.sh > /dev/null\n",
    "!sudo bash bazel-3.1.0-installer-linux-x86_64.sh > /dev/null\n",
    "!sudo apt install build-essential > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VM88ylGvEXEH",
    "outputId": "93fc4ded-d229-4f33-fe8a-9609d2b174f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update-alternatives: <link> and <path> can't be the same\n",
      "\n",
      "Use 'update-alternatives --help' for program usage information.\n",
      "Using installed tensorflow\n",
      "2022-10-08 19:28:00.777678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-08 19:28:01.018403: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-08 19:28:02.071425: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:28:02.071568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:28:02.071591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-08 19:28:04.763224: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-08 19:28:04.996167: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-08 19:28:05.989419: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:28:05.989560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:28:05.989584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-08 19:28:08.546037: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-08 19:28:08.763970: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-08 19:28:09.720305: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:28:09.720426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:28:09.720461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "build -c opt\n",
      "build --cxxopt=\"-std=c++11\"\n",
      "build --auto_output_filter=subpackages\n",
      "build --copt=\"-Wall\" --copt=\"-Wno-sign-compare\"\n",
      "build --linkopt=\"-lrt -lm\"\n",
      "build --action_env TF_HEADER_DIR=\"/usr/local/lib/python3.7/dist-packages/tensorflow/include\"\n",
      "build --action_env TF_SHARED_LIBRARY_DIR=\"/usr/local/lib/python3.7/dist-packages/tensorflow\"\n",
      "build --action_env TF_SHARED_LIBRARY_NAME=\"libtensorflow_framework.so.2\"\n",
      "build --action_env TF_NEED_CUDA=\"0\"\n",
      "build:manylinux2010 --crosstool_top=//third_party/toolchains/preconfig/ubuntu16.04/gcc7_manylinux2010-nvcc-cuda10.0:toolchain\n",
      "build --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"\n",
      "Extracting Bazel installation...\n",
      "Starting local Bazel server and connecting to it...\n",
      "WARNING: ignoring LD_PRELOAD in environment.\n",
      "\u001b[32mINFO: \u001b[0mStarting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "### Installing the build requirements via Bazel\n",
    "!cd waymo-od && ./configure.sh && cat .bazelrc && bazel clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing the TensorFlow Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XXc0KqQB3ou",
    "outputId": "ada7d0a0-670c-449b-cc04-6f7adcbb01b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.10.0 requires grpcio<2.0,>=1.24.3, but you have grpcio 1.18.0 which is incompatible.\n",
      "tensorboard 2.10.1 requires grpcio>=1.24.3, but you have grpcio 1.18.0 which is incompatible.\n",
      "apache-beam 2.41.0 requires grpcio<2,>=1.33.1, but you have grpcio 1.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "protobuf-compiler 1.0.20 requires grpcio==1.18.0, but you have grpcio 1.49.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m2022-10-08 19:30:05.281959: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-08 19:30:05.510381: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-08 19:30:06.482674: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:30:06.482789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-08 19:30:06.482807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-08 19:30:10.274225: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-08 19:30:10.274298: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (417171e71857): /proc/driver/nvidia/version does not exist\n",
      "Running tests under Python 3.7.14: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-10-08 19:30:10.307100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "W1008 19:30:10.960133 139823812429696 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.95s\n",
      "I1008 19:30:11.253104 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.95s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.61s\n",
      "I1008 19:30:11.863774 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.61s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
      "I1008 19:30:12.168359 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.3s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
      "I1008 19:30:12.597525 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.8s\n",
      "I1008 19:30:15.402761 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.8s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I1008 19:30:15.408079 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n",
      "I1008 19:30:15.459747 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "I1008 19:30:15.480257 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I1008 19:30:15.501917 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
      "I1008 19:30:15.630331 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
      "I1008 19:30:15.748347 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
      "I1008 19:30:15.878227 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
      "I1008 19:30:16.003126 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
      "I1008 19:30:16.122145 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
      "I1008 19:30:16.158217 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I1008 19:30:16.368451 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1008 19:30:16.368654 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
      "I1008 19:30:16.368715 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
      "I1008 19:30:16.371722 139823812429696 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1008 19:30:16.405777 139823812429696 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1008 19:30:16.405968 139823812429696 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1008 19:30:16.506793 139823812429696 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1008 19:30:16.506991 139823812429696 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1008 19:30:16.777288 139823812429696 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1008 19:30:16.777534 139823812429696 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1008 19:30:17.031949 139823812429696 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1008 19:30:17.032167 139823812429696 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1008 19:30:17.414129 139823812429696 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1008 19:30:17.414397 139823812429696 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1008 19:30:17.991401 139823812429696 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1008 19:30:17.991657 139823812429696 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1008 19:30:18.526688 139823812429696 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1008 19:30:18.526901 139823812429696 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1008 19:30:18.663567 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1008 19:30:18.740776 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1008 19:30:18.807472 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I1008 19:30:18.807681 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
      "I1008 19:30:18.807742 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
      "I1008 19:30:18.809633 139823812429696 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1008 19:30:18.832256 139823812429696 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1008 19:30:18.832465 139823812429696 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1008 19:30:19.031867 139823812429696 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1008 19:30:19.032076 139823812429696 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1008 19:30:19.364787 139823812429696 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1008 19:30:19.364999 139823812429696 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1008 19:30:19.712328 139823812429696 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1008 19:30:19.712545 139823812429696 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1008 19:30:20.175518 139823812429696 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1008 19:30:20.175717 139823812429696 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1008 19:30:20.647477 139823812429696 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1008 19:30:20.647697 139823812429696 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1008 19:30:21.302872 139823812429696 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1008 19:30:21.303075 139823812429696 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1008 19:30:21.612738 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1008 19:30:21.681915 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1008 19:30:21.754117 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I1008 19:30:21.754315 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
      "I1008 19:30:21.754376 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
      "I1008 19:30:21.756242 139823812429696 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1008 19:30:21.778774 139823812429696 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1008 19:30:21.778966 139823812429696 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1008 19:30:21.967061 139823812429696 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1008 19:30:21.967275 139823812429696 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1008 19:30:22.303484 139823812429696 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1008 19:30:22.303711 139823812429696 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1008 19:30:22.693709 139823812429696 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1008 19:30:22.693918 139823812429696 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1008 19:30:23.183279 139823812429696 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1008 19:30:23.183507 139823812429696 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1008 19:30:23.681112 139823812429696 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1008 19:30:23.681333 139823812429696 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1008 19:30:24.364477 139823812429696 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1008 19:30:24.364687 139823812429696 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I1008 19:30:24.692655 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I1008 19:30:24.772550 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1008 19:30:24.844455 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I1008 19:30:24.844659 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
      "I1008 19:30:24.844748 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
      "I1008 19:30:24.846719 139823812429696 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1008 19:30:24.870955 139823812429696 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1008 19:30:24.871169 139823812429696 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1008 19:30:25.080686 139823812429696 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1008 19:30:25.080904 139823812429696 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1008 19:30:25.428336 139823812429696 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1008 19:30:25.428576 139823812429696 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1008 19:30:26.045211 139823812429696 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1008 19:30:26.045420 139823812429696 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1008 19:30:26.639241 139823812429696 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1008 19:30:26.639467 139823812429696 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1008 19:30:27.284405 139823812429696 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1008 19:30:27.284649 139823812429696 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1008 19:30:28.140938 139823812429696 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1008 19:30:28.141177 139823812429696 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I1008 19:30:28.480216 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I1008 19:30:28.560017 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1008 19:30:28.641209 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I1008 19:30:28.641407 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
      "I1008 19:30:28.641484 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
      "I1008 19:30:28.643361 139823812429696 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1008 19:30:28.668844 139823812429696 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1008 19:30:28.669056 139823812429696 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1008 19:30:28.857034 139823812429696 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1008 19:30:28.857256 139823812429696 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1008 19:30:29.336726 139823812429696 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1008 19:30:29.336939 139823812429696 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1008 19:30:29.815416 139823812429696 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1008 19:30:29.815645 139823812429696 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1008 19:30:30.561318 139823812429696 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1008 19:30:30.561686 139823812429696 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1008 19:30:31.337173 139823812429696 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1008 19:30:31.337391 139823812429696 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1008 19:30:32.502985 139823812429696 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1008 19:30:32.503208 139823812429696 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I1008 19:30:32.885576 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I1008 19:30:32.993621 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1008 19:30:33.087080 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I1008 19:30:33.087292 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
      "I1008 19:30:33.087358 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
      "I1008 19:30:33.089319 139823812429696 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1008 19:30:33.112282 139823812429696 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1008 19:30:33.112520 139823812429696 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1008 19:30:33.396812 139823812429696 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1008 19:30:33.397015 139823812429696 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1008 19:30:33.989096 139823812429696 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1008 19:30:33.989324 139823812429696 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1008 19:30:34.606757 139823812429696 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1008 19:30:34.606993 139823812429696 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1008 19:30:35.752273 139823812429696 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1008 19:30:35.752503 139823812429696 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1008 19:30:36.719990 139823812429696 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1008 19:30:36.720195 139823812429696 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1008 19:30:38.114405 139823812429696 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1008 19:30:38.114651 139823812429696 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I1008 19:30:38.751184 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I1008 19:30:38.859666 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1008 19:30:38.967232 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I1008 19:30:38.967452 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I1008 19:30:38.967522 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
      "I1008 19:30:38.969531 139823812429696 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1008 19:30:39.000709 139823812429696 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1008 19:30:39.000984 139823812429696 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1008 19:30:39.304348 139823812429696 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1008 19:30:39.304624 139823812429696 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1008 19:30:40.025875 139823812429696 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1008 19:30:40.026098 139823812429696 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1008 19:30:40.766170 139823812429696 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1008 19:30:40.766390 139823812429696 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1008 19:30:41.784310 139823812429696 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1008 19:30:41.784558 139823812429696 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1008 19:30:42.865808 139823812429696 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1008 19:30:42.866035 139823812429696 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1008 19:30:44.704335 139823812429696 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1008 19:30:44.704565 139823812429696 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I1008 19:30:45.396022 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I1008 19:30:45.523725 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1008 19:30:45.647459 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I1008 19:30:45.647663 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
      "I1008 19:30:45.647725 139823812429696 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
      "I1008 19:30:45.649632 139823812429696 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1008 19:30:45.675410 139823812429696 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1008 19:30:45.676044 139823812429696 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1008 19:30:46.049476 139823812429696 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1008 19:30:46.049687 139823812429696 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1008 19:30:47.201895 139823812429696 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1008 19:30:47.202127 139823812429696 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1008 19:30:48.028350 139823812429696 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1008 19:30:48.028599 139823812429696 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1008 19:30:49.292903 139823812429696 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1008 19:30:49.293112 139823812429696 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1008 19:30:50.681558 139823812429696 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1008 19:30:50.681756 139823812429696 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1008 19:30:52.893824 139823812429696 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1008 19:30:52.894031 139823812429696 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I1008 19:30:53.909132 139823812429696 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I1008 19:30:54.038281 139823812429696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 38.02s\n",
      "I1008 19:30:54.183528 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 38.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I1008 19:30:54.213953 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I1008 19:30:54.216107 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I1008 19:30:54.216989 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I1008 19:30:54.219199 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I1008 19:30:54.220669 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I1008 19:30:54.221117 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I1008 19:30:54.222162 139823812429696 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 43.927s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "### Fetching the TF models/research/object_detection subdirectory\n",
    "!apt install subversion > /dev/null\n",
    "!svn checkout -q https://github.com/tensorflow/models/trunk/research/object_detection\n",
    "!pip install protobuf > /dev/null\n",
    "### Compiling the protobufs\n",
    "!pip install protobuf-compiler > /dev/null\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "### Installing the COCO API dependency\n",
    "!pip install cython > /dev/null\n",
    "!pip install pycocotools > /dev/null\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!pip install . > /dev/null\n",
    "### Verifying installation was successful\n",
    "!python3 object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLPHSatDE4Hf",
    "outputId": "31cd7723-4534-464f-9e68-324af52b8cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
      "tf-models-official 2.10.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
      "tf-models-official 2.10.0 requires tensorflow~=2.10.0, but you have tensorflow 2.6.0+zzzcolab20220506153740 which is incompatible.\n",
      "tensorflow-text 2.10.0 requires tensorflow<2.11,>=2.10.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.6.0+zzzcolab20220506153740 which is incompatible.\n",
      "spacy 3.4.1 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
      "prophet 1.1.1 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\n",
      "jaxlib 0.3.20+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
      "jax 0.3.21 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
      "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "### Patching tensorflow install to Waymo OD-compatible version (2.6.0)\n",
    "!pip install waymo-open-dataset-tf-2-6-0==1.4.9 > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Downloading and Extracting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4H_dyTJvCIE6"
   },
   "outputs": [],
   "source": [
    "### Import the Waymo OD and TFDS Object Detection API utils\n",
    "import tensorflow as tf\n",
    "import google.protobuf\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "from waymo_open_dataset import dataset_pb2, label_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the `.tfrecord` files from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Authenticating with Google Cloud API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sEy067rBCqip"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From J. Moran's `download_and_process.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "diqRhFXrCZnB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def download_tfr(file_path: str, data_dir: str) -> str:\n",
    "    \"\"\"Download a single `.tfrecord` with `gsutil`.\n",
    "\n",
    "    :param file_path: str, remote path to the `.tfrecord` file,\n",
    "        this should start with 'gs://' and include the bucket name.\n",
    "    :param data_dir: str, the local path to the destination directory.\n",
    "    returns: local_path (str): the absolute path to where the file is saved.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Get the file name from the absolute path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    ### Create the output directory\n",
    "    dest = os.path.join(data_dir, 'raw')\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "    ### Download the `.tfrecord` file from GCS\n",
    "    cmd = ['gsutil', 'cp', file_path, f'{dest}']\n",
    "    print(f'Downloading {file_name}')\n",
    "    res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    if res.returncode != 0:\n",
    "        print(f'Could not download {file_path}')\n",
    "    ### Define aboslute path to the downloaded `.tfrecord` file\n",
    "    local_path = os.path.join(dest, file_name)\n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the object counts and scene attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From J. Moran's `download_and_extract.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Oi34G0EYCM1p"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import waymo_open_dataset\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def extract_frame_data(\n",
    "    fname: str,\n",
    "    frame: waymo_open_dataset.dataset_pb2.Frame,\n",
    "    use_laser_counts=False\n",
    ") -> dict:\n",
    "    \"\"\"Extracts the attribute data from a single Frame instance.  \n",
    "\n",
    "    :param frame: the Waymo Open Dataset `Frame` instance.\n",
    "    :param use_laser_counts: bool (optional), if True, the `laser_object_counts`\n",
    "        are retrieved from `frame.context.stats`. Otherwise, \n",
    "        `camera_object_counts` are retrieved.\n",
    "    :returns: attr_dict, the dict instance populated with the data from `frame`.\n",
    "    \"\"\"\n",
    "\n",
    "    def object_type_name(x: int):\n",
    "        \"\"\"Returns the string class label mapping to the input class id.\"\"\"\n",
    "        return label_pb2.Label.Type.Name(x)\n",
    "\n",
    "    ### Fetching the scene attributes in `context.stats`\n",
    "    attr_dict = {\n",
    "        'segment': fname,\n",
    "        'name': frame.context.name,\n",
    "        'time_of_day': frame.context.stats.time_of_day,\n",
    "        'location': frame.context.stats.location,\n",
    "        'weather': frame.context.stats.weather\n",
    "    }\n",
    "    '''\n",
    "    ### Get the object counts\n",
    "    if use_laser_counts:\n",
    "        attr_dict.update({\n",
    "            object_type_name(x.type): x.count for x in frame.context.stats.laser_object_counts\n",
    "    })\n",
    "    else:\n",
    "        attr_dict.update({\n",
    "            object_type_name(x.type): x.count for x in frame.context.stats.camera_object_counts\n",
    "    })\n",
    "    '''\n",
    "    ### Get the object counts\n",
    "    attr_dict.update({\n",
    "        f\"{object_type_name(x.type)}_LASER\": x.count for x in frame.context.stats.laser_object_counts\n",
    "    })\n",
    "    attr_dict.update({\n",
    "        f\"{object_type_name(x.type)}_CAMERA\": x.count for x in frame.context.stats.camera_object_counts\n",
    "    })\n",
    "    return attr_dict\n",
    "\n",
    "\n",
    "def process_tfrs(\n",
    "    filename_paths: List[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Creates a TFRecordDataset and extracts the attribute data.\n",
    "\n",
    "    :param filename_paths: list of local paths to the downloaded records.\n",
    "    :returns: df_frame, a Pandas DataFrame of all extracted attribute data.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Create a DataFrame instance to store all frame data\n",
    "    df_frames = pd.DataFrame()    # All frames\n",
    "    for fn_path in filename_paths:\n",
    "        fname = os.path.basename(fn_path)\n",
    "        df_frame = pd.DataFrame()     # This frame\n",
    "        i = 0   # data counter\n",
    "        dataset = tf.data.TFRecordDataset(fn_path, compression_type='')\n",
    "        for data in dataset:\n",
    "            if i == 0:\n",
    "                print(f'Processing {fname}')\n",
    "            frame = open_dataset.Frame()\n",
    "            frame.ParseFromString(bytearray(data.numpy()))\n",
    "            frame_data = extract_frame_data(fname, frame)\n",
    "            df_frame = df_frame.append(frame_data, ignore_index=True)\n",
    "            df_frames = df_frames.append(frame_data, ignore_index=True)\n",
    "            i += 1\n",
    "        ### Save csv of each record\n",
    "        df_frame.to_csv(os.path.join(DIR_OUT, f'{fname}.csv'))\n",
    "    return df_frames\n",
    "\n",
    "\n",
    "def download_and_process(path_to_filenames: str, data_dir: str, delete_records=False):\n",
    "    \"\"\"Downloads the requested files and converts them to TF-compatible format.\n",
    "\n",
    "    :param path_to_filenames: the file path of the text file containing all `.tfrecord` \n",
    "        files to download from GCS. This should be a list of strings starting with\n",
    "        'gs://'. The file paths should also include the bucket name.\n",
    "    :param data_dir: the path to the local directory to store the downloaded files.\n",
    "    :param delete_records: bool (optional), flag to remove the downloaded `.tfrecords` from \n",
    "        the local drive if True.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Opening the list of file paths to download from GCS with gsutil\n",
    "    with open(path_to_filenames, 'r') as f:\n",
    "        filename_paths = f.read().splitlines()\n",
    "    ### Restricting the number of files to download from list\n",
    "    ### NOTE: must change the slicing range to fit your needs\n",
    "    filename_paths = filename_paths[81:SIZE]\n",
    "    print(f'Downloading {len(filename_paths)} files. Be patient, this will take a long time.')\n",
    "    ### List of all local file paths of the downloaded `.tfrecord` files\n",
    "    local_paths = []\n",
    "    for fn_path in filename_paths:\n",
    "        dest = os.path.join(data_dir, 'raw')\n",
    "        local_path = os.path.join(dest, os.path.basename(fn_path))\n",
    "        if not os.path.exists(local_path):\n",
    "            local_path = download_tfr(fn_path, data_dir)\n",
    "            local_paths.append(local_path)\n",
    "        else:\n",
    "            local_paths.append(local_path)\n",
    "    ### Process the `.tfrecord` files and return their attribute data as a DataFrame\n",
    "    df_frames = process_tfrs(local_paths)\n",
    "    ### Delete the original `.tfrecord` files to save space\n",
    "    if delete_records:\n",
    "        for local_path in local_paths:\n",
    "            print(f'Deleting {local_path}')\n",
    "            os.remove(local_path)\n",
    "    return df_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "aTB05QUhD8FJ"
   },
   "outputs": [],
   "source": [
    "### Path to the text file containing the GCS file paths of all records to download\n",
    "filenames = '/content/data/waymo_open_dataset/filenames.txt'\n",
    "### Number of records to download from the list (see `download_and_process()` for info)\n",
    "SIZE = 101\n",
    "### Path to store the downloaded (\"raw\") `.tfrecord` files\n",
    "DEST = os.path.join('/content/data/waymo_open_dataset', 'downloaded')\n",
    "os.makedirs(DEST, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "S6k1tvFVJXUB"
   },
   "outputs": [],
   "source": [
    "### Path to store the processed `.csv` file data\n",
    "DIR_OUT = '/content/out/'\n",
    "os.makedirs(DIR_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wV506J8xD_kF",
    "outputId": "99ea7a50-0978-4b47-9d3d-cb50a4d82d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 20 files. Be patient, this will take a long time.\n",
      "Downloading segment-1172406780360799916_1660_000_1680_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11799592541704458019_9828_750_9848_750_with_camera_labels.tfrecord\n",
      "Downloading segment-11839652018869852123_2565_000_2585_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11846396154240966170_3540_000_3560_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11847506886204460250_1640_000_1660_000_with_camera_labels.tfrecord\n",
      "Downloading segment-1191788760630624072_3880_000_3900_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11918003324473417938_1400_000_1420_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11925224148023145510_1040_000_1060_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11928449532664718059_1200_000_1220_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11940460932056521663_1760_000_1780_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11967272535264406807_580_000_600_000_with_camera_labels.tfrecord\n",
      "Downloading segment-11971497357570544465_1200_000_1220_000_with_camera_labels.tfrecord\n",
      "Downloading segment-12012663867578114640_820_000_840_000_with_camera_labels.tfrecord\n",
      "Downloading segment-12027892938363296829_4086_280_4106_280_with_camera_labels.tfrecord\n",
      "Downloading segment-1208303279778032257_1360_000_1380_000_with_camera_labels.tfrecord\n",
      "Downloading segment-12161824480686739258_1813_380_1833_380_with_camera_labels.tfrecord\n",
      "Downloading segment-12174529769287588121_3848_440_3868_440_with_camera_labels.tfrecord\n",
      "Downloading segment-12179768245749640056_5561_070_5581_070_with_camera_labels.tfrecord\n",
      "Downloading segment-12200383401366682847_2552_140_2572_140_with_camera_labels.tfrecord\n",
      "Downloading segment-12208410199966712301_4480_000_4500_000_with_camera_labels.tfrecord\n",
      "Processing segment-1172406780360799916_1660_000_1680_000_with_camera_labels.tfrecord\n",
      "Processing segment-11799592541704458019_9828_750_9848_750_with_camera_labels.tfrecord\n",
      "Processing segment-11839652018869852123_2565_000_2585_000_with_camera_labels.tfrecord\n",
      "Processing segment-11846396154240966170_3540_000_3560_000_with_camera_labels.tfrecord\n",
      "Processing segment-11847506886204460250_1640_000_1660_000_with_camera_labels.tfrecord\n",
      "Processing segment-1191788760630624072_3880_000_3900_000_with_camera_labels.tfrecord\n",
      "Processing segment-11918003324473417938_1400_000_1420_000_with_camera_labels.tfrecord\n",
      "Processing segment-11925224148023145510_1040_000_1060_000_with_camera_labels.tfrecord\n",
      "Processing segment-11928449532664718059_1200_000_1220_000_with_camera_labels.tfrecord\n",
      "Processing segment-11940460932056521663_1760_000_1780_000_with_camera_labels.tfrecord\n",
      "Processing segment-11967272535264406807_580_000_600_000_with_camera_labels.tfrecord\n",
      "Processing segment-11971497357570544465_1200_000_1220_000_with_camera_labels.tfrecord\n",
      "Processing segment-12012663867578114640_820_000_840_000_with_camera_labels.tfrecord\n",
      "Processing segment-12027892938363296829_4086_280_4106_280_with_camera_labels.tfrecord\n",
      "Processing segment-1208303279778032257_1360_000_1380_000_with_camera_labels.tfrecord\n",
      "Processing segment-12161824480686739258_1813_380_1833_380_with_camera_labels.tfrecord\n",
      "Processing segment-12174529769287588121_3848_440_3868_440_with_camera_labels.tfrecord\n",
      "Processing segment-12179768245749640056_5561_070_5581_070_with_camera_labels.tfrecord\n",
      "Processing segment-12200383401366682847_2552_140_2572_140_with_camera_labels.tfrecord\n",
      "Processing segment-12208410199966712301_4480_000_4500_000_with_camera_labels.tfrecord\n"
     ]
    }
   ],
   "source": [
    "### Downloading and extracting data from the last 20 files in list\n",
    "### Returns a Pandas DataFrame containing the extracted data\n",
    "df = download_and_process(filenames, DEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "udMUUVlhJEvA"
   },
   "outputs": [],
   "source": [
    "### Saving the DataFrame as a `.csv` file\n",
    "df.to_csv(os.path.join(DIR_OUT, 'waymo_data_81_to_100.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "OB_xRHa5xO8z"
   },
   "outputs": [],
   "source": [
    "### Getting the local file paths to the batch of downloaded records\n",
    "with open(filenames, 'r') as f:\n",
    "    filename_paths = f.read().splitlines()\n",
    "    filename_paths = filename_paths[51:81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEg7Smz9xDy0",
    "outputId": "d4b475e1-92f5-4334-da1c-095159882589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-10975280749486260148_940_000_960_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11004685739714500220_2300_000_2320_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11017034898130016754_697_830_717_830_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11060291335850384275_3761_210_3781_210_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11070802577416161387_740_000_760_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11076364019363412893_1711_000_1731_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11113047206980595400_2560_000_2580_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11119453952284076633_1369_940_1389_940_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11126313430116606120_1439_990_1459_990_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11139647661584646830_5470_000_5490_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11183906854663518829_2294_000_2314_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11199484219241918646_2810_030_2830_030_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11219370372259322863_5320_000_5340_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11236550977973464715_3620_000_3640_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11252086830380107152_1540_000_1560_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11318901554551149504_520_000_540_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11343624116265195592_5910_530_5930_530_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11355519273066561009_5323_000_5343_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11379226583756500423_6230_810_6250_810_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11388947676680954806_5427_320_5447_320_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11392401368700458296_1086_429_1106_429_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11454085070345530663_1905_000_1925_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-1146261869236413282_1680_000_1700_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11486225968269855324_92_000_112_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11489533038039664633_4820_000_4840_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11566385337103696871_5740_000_5760_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11588853832866011756_2184_462_2204_462_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11623618970700582562_2840_367_2860_367_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11674150664140226235_680_000_700_000_with_camera_labels.tfrecord\n",
      "Deleting /content/data/waymo_open_dataset/downloaded/raw/segment-11718898130355901268_2300_000_2320_000_with_camera_labels.tfrecord\n"
     ]
    }
   ],
   "source": [
    "### Deleting the requested batch of downloaded records\n",
    "dest = os.path.join(DEST, 'raw')\n",
    "for fn_path in filename_paths:\n",
    "    local_path = os.path.join(dest, os.path.basename(fn_path))\n",
    "    print(f'Deleting {local_path}')\n",
    "    os.remove(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kwWUp-x7zJY",
    "outputId": "544681e2-a53d-4a07-fdd7-7a0244da54db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/out/ (stored 0%)\n",
      "  adding: content/out/segment-11252086830380107152_1540_000_1560_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11925224148023145510_1040_000_1060_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-11847506886204460250_1640_000_1660_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10517728057304349900_3360_000_3380_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10940952441434390507_1888_710_1908_710_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11355519273066561009_5323_000_5343_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10793018113277660068_2714_540_2734_540_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10923963890428322967_1445_000_1465_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-12174529769287588121_3848_440_3868_440_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-10391312872392849784_4099_400_4119_400_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11388947676680954806_5427_320_5447_320_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-11076364019363412893_1711_000_1731_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10964956617027590844_1584_680_1604_680_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10231929575853664160_1160_000_1180_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-10724020115992582208_7660_400_7680_400_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10212406498497081993_5300_000_5320_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10107710434105775874_760_000_780_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/waymo_data_21_to_50.csv (deflated 97%)\n",
      "  adding: content/out/segment-1191788760630624072_3880_000_3900_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11318901554551149504_520_000_540_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11379226583756500423_6230_810_6250_810_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11486225968269855324_92_000_112_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-11060291335850384275_3761_210_3781_210_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11674150664140226235_680_000_700_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11219370372259322863_5320_000_5340_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11967272535264406807_580_000_600_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-1146261869236413282_1680_000_1700_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-11566385337103696871_5740_000_5760_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11454085070345530663_1905_000_1925_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11126313430116606120_1439_990_1459_990_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10444454289801298640_4360_000_4380_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-11918003324473417938_1400_000_1420_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11113047206980595400_2560_000_2580_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10588771936253546636_2300_000_2320_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10526338824408452410_5714_660_5734_660_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10226164909075980558_180_000_200_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-11839652018869852123_2565_000_2585_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-12179768245749640056_5561_070_5581_070_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-12027892938363296829_4086_280_4106_280_with_camera_labels.tfrecord.csv (deflated 94%)\n",
      "  adding: content/out/segment-11846396154240966170_3540_000_3560_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11588853832866011756_2184_462_2204_462_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10676267326664322837_311_180_331_180_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10723911392655396041_860_000_880_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-11799592541704458019_9828_750_9848_750_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10876852935525353526_1640_000_1660_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10327752107000040525_1120_000_1140_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11940460932056521663_1760_000_1780_000_with_camera_labels.tfrecord.csv (deflated 94%)\n",
      "  adding: content/out/segment-10206293520369375008_2796_800_2816_800_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11183906854663518829_2294_000_2314_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10770759614217273359_1465_000_1485_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10096619443888687526_2820_000_2840_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/waymo_data_81_to_100.csv (deflated 96%)\n",
      "  adding: content/out/waymo_data_51_to_80.csv (deflated 97%)\n",
      "  adding: content/out/segment-1172406780360799916_1660_000_1680_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10153695247769592104_787_000_807_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10500357041547037089_1474_800_1494_800_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11489533038039664633_4820_000_4840_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-12208410199966712301_4480_000_4500_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10750135302241325253_180_000_200_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11718898130355901268_2300_000_2320_000_with_camera_labels.tfrecord.csv (deflated 94%)\n",
      "  adding: content/out/segment-11070802577416161387_740_000_760_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10786629299947667143_3440_000_3460_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10584247114982259878_490_000_510_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10498013744573185290_1240_000_1260_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-10927752430968246422_4940_000_4960_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11392401368700458296_1086_429_1106_429_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11971497357570544465_1200_000_1220_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11139647661584646830_5470_000_5490_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10082223140073588526_6140_000_6160_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11199484219241918646_2810_030_2830_030_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10072231702153043603_5725_000_5745_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11004685739714500220_2300_000_2320_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10023947602400723454_1120_000_1140_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/waymo_data_1_to_20.csv (deflated 97%)\n",
      "  adding: content/out/segment-11236550977973464715_3620_000_3640_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-10734565072045778791_440_000_460_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10599748131695282446_1380_000_1400_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10075870402459732738_1060_000_1080_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11017034898130016754_697_830_717_830_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10455472356147194054_1560_000_1580_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11119453952284076633_1369_940_1389_940_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/waymo_data.csv (deflated 89%)\n",
      "  adding: content/out/segment-1208303279778032257_1360_000_1380_000_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-11343624116265195592_5910_530_5930_530_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-12161824480686739258_1813_380_1833_380_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10975280749486260148_940_000_960_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11623618970700582562_2840_367_2860_367_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-1022527355599519580_4866_960_4886_960_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-10241508783381919015_2889_360_2909_360_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10275144660749673822_5755_561_5775_561_with_camera_labels.tfrecord.csv (deflated 97%)\n",
      "  adding: content/out/segment-10664823084372323928_4360_000_4380_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-1083056852838271990_4080_000_4100_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-11928449532664718059_1200_000_1220_000_with_camera_labels.tfrecord.csv (deflated 94%)\n",
      "  adding: content/out/segment-10485926982439064520_4980_000_5000_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10235335145367115211_5420_000_5440_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-10963653239323173269_1924_000_1944_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-10625026498155904401_200_000_220_000_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-12012663867578114640_820_000_840_000_with_camera_labels.tfrecord.csv (deflated 96%)\n",
      "  adding: content/out/segment-10596949720463106554_1933_530_1953_530_with_camera_labels.tfrecord.csv (deflated 95%)\n",
      "  adding: content/out/segment-12200383401366682847_2552_140_2572_140_with_camera_labels.tfrecord.csv (deflated 97%)\n"
     ]
    }
   ],
   "source": [
    "### Zipping the `.csv` files for easy export from Google Colab\n",
    "!zip -9 -r '/content/zipped/out.zip' '/content/out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concatenating all batched data into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "        map(pd.read_csv, ['/content/out/waymo_data_1_to_20.csv', \n",
    "                          '/content/out/waymo_data_21_to_50.csv',\n",
    "                          '/content/out/waymo_data_51_to_80.csv',\n",
    "                          '/content/out/waymo_data_81_to_100.csv'\n",
    "                         ]\n",
    "            ), ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exporting the DataFrame as a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/content/out/waymo_object_counts_data_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySULZ-aK70tc"
   },
   "source": [
    "## 3. Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extensions of task\n",
    "* Use [`ray`](https://www.ray.io) to scale the `download_and_process()` method across workers/CPU cores with [`ray.remote()`](https://docs.ray.io/en/latest/ray-core/package-ref.html#ray-remote) and [`ray.get()`](https://docs.ray.io/en/latest/ray-core/package-ref.html#ray-get);\n",
    "* Fetch more records (~800 to choose from in the v1.2 bucket).\n",
    "\n",
    "##### Alternatives\n",
    "* Parse annotation data (e.g., 3D coordinates, bounding box annotation dimensions, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ⬜️ Use the collected `.csv` files for analyses (e.g., class label distributions, time-of-day/location distributions, etc.); \n",
    "- ⬜️ Scale the `download_and_process` function to multiple workers or use with [Cloud TPU API](https://cloud.google.com/tpu/docs/reference/rest);\n",
    "- ⬜️ Integrate into data processing pipeline in a production setting (on entire Perception dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment was prepared by Jonathan Moran for the Udacity Self-Driving Car Engineer Nanodegree programme (link [here](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)).\n",
    "\n",
    "\n",
    "References\n",
    "* [1] Sun, Pei, et al. Scalability in perception for autonomous driving: Waymo Open Dataset. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2446-2454. 2020. [doi:10.48550/arXiv.1912.04838](https://arxiv.org/abs/1912.04838).\n",
    "\n",
    "\n",
    "Helpful resources:\n",
    "* [TensorFlow Object Detection API Installation | TensorFlow 2 Object Detection API tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tensorflow-object-detection-api-installation);\n",
    "* [Exploring the Waymo Open Dataset by K. Shulz (@kittyshulz) | GitHub](https://github.com/kittyschulz/Exploring-Waymo-Open-Dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
