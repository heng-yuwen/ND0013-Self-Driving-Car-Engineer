{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba9157f",
   "metadata": {},
   "source": [
    "# Exercise 1.4.1 - Pooling Layers in CNNs\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8d3fc",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b85daa",
   "metadata": {},
   "source": [
    "* Implement a simplified version of the Pooling layer using Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171f836",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa352df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479ca8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b589b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4474daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_COLAB = False                # True if running in Google Colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94fd4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory\n",
    "DIR_BASE = '' if not ENV_COLAB else '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85723c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subdirectory to save output files\n",
    "DIR_OUT = os.path.join(DIR_BASE, 'out/')\n",
    "# Subdirectory pointing to input data\n",
    "DIR_SRC = os.path.join(DIR_BASE, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c882d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating subdirectories (if not exists)\n",
    "os.makedirs(DIR_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430867e",
   "metadata": {},
   "source": [
    "### 1.1. Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749cc023",
   "metadata": {},
   "source": [
    "#### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be777cb1",
   "metadata": {},
   "source": [
    "_Pooling layers_ are fundamental building blocks in [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) architectures. These intermediate layers are used in CNNs to reduce the dimentionality of input data. Pooling layers function by aggregating an input's spatial information in a process akin to [downsampling](https://en.wikipedia.org/wiki/Downsampling_\\(signal_processing\\)). By reducing the dimensionality of the input data, pooling layers help mitigate kernel sensitivity to granular features (finer details). As the input data is aggregated and its area reduced in size, the convolution kernels of a predefined size are able to cover a larger subregion within the input.\n",
    "\n",
    "Pooling layers, like their convolutional counterparts, operate over an input using a sliding-window approach. Because of this, pooling layers share several parameters â€” a _window size_ (the height, width dimensions of the _pooling window_) and a _stride_ amount (number of pixels to shift the centre of the sliding window on each iteration). These hyperparameters allow practitioners to control how much spatial resolution to reduce from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3347587",
   "metadata": {},
   "source": [
    "![Fig. 1. The sliding window technique used to compute the pooling layer output.](figures/2022-09-07-Figure-1-Sliding-Window-Technique.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739e65f",
   "metadata": {},
   "source": [
    "$$\\textrm{Fig. 1. The sliding window technique for a 4x4 kernel with a stride length of 3.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10535452",
   "metadata": {},
   "source": [
    "One key difference between pooling layers and other types of convolutional layers is that the pooling layers contain _zero trainable parameters_. Therefore, pooling layers help downsample input data without introducing significant complexity to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f400d",
   "metadata": {},
   "source": [
    "#### Types of Pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a36c0",
   "metadata": {},
   "source": [
    "Suppose we have an input matrix $X$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X = \n",
    "    \\begin{bmatrix}\n",
    "        0 & 1 & 2 \\\\\n",
    "        3 & 4 & 5 \\\\\n",
    "        6 & 7 & 8 \\\\\n",
    "    \\end{bmatrix} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In order to calculate the kernel dimensions, we need to first know the dimensions of our input. From inspection we see that $X$ is a 2D matrix with the following dimensions: a width of $3$, a height of $3$ and a depth of $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716154a6",
   "metadata": {},
   "source": [
    "We can select a kernel/filter with dimensions $\\left(\\mathrm{f}_{\\mathrm{w}}, \\ \\mathrm{f}_{\\mathrm{h}}, \\ \\mathrm{d}_{0}\\right)$ using the following equations defined in terms of input dimensions $\\left(\\mathrm{w}_{0}, \\ \\mathrm{h}_{0}, \\ \\mathrm{d}_{0}\\right)$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathrm{w}_{\\mathrm{output}} &= \\frac{\\mathrm{w}_{0} - \\mathrm{f}_{\\mathrm{w}} + 2*p}{s} + 1, \\\\\n",
    "    \\\n",
    "    \\mathrm{h}_{\\mathrm{output}} &= \\frac{\\mathrm{h}_{0} - \\mathrm{f}_{\\mathrm{h}} + 2*p}{s} + 1. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In the formulas above we have several hyperparameters available to the practitioner to modify: the filter size, $\\mathrm{f}$, the padding amount, $\\mathrm{p}$ (discussed below), and stride length $\\mathrm{s}$. The filter depth, $\\mathrm{d}_{\\mathrm{kernel}}$, is the only fixed parameter and its value is equal to the depth $\\mathrm{d}_{0}$ of the input . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fd26ab",
   "metadata": {},
   "source": [
    "In the following examples, we will use a kernel of dimensions $\\left(\\mathrm{w}_{\\mathrm{kernel}} x \\ \\mathrm{h}_{\\mathrm{kernel}} x \\ \\mathrm{d}_{\\mathrm{kernel}}\\right) = \\left(2 x 2 x 1\\right)$. We will also select a stride length $s = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e8a9e7",
   "metadata": {},
   "source": [
    "##### The Max Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44963d48",
   "metadata": {},
   "source": [
    "Rather than subsampling an input image by selecting e.g., every other pixel value, we can choose the _maximum_ value over a set of adjacent pixels in the kernel window.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X^{\\prime} &= \n",
    "    \\begin{bmatrix}\n",
    "        max\n",
    "        \\begin{pmatrix}\n",
    "        0 & 1 \\\\\n",
    "        3 & 4 \\\\\n",
    "        \\end{pmatrix} \n",
    "        &\n",
    "        max\n",
    "        \\begin{pmatrix}\n",
    "        1 & 2 \\\\\n",
    "        4 & 5 \\\\\n",
    "        \\end{pmatrix}\n",
    "        \\\\\n",
    "        max\n",
    "        \\begin{pmatrix}\n",
    "        3 & 4 \\\\\n",
    "        6 & 7 \\\\\n",
    "        \\end{pmatrix}\n",
    "        &\n",
    "        max\n",
    "        \\begin{pmatrix}\n",
    "        4 & 5 \\\\\n",
    "        7 & 8 \\\\\n",
    "        \\end{pmatrix}\n",
    "    \\end{bmatrix}. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Therefore we obtain the output matrix\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X^{\\prime} &= \n",
    "\\begin{bmatrix}\n",
    "    4 & 5 \\\\\n",
    "    7 & 8 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}. \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2c0b84",
   "metadata": {},
   "source": [
    "##### The Min Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd347cd",
   "metadata": {},
   "source": [
    "In a Min Pooling layer, we preserve the _minimum_ pixel value taken from the adjacent pixels in each kernel window, \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X^{\\prime} &= \n",
    "    \\begin{bmatrix}\n",
    "        min\n",
    "        \\begin{pmatrix}\n",
    "        0 & 1 \\\\\n",
    "        3 & 4 \\\\\n",
    "        \\end{pmatrix} \n",
    "        &\n",
    "        min\n",
    "        \\begin{pmatrix}\n",
    "        1 & 2 \\\\\n",
    "        4 & 5 \\\\\n",
    "        \\end{pmatrix}\n",
    "        \\\\\n",
    "        min\n",
    "        \\begin{pmatrix}\n",
    "        3 & 4 \\\\\n",
    "        6 & 7 \\\\\n",
    "        \\end{pmatrix}\n",
    "        &\n",
    "        min\n",
    "        \\begin{pmatrix}\n",
    "        4 & 5 \\\\\n",
    "        7 & 8 \\\\\n",
    "        \\end{pmatrix}\n",
    "    \\end{bmatrix}. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore we obtain the output matrix\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X^{\\prime} &= \n",
    "\\begin{bmatrix}\n",
    "    0 & 1 \\\\\n",
    "    3 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}. \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6aa83a",
   "metadata": {},
   "source": [
    "##### The Average Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0854c4",
   "metadata": {},
   "source": [
    "We can also use an Average Pooling layer to downsample the input. The _average_ value is computed for every window of pixels,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X^{\\prime} &= \n",
    "    \\begin{bmatrix}\n",
    "        avg\n",
    "        \\begin{pmatrix}\n",
    "        0 & 1 \\\\\n",
    "        3 & 4 \\\\\n",
    "        \\end{pmatrix} \n",
    "        &\n",
    "        avg\n",
    "        \\begin{pmatrix}\n",
    "        1 & 2 \\\\\n",
    "        4 & 5 \\\\\n",
    "        \\end{pmatrix}\n",
    "        \\\\\n",
    "        avg\n",
    "        \\begin{pmatrix}\n",
    "        3 & 4 \\\\\n",
    "        6 & 7 \\\\\n",
    "        \\end{pmatrix}\n",
    "        &\n",
    "        avg\n",
    "        \\begin{pmatrix}\n",
    "        4 & 5 \\\\\n",
    "        7 & 8 \\\\\n",
    "        \\end{pmatrix}\n",
    "    \\end{bmatrix}. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Therefore we obtain the output matrix\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "X^{\\prime} &= \n",
    "\\begin{bmatrix}\n",
    "    2 & 3 \\\\\n",
    "    5 & 6 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}. \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bcc0cf",
   "metadata": {},
   "source": [
    "We will see in our implementation how the above layers act to reduce an input image's spatial dimentionality while preserving information in various ways. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcb076",
   "metadata": {},
   "source": [
    "### 1.2. Padding and Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a345bd",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47e9ec",
   "metadata": {},
   "source": [
    "_Padding_ is a technique that allows us to specify the output size we want to obtain after performing a strided pooling or convolution operation. In the above example, we saw that our input matrix $X$ of dimensions $\\left(3 x 3 x 1\\right)$ resulted in an output matrix $X^{\\prime}$ of dimensions $\\left(2 x 2 x 1\\right)$ after performing a pooling operation over $X$ with a selected kernel size of $\\left(2 x 2 x 1\\right)$ and a stride length of $1$.\n",
    "\n",
    "Suppose instead we wanted to preserve the original dimensions of the input matrix after performing the sliding window approach. Good news is that while this is technically possible, we must first take several extra steps into consideration before jumping into the sliding window calculations like before.\n",
    "\n",
    "By revisiting the output width and size formulas above, we can find the ideal padding dimensions $p$ that we will need to use in order to obtain a desired output dimensions. That is, if we want an output of dimensions $\\left(\\mathrm{w}_{\\mathrm{output}}, \\ \\mathrm{h}_{\\mathrm{output}}, \\ \\mathrm{d}_{\\mathrm{output}}\\right) = \\left(\\mathrm{w}_{0}, \\ \\mathrm{h}_{0}, \\ \\mathrm{d}_{0}\\right)$, then we need to solve the equations for a specific padding amount $p$ where that is true,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathrm{w}_{\\mathrm{output}} &= \\frac{\\mathrm{w}_{0} - \\mathrm{f}_{\\mathrm{w}} + 2*p}{s} + 1 &= \\ \\mathrm{w}_{0}, \\\\\n",
    "    \\\n",
    "    \\mathrm{h}_{\\mathrm{output}} &= \\frac{\\mathrm{h}_{0} - \\mathrm{f}_{\\mathrm{h}} + 2*p}{s} + 1 &=  \\ \\mathrm{h}_{0}. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Rearranging the above expressions in terms of padding $p$, we obtain\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    p_{\\mathrm{w}} &= \\frac{s*\\mathrm{w}_{\\mathrm{output}} - s + \\mathrm{f}_{\\mathrm{w}} - \\mathrm{w}_{0}}{2}, \\\\\n",
    "    \\\n",
    "    p_{\\mathrm{h}} &= \\frac{s*\\mathrm{h}_{\\mathrm{output}} - s + \\mathrm{f}_{\\mathrm{h}} - \\mathrm{h}_{0}}{2}. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Let's assume we have an input matrix $X$ with dimensions $\\left(6 x 6 x 1\\right)$. If we want to preserve the dimensionality $X$ after passing it through one of the pooling layers above, we need to find a value of $p$ that makes the expressions above equal our initial dimensions of $X$. That is, $\\left(\\mathrm{w}_{\\mathrm{output}}, \\ \\mathrm{h}_{\\mathrm{output}}, \\ \\mathrm{d}_{\\mathrm{output}}\\right) = \\left(\\mathrm{w}_{0}, \\ \\mathrm{h}_{0}, \\ \\mathrm{d}_{0}\\right)$. For a given kernel size $\\left(3, 3, 1\\right)$ and a stride length of $s=1$, we can solve for $p$ after substituting in these known values,\n",
    "$$\n",
    "\\begin{align}\n",
    "    p_{\\mathrm{w}} &= \\frac{(1)*6 - 1 + 3 - 6}{2} &= 1, \\\\\n",
    "    \\\n",
    "    p_{\\mathrm{h}} &= \\frac{(1)*6 - 1 + 3 - 6}{2} &= 1. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "From the above calculations we determined that we will need to _pad_ our input matrix $X$ by a value $1$ along each axis. In other words, we must add a column vector of dimensions $\\left(1 \\ x \\ \\mathrm{w}_{0}\\right)$ to both the left-most and right-most columns of matrix $X$, and add a row vector of dimensions $\\left(1 \\ x \\ \\mathrm{h}_{0}\\right)$ to the upper-most and lower-most rows of matrix $X$. Now that we know the dimensions of our padding, lets see which values we should use to fill in the padding arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c9cd8",
   "metadata": {},
   "source": [
    "##### Zero padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec357e4",
   "metadata": {},
   "source": [
    "As the name implies, _zero padding_ is a technique that adds an array of _zeros_ along the perimeter of an input image. When used together when Max Pooling, the zero-padded arrays will not affect the resulting values of a pooling operation. That is, taking the $max$ of a non-zero pixel value together with a neighbouring padding value of zero results in the original pixel value. Therefore, no information along the perimeter of an image is lost or discarded.\n",
    "\n",
    "To use zero padding in Numpy, simply pass the `mode=\"constant\"` argument along with `constant_values=[0]` into the [`numpy.pad()`](https://numpy.org/doc/stable/reference/generated/numpy.pad.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ee4ff",
   "metadata": {},
   "source": [
    "##### Nearest-neighbour interpolation padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693ec11",
   "metadata": {},
   "source": [
    "Another padding technique known as [nearest-neighbour interpolation](https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation) is to fill the padding arrays with values that equal the image pixel values along the perimeter. Suppose we have a row vector `X[0,:] = [0, 1, 2, 3]`. Using a padding size of $p=1$, we would therefore add a row vector of equal length to the top of the matrix and fill it with the _same_ adjacent pixel values along the vector `X[0, :]`. This technique could be used with Average Pooling to avoid information loss.\n",
    "\n",
    "To use nearest-neighbour interpolation padding in Numpy, simply pass the `mode=\"edge\"` argument into the [`numpy.pad()`](https://numpy.org/doc/stable/reference/generated/numpy.pad.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba24446",
   "metadata": {},
   "source": [
    "##### Note on the practicality of pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec505e3b",
   "metadata": {},
   "source": [
    "As mentioned earlier, the primary use case for pooling layers in convolutional neural networks is to intentionally _reduce_ the spatial dimensionality of the input. Therefore, it is often not the case that one would use padding to _preserve_ input dimensionality. However, unexpected reductions in dimensionality may occur when using a sliding window approach without a carefully selected kernel size.\n",
    "\n",
    "A more practical use case for padding is often to handle the unexpected _edge cases_ (pun intended) when performing the sliding window calculations. In the case that the selected kernel size is _not_ an integer multiple of the input dimensions, one would end up with something like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a0956",
   "metadata": {},
   "source": [
    "![Fig. 2. Sliding window \"overshoot\" occurring along the perimeter of the input.](figures/2022-09-07-Figure-2-Sliding-Window-Overshoot.png)\n",
    "\n",
    "$$\n",
    "\\textrm{Fig. 2. Sliding window \"overshoot\" occurring along the perimeter of the input.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208f3c4",
   "metadata": {},
   "source": [
    "A kernel with this type of mismatch will tend to \"overshoot\" the bounds of the input and lead to an _incomplete_ window of pixel values (shown in red). When this happens, the standard practice is to _discard_ the window and _drop_ all pixel values in that window segment. When using the TensorFlow [`tf.nn.convolution`](https://www.tensorflow.org/api_docs/python/tf/nn/convolution) or [`tf.nn.pool`](https://www.tensorflow.org/api_docs/python/tf/nn/pool) operations, this is the expected behaviour when using the [`padding='VALID'`](https://www.tensorflow.org/api_docs/python/tf/nn#valid_padding_2) argument. \n",
    "\n",
    "While losing a few windows of computation might not seem like much, this affect gets compounded as more and more convolution or pooling layers are added to a network. With modern networks having handfuls of these layers, this can add up to a significant, unexpected reduction in resolution as your images pass through the network. To give [some perspective](https://blog.paperspace.com/padding-in-convolutional-neural-networks/), suppose we have a CNN with just four convolution layers and a kernel size of $3x3$. When we apply these layers to a $\\left(28, 28\\right)$ input image (e.g., an MNIST dataset image), we end up at the end with a $\\left(20, 20\\right)$ image. By reducing the image down to this size, we lose a total of _eight rows and columns_. This is equivalent to a loss of nearly *28%* of the original image *along each dimension*. All together, we have a total pixel loss of a whopping **49%** â€” and that's not even factoring in our intended downsampling!\n",
    "\n",
    "To circumvent this behaviour, padding is added to the edges of the input to \"fill in\" the missing values in the window. We described above two techniques for padding: _zero padding_ (left) or _[nearest-neighbour interpolation](https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation) padding_ (right):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a96f3",
   "metadata": {},
   "source": [
    "![Fig. 3. Two common padding techniques: (a) zero padding and (b) interpolation.](figures/2022-09-07-Figure-3-Sliding-Window-Padding-Techniques.png)\n",
    "\n",
    "$$\n",
    "\\textrm{Fig. 3. Two common padding techniques: (a) zero padding and (b) nearest-neighbour interpolation padding.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d79ce4",
   "metadata": {},
   "source": [
    "With padding enabled (i.e., when passing in the [`padding='SAME'`](https://www.tensorflow.org/api_docs/python/tf/nn#same_padding_2) argument in the TensorFlow operation), we can preserve the image dimensions using one of these two techniques. Note that other techniques exist for populating padding values with e.g., summary statistics using an arithmetic mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b11f4",
   "metadata": {},
   "source": [
    "### Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801e5167",
   "metadata": {},
   "source": [
    "Since we gave a disproportionately long time to padding, we won't go into that much detail about _stride_. Just know that this parameter also has an impact on the resulting dimensions of an input, and that stride can be expressed in terms of displacement in both the $x$- and $y$-direction. A stride of $\\left(2, 3\\right)$ indicates that the filter will be displaced by $2$ pixels on each horizontal pass, and that the filter will be displaced by $3$ pixels on each vertical pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad2e6d",
   "metadata": {},
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000cc1f3",
   "metadata": {},
   "source": [
    "### 2.1. Padding and Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5b137",
   "metadata": {},
   "source": [
    "You will have to implement two functions and a small script. The first function is a padding \n",
    "function. Using the input size and the pooling layer parameters (stride and filter size), \n",
    "this function finds the padding `wpad` and `hpad` (width and height padding) such that the \n",
    "input dimensions are padded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c8e3d",
   "metadata": {},
   "source": [
    "#### Padding algorithm with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53659cf4",
   "metadata": {},
   "source": [
    "**Note**: Udacity doesn't explicity mention that `get_paddings` should return the padding dimensions such that the original input `array` dimensions are preserved after the intended pooling operation. Therefore, we will assume this to be the desired output in order to make use of the padding formulas we highlighted in Sect. 1.2. Udacity also fails to mention the desired output format of `get_paddings`, which we now know is the `pad_width` argument to be used with the Numpy [`np.pad()`](https://numpy.org/doc/stable/reference/generated/numpy.pad.html) function. Here we are expected to return the sequence of values with which to pad _each_ dimension of the input `array`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d6bc7",
   "metadata": {},
   "source": [
    "Suppose we have a $4x4$ input matrix of zeros,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41cf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c3e7f5",
   "metadata": {},
   "source": [
    "We can define a `pad_width` sequence in the following form:\n",
    "```\n",
    "pad_width = [[upper_width, lower_width], [left_width, right_width]]\n",
    "```\n",
    "\n",
    "Given that we want to, say, pad the edges of `X` such that the:\n",
    "* Upper-most (top) edge has a padding width of `1`;\n",
    "* Lower-most (bottom) edge has a padding width of `2`;\n",
    "* Left-most edge edge has a padding width of `0`;\n",
    "* Right-most edge has a padding with of `3`.\n",
    "\n",
    "We can yield the following sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4494b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_width = [[1, 2], [0, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed21fe",
   "metadata": {},
   "source": [
    "Now testing this with the Numpy [`pad()`](https://numpy.org/doc/stable/reference/generated/numpy.pad.html) function using a constant padding value of `1` we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de699cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(X, pad_width, constant_values=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df7d77",
   "metadata": {},
   "source": [
    "From the result we can compare our results and see that we indeed obtained our matrix `X` padded with `1`s according to our specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9ee5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `pooling.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04240e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paddings(array: np.ndarray, pool_size: int, \n",
    "                 pool_stride: int) -> List[List[int]]:\n",
    "    \"\"\"Returns the range of values to pad on each edge using Numpy.\n",
    "    \n",
    "    Computes the padding amounts along each dimension such that the\n",
    "    spatial dimensionality of the input is preserved (akin to the\n",
    "    TensorFlow Keras `padding=\"same\"` argument). Note that the input\n",
    "    is a 4-dimensional array but we computing only the padding amounts \n",
    "    for the 2D image surface (the width and height axes).\n",
    "\n",
    "    For more information on the Numpy `pad()` function, see:\n",
    "    https://numpy.org/doc/stable/reference/generated/numpy.pad.html\n",
    "    \n",
    "    :param array: np.ndarray, the input data of dimensions [NxWxHxC], \n",
    "        i.e., [n_samples x width x height x n_channels].\n",
    "    :param pool_size: int, the symmetric kernel window dimension.\n",
    "    :param pool_stride: int, the amount to displace the kernel window\n",
    "        in the horizontal and vertical direction (symmetric).\n",
    "    :returns: paddings, the Numpy `pad_width` padding sequences.\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    \n",
    "    wpad = None\n",
    "    hpad = None\n",
    "    # Get the per-sample input dimensions\n",
    "    _, w, h, d = array.shape\n",
    "    # Set the desired output shape\n",
    "    w_out, h_out = w, h\n",
    "    # Compute the padding dimensions\n",
    "    wpad = (pool_stride * w_out - w + pool_size - pool_stride) // 2\n",
    "    hpad = (pool_stride * h_out - h + pool_size - pool_stride) // 2\n",
    "    # Return the range of values to pad along each dimension\n",
    "    # [n_samples, width, height, n_channels]\n",
    "    return [[0, 0], [0, wpad], [0, hpad], [0, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4e304",
   "metadata": {},
   "source": [
    "#### Pooling helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419bf0d8",
   "metadata": {},
   "source": [
    "The next function calculates the output dimensions after pooling given the padded array\n",
    "dimensions and the pooling parameters (stride and filter size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a8636b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `pooling.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e438ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_size(shape: List[int], pool_size: int, \n",
    "                    pool_stride: int, padding_size: int=0) -> List[int]:\n",
    "    \"\"\"Returns the output dimensions after pooling.\n",
    "    \n",
    "    :param shape: the shape of the input array, i.e.,\n",
    "        [n_samples, width, height, n_channels].\n",
    "    :param pool_size: the window size of the kernel (dim. of the square matrix).\n",
    "    :param pool_stride: the displacement amount along the horizontal/vertical axes.\n",
    "    :param padding_size: int (optional), amount to pad the input array along all axes.\n",
    "    :returns: the output shape after pooling is performed, i.e.,\n",
    "        [n_samples, new_width, new_height, n_channels].\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    \n",
    "    new_w = None\n",
    "    new_h = None\n",
    "    # Get the per-sample dimensions\n",
    "    _, w, h, d = shape\n",
    "    # Compute the output dimensions after pooling\n",
    "    new_w = ((w - pool_size + 2 * padding_size) // pool_stride) + 1\n",
    "    new_h = ((h - pool_size + 2 * padding_size) // pool_stride) + 1\n",
    "    return [shape[0], int(new_w), int(new_h), shape[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e21e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape of X\n",
    "# [n_samples, width, height, n_channels]\n",
    "X_shape = [1, 4, 4, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84310ade",
   "metadata": {},
   "source": [
    "Assuming the previous $4x4$ matrix `X` as our input, let's calculate the output size of `X` after we have performed our pooling operation. Using a kernel size of $2x2$, and a pool stride of $1$ we expect the following output dimensions:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    w_{out} &=  \\frac{\\mathrm{w}_{0} - \\mathrm{f}_{\\mathrm{w}} + 2*p}{s} + 1, \n",
    "    & \\qquad h_{out} &=  \\frac{\\mathrm{h}_{0} - \\mathrm{f}_{\\mathrm{h}} + 2*p}{s} + 1, \\\\\n",
    "    &= \\frac{4 - 2 + 2*0}{1} + 1,\n",
    "    & \\qquad &= \\frac{4 - 2 + 2*0}{1} + 1. \\\\\n",
    "    &= 3. \n",
    "    & \\qquad &= 3.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore we will have an output matrix of $3x3$ after pooling is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2345fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New      (width, height):  (3, 3)\n",
      "Original (width, height):  (4, 4)\n"
     ]
    }
   ],
   "source": [
    "_, new_w, new_h, _ = get_output_size(X_shape, pool_size=2, pool_stride=1)\n",
    "print('New      (width, height):', f' ({new_w}, {new_h})')\n",
    "print('Original (width, height):', f' ({X_shape[1]}, {X_shape[2]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc82672",
   "metadata": {},
   "source": [
    "**Note**: the input matrix `X` has not been padded in this example (therefore we have an expected mismatch between the input and output dimensions after pooling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d576dc",
   "metadata": {},
   "source": [
    "Finally, the script calculates the pooling layer output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bc9a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `pooling.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23fec81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the kernel hypeparameters\n",
    "POOL_SIZE = 3\n",
    "STRIDE = 3\n",
    "### Testing the pooling operation on array of random values\n",
    "input_array = np.random.rand(1, 224, 224, 16)\n",
    "pool_size = POOL_SIZE\n",
    "pool_stride = STRIDE\n",
    "### Performing zero padding on the test array\n",
    "paddings = get_paddings(input_array, pool_size, pool_stride)\n",
    "padded = np.pad(input_array, paddings, mode='constant', constant_values=0)\n",
    "### Get the output size of the pooled layer\n",
    "output_size = get_output_size(input_array.shape, pool_size, pool_stride, padding_size=paddings[1][1])\n",
    "output = np.zeros(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98297f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded array shape: (1, 448, 448, 16)\n"
     ]
    }
   ],
   "source": [
    "### Print the padded array shape\n",
    "# [n_samples, width, height, n_channels]\n",
    "print('Padded array shape:', padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59e5a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding ranges: [[0, 0], [0, 224], [0, 224], [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "### Print the padding ranges along each axes\n",
    "# padding the width and height dimensions according to:\n",
    "# [[], [upper_width, lower_width], [left_width, right_width], []]\n",
    "print('Padding ranges:', paddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c7215de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: [1, 224, 224, 16]\n"
     ]
    }
   ],
   "source": [
    "### Print the output size after pooling\n",
    "print('Output size:', output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ef82724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New      (width, height):  (224, 224)\n",
      "Original (width, height):  (224, 224)\n"
     ]
    }
   ],
   "source": [
    "### Comparing the resulting output shape against the original\n",
    "# shape is given as: [n_samples, width, height, n_channels]\n",
    "_, orig_w, orig_h, _ = input_array.shape \n",
    "_, new_w, new_h, _ = output.shape\n",
    "print('New      (width, height):', f' ({new_w}, {new_h})')\n",
    "print('Original (width, height):', f' ({orig_w}, {orig_h})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c69edf",
   "metadata": {},
   "source": [
    "You can run `python pooling.py` to check your implementation - note that the checking of the output will require input of a 3x3 filter and stride of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "871db46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17c33b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(output):\n",
    "    \"\"\"\n",
    "    checking the shape of the output\n",
    "    \"\"\"\n",
    "    if output.shape == (1, 75, 75, 16):\n",
    "        print('Success!')\n",
    "    else:\n",
    "        print('Failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af09353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENT THE POOLING CALCULATION \n",
    "check_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4154ee",
   "metadata": {},
   "source": [
    "**Note**: we should \\*disregard\\* this output as the Udacity mentor Neha on [this](https://knowledge.udacity.com/questions/817400) Knowledge support forum mentions that the provided test case (the expected output shape) is **invalid** for the provided input data (`stride = 3`, `pool_size = 3`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f343ace",
   "metadata": {},
   "source": [
    "## 3. Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3bff22",
   "metadata": {},
   "source": [
    "##### Alternatives\n",
    "* Use the TensorFlow Keras [`tf.keras.layers.ZeroPadding2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D) layer to pad the image data;\n",
    "    * Can pass in the existing `paddings` from `get_paddings` into the `padding` argument (after converting to `tuple`s);\n",
    "    * Can instead specify an integer value for symmetric padding applied to height and width (i.e., the `paddings[1][1]` value we computed).\n",
    "    \n",
    "##### Extensions of task\n",
    "* Use the TensorFlow Keras [`tf.keras.layers.MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) to compute Max Pooling over the image data;\n",
    "    * In order to preserve input dimensionality, we pass in the `padding=\"same\"` argument, otherwise we use `padding=\"valid\"`;\n",
    "* Use the TensorFlow Keras [`tf.keras.layers.AveragePooling2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) to compute Average Pooling over the image data;\n",
    "    * This layer computes the _average_ value in each subregion within the kernel window (similar to discussed);\n",
    "    * In order to preserve input dimensionality, the same arguments as mentioned for `MaxPool2D` hold true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514af0f7",
   "metadata": {},
   "source": [
    "## 4. Future Work\n",
    "\n",
    "- âœ… Utilise the TensorFlow Keras [`ZeroPadding2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ZeroPadding2D) and [`MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers in a custom CNN architecture (see [Exercise 1.4.2](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-4-2-Building-Custom-CNNs/2022-09-12-Building-Custom-Convolutional-Neural-Networks.ipynb));\n",
    "- âœ… Experiment with varying spatial dimensionality behaviours (i.e., reduce/preserve input dimensionality) and compare their effect on model performance (e.g., input image resizing â€” see [Project 1.1: Report](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/1-1-Object-Detection-in-Urban-Environments/2022-10-16-Report.md))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff0844",
   "metadata": {},
   "source": [
    "## Credits\n",
    "This assignment was prepared by Thomas Hossler and Michael Virgo et al., Winter 2021 (link [here](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)).\n",
    "\n",
    "Helpful resources:\n",
    "* [7.3. Padding and Strides | Dive into Deep Learning](https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html)\n",
    "* [Tutorial 22 - Padding in Convolutional Neural Network by K. Naik | YouTube](https://www.youtube.com/watch?v=PGBop7Ka9AU)\n",
    "* [Padding in Convolutional Neural Networks by O. Olu-Ipinlaye | Paperspace](https://blog.paperspace.com/padding-in-convolutional-neural-networks/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
