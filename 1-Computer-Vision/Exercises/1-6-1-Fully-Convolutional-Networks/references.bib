%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Jonathan Moran at 2023-01-25 16:23:59 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@article{article,
	author = {Piramanayagam, Sankaranarayanan and Saber, Eli and Schwartzkopf, Wade and Koehler, Frederick},
	date-added = {2023-01-25 16:23:49 -0800},
	date-modified = {2023-01-25 16:23:55 -0800},
	doi = {10.3390/rs10091429},
	journal = {Remote Sensing},
	month = {09},
	pages = {1429},
	title = {Supervised Classification of Multisensor Remotely Sensed Images Using a Deep Learning Framework},
	volume = {10},
	year = {2018}}

@misc{https://doi.org/10.48550/arxiv.1605.06211,
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.},
	author = {Shelhamer, Evan and Long, Jonathan and Darrell, Trevor},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-added = {2023-01-25 16:21:58 -0800},
	date-modified = {2023-01-25 16:22:28 -0800},
	doi = {10.48550/ARXIV.1605.06211},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Fully Convolutional Networks for Semantic Segmentation},
	url = {https://arxiv.org/abs/1605.06211},
	year = {2016}}

@misc{https://doi.org/10.48550/arxiv.1603.07285,
	abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
	author = {Dumoulin, Vincent and Visin, Francesco},
	copyright = {arXiv.org perpetual, non-exclusive license},
	date-modified = {2023-01-25 12:15:55 -0800},
	doi = {10.48550/ARXIV.1603.07285},
	keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {A guide to convolution arithmetic for deep learning},
	url = {https://arxiv.org/abs/1603.07285},
	year = {2016},
	bdsk-url-1 = {https://arxiv.org/abs/1603.07285},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1603.07285}}
