{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d3c8fa",
   "metadata": {
    "id": "10d3c8fa"
   },
   "source": [
    "# Exercise 1.7.1 — Scene Understanding\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8342f66",
   "metadata": {
    "id": "a8342f66"
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8a817",
   "metadata": {
    "id": "3ce8a817"
   },
   "source": [
    "* Compute the Mean Intersection over Union (IoU) of the multi-class segmentation label predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a226974",
   "metadata": {
    "id": "9a226974"
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e37f8f",
   "metadata": {
    "id": "36e37f8f"
   },
   "outputs": [],
   "source": [
    "### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040b9ad5",
   "metadata": {
    "id": "040b9ad5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from typing import List, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3396c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "6f3396c3",
    "outputId": "ffb26494-6cbb-4474-f7b3-58fb49394400"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab345e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "9ab345e3",
    "outputId": "97d046f0-b0ae-476e-a634-1d99ebd69c1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b54c301",
   "metadata": {
    "id": "4b54c301"
   },
   "outputs": [],
   "source": [
    "### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5279089e",
   "metadata": {
    "id": "5279089e"
   },
   "outputs": [],
   "source": [
    "ENV_COLAB = True                # True if running in Google Colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda135f9",
   "metadata": {
    "id": "eda135f9"
   },
   "outputs": [],
   "source": [
    "# Root directory\n",
    "DIR_BASE = '' if not ENV_COLAB else '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8bc08a8",
   "metadata": {
    "id": "a8bc08a8"
   },
   "outputs": [],
   "source": [
    "# Subdirectory to save output files\n",
    "DIR_OUT = os.path.join(DIR_BASE, 'out/')\n",
    "# Subdirectory pointing to input data\n",
    "DIR_SRC = os.path.join(DIR_BASE, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c1e4cd",
   "metadata": {
    "id": "e7c1e4cd"
   },
   "outputs": [],
   "source": [
    "### Creating subdirectories (if not exists)\n",
    "os.makedirs(DIR_OUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e58534",
   "metadata": {
    "id": "21e58534"
   },
   "source": [
    "### 1.1. Scene Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d70ec3",
   "metadata": {
    "id": "73d70ec3"
   },
   "source": [
    "#### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd081af",
   "metadata": {
    "id": "3fd081af"
   },
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34dd32",
   "metadata": {
    "id": "5f34dd32"
   },
   "source": [
    "#### Metrics — Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab143bf",
   "metadata": {
    "id": "3ab143bf"
   },
   "source": [
    "In the [very first exercise](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-1-1-Choosing-Metrics/2022-07-25-Choosing-Metrics-IoU.ipynb) of this course, we covered the Intersection over Union (IoU) metric and its application to the bounding box prediction task. Now, we use the IoU metric again but this time for semantic segmentation and scene understanding.\n",
    "\n",
    "We start with the same general formula for the IoU score given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{IoU} &= \\frac{\\textrm{Area of Intersection}}{\\textrm{Area of Union}},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "but now we calculate the IoU score using the following binary classification metrics:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{IoU} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN} + \\mathrm{TN}}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With this form of the IoU equation, all we need to do is compute the true positive ($\\mathrm{TP}$), true negative ($\\mathrm{TN}$), and the false positive ($\\mathrm{FN}$), false negative ($\\mathrm{FN}$) rates. For the image segmentation task, this boils down to the pixel-wise classification predictions. Thankfully, the algorithms we designed in [Sect. 2.1](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/1-Computer-Vision/Exercises/1-1-1-Choosing-Metrics/2022-07-25-Choosing-Metrics-IoU.ipynb) of Exercise 1.1.1 hold; all we need to do is compute the pixel-wise classification metrics for each class using the same tabular approach as before. With these metrics, we evaluate the $\\mathrm{IoU}$ formula and obtain a score indicating the amount of \"overlap\" between the predicted region and the true region of each segmented object. \n",
    "\n",
    "Let's illustrate this with a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cb770",
   "metadata": {
    "id": "d54cb770"
   },
   "source": [
    "```python\n",
    "ground_truth_labels = [\n",
    "    [0, 0, 0, 0], \n",
    "    [1, 1, 1, 1],\n",
    "    [2, 2, 2, 2], \n",
    "    [3, 3, 3, 3],\n",
    "]\n",
    "predicted_labels = [\n",
    "    [1, 0, 0, 0],\n",
    "    [1, 3, 0, 1],\n",
    "    [2, 2, 2, 3],\n",
    "    [3, 1, 0, 0],\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc4fe7",
   "metadata": {
    "id": "69dc4fe7"
   },
   "source": [
    "Above we define a set of _ground-truth_ and _predicted_ labels. Each row in the matrix corresponds to a class; looking at the first row of the `ground_truth_labels` (\"$\\mathrm{A}$\") matrix, we see that class `0` should appear at all four pixel locations. Looking at the first row of `predicted_labels` (\"$\\mathrm{B}$\" matrix), we see instead that only three of the four pixel locations were given a correct prediction of class `0`. In other words, we have in the first row a $\\mathrm{TP} = 3$. Now, we need to compute for class `0` the false positive ($\\mathrm{FP}$) rate. To do this, we examine the _other_ pixel locations (i.e., other rows of the `predicted_labels` matrix), and add up any occurrences of class label `0` where the corresponding entries in `ground_truth_labels` do not match. Since class label `0` was predicted _incorrectly_ at pixel locations $\\mathrm{B}_{2, 3}$, $\\mathrm{B}_{3, 3}$, and $\\mathrm{B}_{4, 4}$, we have a $\\mathrm{FP} = 3$. Now let's complete the calculations for the two other metrics: true negative ($\\mathrm{TN}$) and false negative ($\\mathrm{FN}$). The $\\mathrm{TN}$ value for this problem is easy to compute, since we assume all predictions here were valid (i.e., that we expected a class label to be predicted for every pixel in `predicted_labels`). That means our $\\mathrm{TN} = 0$. Lastly, our $\\mathrm{FN}$ rate is computed as the number of _incorrect_ predictions for class `0`. Looking at the first row of the `predicted_labels` matrix (i.e., the \"predictions\" for class `0`), we count the number of label predictions that are _not_ equal to class `0` to get our false negative rate. With _one_ incorrect class `0` prediction at the first index $\\mathrm{B}_{1, 1} = $ `1`, we have therefore a $\\mathrm{FN} = 1$. \n",
    "\n",
    "With these four classification metrics out of the way, we can obtain the $\\mathrm{IoU}$ score for class `0` as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{IoU}_{0} &= \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN} + \\mathrm{TN}} = \\frac{3}{3 + 3 + 1 + 0} = \\frac{3}{7} \\approx 0.4286.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now that we have the $\\mathrm{IoU}$ score for class `0` computed, we repeat the process for the other three rows (classes) in `predicted_labels` to obtain each classes' respective $\\mathrm{IoU}$ score. Once we have completed the calculations of all four classes, we can take the average to obtain the $\\mathrm{IoU}_{\\textrm{mean}}$, as simply:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{IoU}_{\\textrm{mean}} &= \\frac{1}{n}\\sum_{i=0}^{n} \\mathrm{IoU}_{i},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is nothing but the sum of the per-class $\\mathrm{IoU}$ scores divided by the total number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c37ea7fa",
   "metadata": {
    "id": "c37ea7fa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cfaa112",
   "metadata": {
    "id": "7cfaa112"
   },
   "source": [
    "### 1.2. FCN-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9769c0",
   "metadata": {
    "id": "4d9769c0"
   },
   "source": [
    "#### Network Architecture — Encoder and Decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cc7a7",
   "metadata": {
    "id": "066cc7a7"
   },
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81567d69",
   "metadata": {
    "id": "81567d69"
   },
   "source": [
    "#### Segmentation — Classifiction and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4bcc5",
   "metadata": {
    "id": "38a4bcc5"
   },
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b337dc",
   "metadata": {
    "id": "19b337dc"
   },
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76f553",
   "metadata": {
    "id": "9d76f553"
   },
   "source": [
    "### 2.1. Intersection over Union (IoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0509c31",
   "metadata": {
    "id": "e0509c31"
   },
   "source": [
    "Here we use the TensorFlow [`tf.keras.metrics.MeanIoU`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU) function to compute the mean Intersection over Union (IoU) across all classes $i=0,\\ldots, n$.\n",
    "\n",
    "In order to use the metric as a standalone function, we have to first initialise the respective [`tf.keras.metrics.Metric`](https://www.tensorflow.org/versions/r2.9/api_docs/python/tf/keras/metrics/Metric) subclass instance (i.e., `MeanIoU`), then perform a single \"state update\" using the [`update_state()`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/MeanIoU#update_state) class method. As arguments to this function, we pass in the `y_true` and `y_pred` tensors that we wish to evaluate. Optionally, we can provide a `sample_weight` scalar value or vector of rank equal to `y_true`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1588d58",
   "metadata": {
    "id": "f1588d58"
   },
   "outputs": [],
   "source": [
    "### Defining the number of distinct class labels (i.e., classes)\n",
    "N_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d89c5313",
   "metadata": {
    "id": "d89c5313"
   },
   "outputs": [],
   "source": [
    "### Initialising the `tf.keras.metrics.Metric` instance\n",
    "iou_mean = tf.keras.metrics.MeanIoU(\n",
    "    num_classes=N_CLASSES,\n",
    "    name='Mean IoU for multi-class object segmentation data',\n",
    "    dtype=tf.dtypes.float32,\n",
    "    ### Additional arguments for TF2.10+ API:\n",
    "    #ignore_class=None,\n",
    "    #sparse_y_true=True,    # `True` if class labels are integers, `False` if floating-point\n",
    "    #sparse_y_pred=True,\n",
    "    #axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aEPRhQllMLHG",
   "metadata": {
    "id": "aEPRhQllMLHG"
   },
   "source": [
    "#### Testing the `MeanIoU` metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFL3s0eqMK9W",
   "metadata": {
    "id": "SFL3s0eqMK9W"
   },
   "source": [
    "TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c0ea8b",
   "metadata": {
    "id": "b0c0ea8b"
   },
   "source": [
    "### 2.2. Separable Depthwise Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89e05aa",
   "metadata": {
    "id": "e89e05aa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9aba00",
   "metadata": {
    "id": "ce9aba00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24db9973",
   "metadata": {
    "id": "24db9973"
   },
   "source": [
    "### 2.3. SSD Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b1ab4e8",
   "metadata": {
    "id": "6b1ab4e8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3955c0f",
   "metadata": {
    "id": "b3955c0f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f22d31",
   "metadata": {
    "id": "e6f22d31"
   },
   "source": [
    "### 2.4. Filtering Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b9fcb11",
   "metadata": {
    "id": "0b9fcb11"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a3affc3",
   "metadata": {
    "id": "5a3affc3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e3b6185",
   "metadata": {
    "id": "5e3b6185"
   },
   "source": [
    "#### 2.5. Object Detection Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921de691",
   "metadata": {
    "id": "921de691"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24c320b4",
   "metadata": {
    "id": "24c320b4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac72970d",
   "metadata": {
    "id": "ac72970d"
   },
   "source": [
    "### 2.6. Timing Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "403d2bae",
   "metadata": {
    "id": "403d2bae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc17783",
   "metadata": {
    "id": "6dc17783"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23b7033d",
   "metadata": {
    "id": "23b7033d"
   },
   "source": [
    "### 2.7. Object Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2846dd45",
   "metadata": {
    "id": "2846dd45"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d8cee3f",
   "metadata": {
    "id": "4d8cee3f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c6e83cf",
   "metadata": {
    "id": "5c6e83cf"
   },
   "source": [
    "## 3. Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d7d2f",
   "metadata": {
    "id": "138d7d2f"
   },
   "source": [
    "##### Alternatives\n",
    "* TODO.\n",
    "##### Extensions of task\n",
    "* TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f9ba4",
   "metadata": {
    "id": "550f9ba4"
   },
   "source": [
    "## 4. Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728bd96",
   "metadata": {
    "id": "5728bd96"
   },
   "source": [
    "- ⬜️ TODO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6526376",
   "metadata": {
    "id": "f6526376"
   },
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9606fb",
   "metadata": {
    "id": "9a9606fb"
   },
   "source": [
    "This assignment was prepared by Kelvin Lwin, Andrew Bauman, Dominique Luna et al., 2021 (link [here](https://github.com/udacity/CarND-Object-Detection-Lab)).\n",
    "\n",
    "References\n",
    "* [] TODO.\n",
    "\n",
    "Helpful resources:\n",
    "* [`CarND-Object-Detection-Lab` by @udacity | GitHub](https://github.com/udacity/CarND-Object-Detection-Lab);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
