{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2203c9",
   "metadata": {},
   "source": [
    "# Exercise 3 - Geometric transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14deed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa668b7c",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c524e5a",
   "metadata": {},
   "source": [
    "In this exercise, you will implement the following geometric transformations\n",
    "from scratch: horizontal flipping and resizing in `augmentations.py`. You can also \n",
    "implement random cropping as an additional but not required exercise. Your \n",
    "implementations should not only affect the images but also the associated bounding boxes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0cc7d",
   "metadata": {},
   "source": [
    "![](data/example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(gt_bbox, pred_bbox):\n",
    "    \"\"\"\n",
    "    calculate iou \n",
    "    args:\n",
    "    - gt_bbox [array]: 1x4 single gt bbox\n",
    "    - pred_bbox [array]: 1x4 single pred bbox\n",
    "    returns:\n",
    "    - iou [float]: iou between 2 bboxes\n",
    "    - [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    xmin = np.max([gt_bbox[0], pred_bbox[0]])\n",
    "    ymin = np.max([gt_bbox[1], pred_bbox[1]])\n",
    "    xmax = np.min([gt_bbox[2], pred_bbox[2]])\n",
    "    ymax = np.min([gt_bbox[3], pred_bbox[3]])\n",
    "    \n",
    "    intersection = max(0, xmax - xmin) * max(0, ymax - ymin)\n",
    "    gt_area = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])\n",
    "    pred_area = (pred_bbox[2] - pred_bbox[0]) * (pred_bbox[3] - pred_bbox[1])\n",
    "    \n",
    "    union = gt_area + pred_area - intersection\n",
    "    return intersection / union, [xmin, ymin, xmax, ymax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1a2c7",
   "metadata": {},
   "source": [
    "## Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85d523",
   "metadata": {},
   "source": [
    "The `hflip` function takes the image and bounding boxes as input and performs a \n",
    "horizontal flip. For example, an object initially on the left of the image will \n",
    "end up on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hflip(img, bboxes):\n",
    "    \"\"\"\n",
    "    horizontal flip of an image and annotations\n",
    "    args:\n",
    "    - img [PIL.Image]: original image\n",
    "    - bboxes [list[list]]: list of bounding boxes\n",
    "    return:\n",
    "    - flipped_img [PIL.Image]: horizontally flipped image\n",
    "    - flipped_bboxes [list[list]]: horizontally flipped bboxes\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    return flipped_img, flipped_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc6bb7",
   "metadata": {},
   "source": [
    "The `resize` function takes the image, bounding boxes and target size as input. \n",
    "It scales up or down images and bounding boxes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5270bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, boxes, size):\n",
    "    \"\"\"\n",
    "    resized image and annotations\n",
    "    args:\n",
    "    - img [PIL.Image]: original image\n",
    "    - boxes [list[list]]: list of bounding boxes\n",
    "    - size [array]: 1x2 array [width, height]\n",
    "    returns:\n",
    "    - resized_img [PIL.Image]: resized image\n",
    "    - resized_boxes [list[list]]: resized bboxes\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    return resized_image, resized_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178296d8",
   "metadata": {},
   "source": [
    "The `random_crop` function takes a few additional inputs. It also needs the classes, \n",
    "the crop size and the minimum area. Let's explain these parameters:\n",
    "* `crop_size` is the size of the crop. It should be smaller than the dimensions of the input image.\n",
    "* `min_area` is the minimum area of a bounding boxes to be considered as an object after cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00045fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(img, boxes, crop_size, min_area=100):\n",
    "    \"\"\"\n",
    "    random cropping of an image and annotations\n",
    "    args:\n",
    "    - img [PIL.Image]: original image\n",
    "    - boxes [list[list]]: list of bounding boxes\n",
    "    - crop_size [array]: 1x2 array [width, height]\n",
    "    - min_area [int]: min area of a bbox to be kept in the crop\n",
    "    returns:\n",
    "    - cropped_img [PIL.Image]: resized image\n",
    "    - cropped_boxes [list[list]]: resized bboxes\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    return cropped_image, cropped_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d824e8",
   "metadata": {},
   "source": [
    "Because we are cropping randomly, we may only keep a tiny portion of an object, in which\n",
    "case the annotations will not be useful anymore. For example, in the image below, we may not want to keep the annotation of the cat because most of the animal's body is not visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6133171",
   "metadata": {},
   "source": [
    "![](data/cat_cropped.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0462f02",
   "metadata": {},
   "source": [
    "**Note:** You'll need to use the \"Desktop\" button to view the visualizations of each augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix seed to check results\n",
    "    \n",
    "# open annotations\n",
    "    \n",
    "# filter annotations and open image\n",
    "    \n",
    "# check horizontal flip, resize and random crop\n",
    "\n",
    "# use check_results defined in utils.py for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd3ed40",
   "metadata": {},
   "source": [
    "## Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4393e",
   "metadata": {},
   "source": [
    "The `hflip` transform does not affect the x coordinates of the bounding boxes.\n",
    "\n",
    "You will use the same ratio in `resize` for the image and the bounding boxes. \n",
    "\n",
    "To find which bounding box belongs to the cropped area, you can use the `calculate_iou`\n",
    "function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d47d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plot_histogram(img):\n",
    "    \"\"\" plot channel-wise pixel value distribution \"\"\"\n",
    "    histogram = img.histogram()\n",
    "\n",
    "    R = histogram[0:256]\n",
    "    G = histogram[256:512]\n",
    "    B = histogram[512:768]\n",
    "\n",
    "    plt.plot(range(256), R, color='r')\n",
    "    plt.fill_between(range(256), R, color='r', alpha=0.5)\n",
    "    plt.plot(range(256), G, color='g')\n",
    "    plt.fill_between(range(256), G, color='g', alpha=0.5)\n",
    "    plt.plot(range(256), B, color='b')\n",
    "    plt.fill_between(range(256), B, color='b', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def display_results(img, bboxes, aug_img, aug_bboxes):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    ax[0].imshow(img)\n",
    "    for bb in bboxes:\n",
    "        y1, x1, y2, x2 = bb\n",
    "        rec = Rectangle((x1, y1), x2-x1, y2-y1, facecolor='none', edgecolor='r')\n",
    "        ax[0].add_patch(rec)\n",
    "    \n",
    "    ax[1].imshow(aug_img)\n",
    "    for bb in aug_bboxes:\n",
    "        y1, x1, y2, x2 = bb\n",
    "        rec = Rectangle((x1, y1), x2-x1, y2-y1, facecolor='none', edgecolor='r')\n",
    "        ax[1].add_patch(rec)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_results(img, boxes, aug_type, classes=None):\n",
    "    if aug_type == 'hflip':\n",
    "        imcheck = Image.open('data/augmented/flipped.png')\n",
    "        bbcheck = np.load('data/augmented/flipped.npy')\n",
    "        assert np.array_equal(np.array(imcheck), np.array(img)), 'Horizontal flip is wrong!'\n",
    "        assert np.array_equal(np.array(boxes), bbcheck), 'Horizontal flip is wrong!'\n",
    "        print('Horizontal flip is working')\n",
    "\n",
    "    elif aug_type == 'resize':\n",
    "        imcheck = Image.open('data/augmented/resized.png')\n",
    "        bbcheck = np.load('data/augmented/resized.npy')\n",
    "        assert np.array_equal(np.array(imcheck), np.array(img)), 'Resizing is wrong!'\n",
    "        assert np.array_equal(np.array(boxes), bbcheck), 'Resizing is wrong!'\n",
    "        print('Resizing is working')\n",
    "\n",
    "    elif aug_type == 'random_crop':\n",
    "        imcheck = Image.open('data/augmented/cropped.png')\n",
    "        bbcheck = np.load('data/augmented/cropped_bb.npy')\n",
    "        clcheck = np.load('data/augmented/cropped_cl.npy')\n",
    "        assert np.array_equal(np.array(imcheck), np.array(img)), 'Cropping is wrong!'\n",
    "        assert np.array_equal(np.array(boxes), bbcheck), 'Cropping is wrong!'\n",
    "        assert np.array_equal(np.array(classes), clcheck), 'Cropping is wrong!'\n",
    "        print('Cropping is working')\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
