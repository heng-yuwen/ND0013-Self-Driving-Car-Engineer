{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b73b05",
   "metadata": {},
   "source": [
    "# Exercise 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65fb0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911bfcb4",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bffe29",
   "metadata": {},
   "source": [
    "In this exercise we will implement the following functions:\n",
    "* `softmax`: computes the softmax (normalised exponential function) of a input tensor;\n",
    "* `cross_entropy`: calculates the cross-entropy loss between one-hot encoded prediction and ground truth vectors;\n",
    "* `model`: logistic regression algorithm;\n",
    "* `accuracy`: calculates the accuracy between a set of predictions and corresponding ground truth labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dac69d",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a59ca631",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e824358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56eab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d863b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_COLAB = False                # True if running in Google Colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae4ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory\n",
    "DIR_BASE = '' if not ENV_COLAB else '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e23b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subdirectory to save output files\n",
    "DIR_OUT = os.path.join(DIR_BASE, 'out/')\n",
    "# Subdirectory pointing to input data\n",
    "DIR_SRC = os.path.join(DIR_BASE, 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e503b95",
   "metadata": {},
   "source": [
    "### 1.1. Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16f4ca",
   "metadata": {},
   "source": [
    "The [softmax function](https://en.wikipedia.org/wiki/Softmax_function) is a generalisation of the sigmoid [logistic function](https://en.wikipedia.org/wiki/Logistic_function) to multiple dimensions. In machine learning, particularly for logistic regression, the softmax function $\\phi$ acts as a decision boundary applied to multi-class datasets, computing the probability of each observation $x_{i}$ belonging to one of $j = i,...,k$ class labels (assuming an independent relationship between the classes),\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    P\\left(y=j \\ \\vert \\ z_{i}\\right) = \\phi_{softmax}\\left(z_{i}\\right) \n",
    "    = \\frac{\\mathcal{e}^{z_{i}}}{\\sum_{j=0}^{k}\\mathcal{e}^{z_{k}^{i}}}.\n",
    "    \\end{align}\n",
    "$$\n",
    "The input $z$ is defined to be\n",
    "$$\n",
    "\\begin{align}\n",
    "    z &= w_{0}x_{0} + w_{1}x_{1} + \\ldots + w_{m}x_{m} = \\sum_{i=0}^{m} w_{i}x_{i} = \\mathrm{w}^{\\top}\\mathrm{x}.\n",
    "    \\end{align}\n",
    "$$\n",
    "such that $\\mathrm{w}$ is the weight vector, $\\mathrm{x}$ is the feature vector belonging to a single training observation, and $w_{0}$ is the bias unit.\n",
    "\n",
    "The softmax function computes the probability for each class $P\\left(y=j \\vert x_{i}; w_{j}\\right)$, then a correction step is applied to the predictions during training using a cost function that minimises the cross-entropy over the training set observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ed8e6",
   "metadata": {},
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4e643",
   "metadata": {},
   "source": [
    "### 2.1. Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5d459",
   "metadata": {},
   "source": [
    "In this exercise, you have to implement 4 different functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8128d23",
   "metadata": {},
   "source": [
    "* `softmax`: compute the softmax of a vector. This function takes as input a tensor and outputs a discrete probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b539cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `logistic.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d144aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    softmax implementation\n",
    "    args:\n",
    "    - logits [tensor]: 1xN logits tensor\n",
    "    returns:\n",
    "    - soft_logits [tensor]: softmax of logits\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    \n",
    "    soft_logits = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    return soft_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcadaedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02364054, 0.06426166, 0.1746813 , 0.474833  , 0.02364054,\n",
       "       0.06426166, 0.1746813 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing the softmax function\n",
    "a = [1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0]\n",
    "softmax(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c3489",
   "metadata": {},
   "source": [
    "### 2.2. Cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ba4a0",
   "metadata": {},
   "source": [
    "* `cross_entropy`: calculate the cross entropy loss given a vector of predictions (after softmax) and a vector of ground truth (one-hot vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae0b187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `logistic.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "340e7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(scaled_logits, one_hot):\n",
    "    \"\"\"\n",
    "    Cross entropy loss implementation\n",
    "    args:\n",
    "    - scaled_logits [tensor]: NxC tensor where N batch size / C number of classes\n",
    "    - one_hot [tensor]: one hot tensor\n",
    "    returns:\n",
    "    - loss [tensor]: cross entropy \n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a0b25",
   "metadata": {},
   "source": [
    "### 2.3. Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa6d04",
   "metadata": {},
   "source": [
    "* `model`: takes a batch of images (stack of images along the first dimensions) and feeds it through the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8cf3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `logistic.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92083e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, W, b):\n",
    "    \"\"\"\n",
    "    logistic regression model\n",
    "    args:\n",
    "    - X [tensor]: input HxWx3\n",
    "    - W [tensor]: weights\n",
    "    - b [tensor]: bias\n",
    "    returns:\n",
    "    - output [tensor]\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef47e0",
   "metadata": {},
   "source": [
    "### 2.4. Prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aca75b",
   "metadata": {},
   "source": [
    "* `accuracy`: given a vector of predictions and a vector of ground truth, calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06181bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `logistic.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bf1feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, Y):\n",
    "    \"\"\"\n",
    "    calculate accuracy\n",
    "    args:\n",
    "    - y_hat [tensor]: NxC tensor of models predictions\n",
    "    - y [tensor]: N tensor of ground truth classes\n",
    "    returns:\n",
    "    - acc [tensor]: accuracy\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8b2e1",
   "metadata": {},
   "source": [
    "## Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be159df3",
   "metadata": {},
   "source": [
    "You can leverage the `tf.boolean_mask` function to calculate the cross entropy. Keep in mind\n",
    "that most elements of the ground truth vector are zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3db93",
   "metadata": {},
   "source": [
    "## Credits\n",
    "This assignment was prepared by Thomas Hossler and Michael Virgo et al., Winter 2021 (link [here](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)).\n",
    "\n",
    "References\n",
    "\n",
    "\n",
    "Helpful resources:\n",
    "* [Softmax Regression and How is it Related to Logistic Regression? | KDnuggets](https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
