%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Jonathan Moran at 2022-09-17 20:18:09 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@article{Potirakis:2021tx,
	abstract = {For several years, much research has focused on the importance of traffic sign recognition systems, which have played a very important role in road safety. Researchers have exploited the techniques of machine learning, deep learning, and image processing to carry out their research successfully. The new and recent research on road sign classification and recognition systems is the result of the use of deep learning-based architectures such as the convolutional neural network (CNN) architectures. In this research work, the goal was to achieve a CNN model that is lightweight and easily implemented for an embedded application and with excellent classification accuracy. We choose to work with an improved network LeNet-5 model for the classification of road signs. We trained our model network on the German Traffic Sign Recognition Benchmark (GTSRB) database and also on the Belgian Traffic Sign Data Set (BTSD), and it gave good results compared to other models tested by us and others tested by different researchers. The accuracy was 99.84\&{\#}x0025; on GTSRB and 98.37\&{\#}x0025; on BTSD. The lightness and the reduced number of parameters of our model (0.38 million) based on the enhanced LeNet-5 network pushed us to test our model for an embedded application using a webcam. The results we found are efficient, which emphasize the effectiveness of our method.},
	author = {Potirakis, Stelios M. and Zaibi, Ameur and Ladgham, Anis and Sakly, Anis},
	date = {2021/04/30},
	date-added = {2022-09-17 20:18:04 -0700},
	date-modified = {2022-09-17 20:18:04 -0700},
	doi = {10.1155/2021/8870529},
	isbn = {1687-725X},
	journal = {Journal of Sensors},
	pages = {8870529},
	publisher = {Hindawi},
	title = {A Lightweight Model for Traffic Sign Classification Based on Enhanced LeNet-5 Network},
	url = {https://doi.org/10.1155/2021/8870529},
	volume = {2021},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1155/2021/8870529}}

@inproceedings{pmlr-v15-glorot11a,
	abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.},
	address = {Fort Lauderdale, FL, USA},
	author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	date-added = {2022-09-13 16:36:38 -0700},
	date-modified = {2022-09-13 16:39:17 -0700},
	editor = {Gordon, Geoffrey and Dunson, David and Dud{\'\i}k, Miroslav},
	journal = {Journal of Machine Learning Research},
	month = {11--13 Apr},
	pages = {315--323},
	pdf = {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Deep Sparse Rectifier Neural Networks},
	url = {https://proceedings.mlr.press/v15/glorot11a.html},
	volume = {15},
	year = {2011},
	bdsk-url-1 = {https://proceedings.mlr.press/v15/glorot11a.html}}

@article{726791,
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	date-added = {2022-09-13 16:31:11 -0700},
	date-modified = {2022-09-13 16:31:15 -0700},
	doi = {10.1109/5.726791},
	journal = {Proceedings of the IEEE},
	number = {11},
	pages = {2278-2324},
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1109/5.726791}}

@misc{https://doi.org/10.48550/arxiv.1511.07122,
	author = {Yu, Fisher and Koltun, Vladlen},
	copyright = {arXiv.org perpetual, non-exclusive license},
	doi = {10.48550/ARXIV.1511.07122},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},
	title = {Multi-Scale Context Aggregation by Dilated Convolutions},
	url = {https://arxiv.org/abs/1511.07122},
	year = {2015},
	bdsk-url-1 = {https://arxiv.org/abs/1511.07122},
	bdsk-url-2 = {https://doi.org/10.48550/ARXIV.1511.07122}}
