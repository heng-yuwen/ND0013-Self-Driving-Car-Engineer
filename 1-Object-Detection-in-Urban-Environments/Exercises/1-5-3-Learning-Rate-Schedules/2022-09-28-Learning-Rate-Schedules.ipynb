{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe5351fa",
   "metadata": {},
   "source": [
    "# Exercise 3 - Learning rate annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e46a05",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3854c9",
   "metadata": {},
   "source": [
    "In this exercise, you have to implement two different learning rate annealing (decay)\n",
    "strategies: step wise annealing and exponential annealing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f14f13",
   "metadata": {},
   "source": [
    "## Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff21e5",
   "metadata": {},
   "source": [
    "To do so, you will have to leverage Keras `callbacks`. Callbacks performs various action\n",
    "at different stages of training. For example, Keras uses a callback to save the models weights at \n",
    "the end of each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4819d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51cb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LrLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        history = self.model.history.history\n",
    "        history['lr'] = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        history = self.model.history.history\n",
    "        optimizer = self.model.optimizer\n",
    "        decayed_lr = optimizer._decayed_lr('float32').numpy()\n",
    "        history['lr'].append(decayed_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02e3b1",
   "metadata": {},
   "source": [
    "You can either use pre-implemented schedulers (see Tips) or implement a scheduler yourself \n",
    "using your own custom decay function, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f02e8",
   "metadata": {},
   "source": [
    "```\n",
    "def decay(model, callbacks, lr=0.001):\n",
    "    \"\"\" create custom decay that does not do anything \"\"\"\n",
    "    def scheduler(epoch, lr):\n",
    "        return lr \n",
    "\n",
    "    callbacks.append(tf.keras.callbacks.LearningRateScheduler(scheduler))\n",
    "\n",
    "    # compile model\n",
    "    model.compile()\n",
    "    \n",
    "    return model, callbacks \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc66163",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(model, callbacks, lr=0.001):\n",
    "    \"\"\" use exponential decay \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(model, callbacks, lr=0.001):\n",
    "    \"\"\" create custom decay using learning rate scheduler \"\"\"\n",
    "    #  IMPLEMENT THIS FUNCTION\n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd5d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceb36cf4",
   "metadata": {},
   "source": [
    "Feel free to use any decay rates as well as a step size of your choice for the stepwise scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a20d9",
   "metadata": {},
   "source": [
    "You can run `python training.py` to see the effect of different annealing strategies on your training and model performances. Make sure to feed in the GTSRB dataset as the image directory, and use the Desktop to view the visualization of final training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_logger(mod_name):\n",
    "    logger = logging.getLogger(mod_name)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca487dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_module_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Download and process tf files')\n",
    "parser.add_argument('-d', '--imdir', required=True, type=str,\n",
    "                    help='data directory')\n",
    "parser.add_argument('-e', '--epochs', default=10, type=int,\n",
    "                    help='Number of epochs')\n",
    "args = parser.parse_args()    \n",
    "\n",
    "logger.info(f'Training for {args.epochs} epochs using {args.imdir} data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54677d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb790ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image,label):\n",
    "    \"\"\" small function to normalize input images \"\"\"\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf107ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(imdir):\n",
    "    \"\"\" extract GTSRB dataset from directory \"\"\"\n",
    "    train_dataset = image_dataset_from_directory(imdir, \n",
    "                                       image_size=(32, 32),\n",
    "                                       batch_size=32,\n",
    "                                       validation_split=0.2,\n",
    "                                       subset='training',\n",
    "                                       seed=123,\n",
    "                                       label_mode='int')\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(imdir, \n",
    "                                        image_size=(32, 32),\n",
    "                                        batch_size=32,\n",
    "                                        validation_split=0.2,\n",
    "                                        subset='validation',\n",
    "                                        seed=123,\n",
    "                                        label_mode='int')\n",
    "    train_dataset = train_dataset.map(process)\n",
    "    val_dataset = val_dataset.map(process)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datasets\n",
    "train_dataset, val_dataset = get_datasets(args.imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datasets\n",
    "train_dataset, val_dataset = get_datasets(args.imdir)\n",
    "logger = LrLogger()\n",
    "callbacks = [logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139add21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d04301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    net = tf.keras.models.Sequential()\n",
    "    input_shape = [32, 32, 3]\n",
    "    net.add(Conv2D(6, kernel_size=(3, 3), strides=(1, 1), activation='relu', \n",
    "                   input_shape=input_shape))\n",
    "    net.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    net.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1), activation='relu'))   \n",
    "    net.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(120, activation='relu'))\n",
    "    net.add(Dense(84, activation='relu'))\n",
    "    net.add(Dense(43))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, callbacks = exponential_decay(model, callbacks)\n",
    "model, callbacks = step_decay(model, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5cac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_dataset, \n",
    "                    epochs=args.epochs, \n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc868b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(history):\n",
    "    \"\"\" plot loss and accuracy from keras history object \"\"\"\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].plot(history.history['loss'], linewidth=3)\n",
    "    ax[0].plot(history.history['val_loss'], linewidth=3)\n",
    "    ax[0].set_title('Loss', fontsize=16)\n",
    "    ax[0].set_ylabel('Loss', fontsize=16)\n",
    "    ax[0].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[0].legend(['train loss', 'val loss'], loc='upper right')\n",
    "    ax[1].plot(history.history['accuracy'], linewidth=3)\n",
    "    ax[1].plot(history.history['val_accuracy'], linewidth=3)\n",
    "    ax[1].set_title('Accuracy', fontsize=16)\n",
    "    ax[1].set_ylabel('Accuracy', fontsize=16)\n",
    "    ax[1].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[1].legend(['train acc', 'val acc'], loc='upper left')\n",
    "    ax[2].plot(history.history['lr'], linewidth=3)\n",
    "    ax[2].set_title('Learning rate', fontsize=16)\n",
    "    ax[2].set_ylabel('Learning Rate', fontsize=16)\n",
    "    ax[2].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[2].legend(['learning rate'], loc='upper right')\n",
    "    # ax[2].ticklabel_format(axis='y', style='sci')\n",
    "    ax[2].yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a18028a",
   "metadata": {},
   "source": [
    "## Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fb1df0",
   "metadata": {},
   "source": [
    "You can find pre-implemented schedulers (Keras naming convention for learning rate annealing strategies) \n",
    "[here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
