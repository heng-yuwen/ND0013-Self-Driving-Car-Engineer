{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620da957",
   "metadata": {},
   "source": [
    "# Exercise 1.5.3 - Learning Rate Schedules\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b189d",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc715f2",
   "metadata": {},
   "source": [
    "* Implement two different [learning rate schedules](https://en.wikipedia.org/wiki/Learning_rate#Learning_rate_schedule): [exponential decay](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay) and step-wise annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750d6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf54b94",
   "metadata": {},
   "source": [
    "## Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a2d3d",
   "metadata": {},
   "source": [
    "To do so, you will have to leverage Keras `callbacks`. Callbacks performs various action\n",
    "at different stages of training. For example, Keras uses a callback to save the models weights at \n",
    "the end of each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LrLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        history = self.model.history.history\n",
    "        history['lr'] = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        history = self.model.history.history\n",
    "        optimizer = self.model.optimizer\n",
    "        decayed_lr = optimizer._decayed_lr('float32').numpy()\n",
    "        history['lr'].append(decayed_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f91ab",
   "metadata": {},
   "source": [
    "You can either use pre-implemented schedulers (see Tips) or implement a scheduler yourself \n",
    "using your own custom decay function, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb93f0",
   "metadata": {},
   "source": [
    "```\n",
    "def decay(model, callbacks, lr=0.001):\n",
    "    \"\"\" create custom decay that does not do anything \"\"\"\n",
    "    def scheduler(epoch, lr):\n",
    "        return lr \n",
    "\n",
    "    callbacks.append(tf.keras.callbacks.LearningRateScheduler(scheduler))\n",
    "\n",
    "    # compile model\n",
    "    model.compile()\n",
    "    \n",
    "    return model, callbacks \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfeb3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cf0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(\n",
    "        model: tf.keras.Model, callbacks: List[tf.keras.callbacks.Callback]=[], \n",
    "        initial_lr: float=0.001\n",
    ") -> Tuple[tf.keras.Model, List[tf.keras.callbacks.Callback]]:\n",
    "    \"\"\"Compiles and returns Model instance with exponential decay LR schedule.\n",
    "    \n",
    "    :param model: the tf.keras.Model instance to compile.\n",
    "    :param callbacks: the list of tf.keras.callbacks to pass alongside model.\n",
    "    :param initial_lr: the value to fix the learning rate at before annealing.\n",
    "    :returns: tuple, the compiled Model instance and its callbacks.\n",
    "    \"\"\"\n",
    "    # IMPLEMENT THIS FUNCTION\n",
    "    \n",
    "    # Instantiate the learning rate schedule\n",
    "    lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                        initial_learning_rate=initial_lr,\n",
    "                        decay_steps=100,\n",
    "                        decay_rate=0.95,\n",
    "                        staircase=False\n",
    "    )\n",
    "    # Instantiate the optimiser\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy']\n",
    "    )\n",
    "    # Return the model and any specified callbacks\n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b107708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 14:19:24.263631: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e46374d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = exponential_decay(model=model, callbacks=[], initial_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9fe62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(\n",
    "        model: tf.keras.Model, callbacks: List[tf.keras.callbacks.Callback]=[], \n",
    "        initial_lr: float=0.001\n",
    ") -> Tuple[tf.keras.Model, List[tf.keras.callbacks.Callback]]:\n",
    "    \"\"\"Compiles and returns Model instance with step-wise decay LR schedule.\n",
    "    \n",
    "    :param model: the tf.keras.Model instance to compile.\n",
    "    :param callbacks: the list of tf.keras.callbacks to pass alongside model.\n",
    "    :param initial_lr: the value to fix the learning rate at before annealing.\n",
    "    :returns: tuple, the compiled Model instance and its callbacks.\n",
    "    \"\"\"\n",
    "    #  IMPLEMENT THIS FUNCTION\n",
    "    \n",
    "    def scheduler(epoch: int, lr: float):\n",
    "        \"\"\"Simple custom constant step-wise annealing schedule.\"\"\"\n",
    "        return lr / 2 if epoch % 10 == 0 and epoch > 0 else lr\n",
    "    \n",
    "    # Instantiate a custom Keras callback to perform LR annealing\n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "                            schedule=scheduler, verbose=1\n",
    "    )\n",
    "    callbacks.append(lr_schedule)\n",
    "    # Instantiate the optimiser with the initial learning rate value\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                  metrics=['accuracy']\n",
    "    )\n",
    "    # Return the compiled model and the custom LR scheduler and any other callback\n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b5e1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14c699fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, callbacks = step_decay(model=model, callbacks=[], initial_lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee359c",
   "metadata": {},
   "source": [
    "Feel free to use any decay rates as well as a step size of your choice for the stepwise scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366a164",
   "metadata": {},
   "source": [
    "You can run `python training.py` to see the effect of different annealing strategies on your training and model performances. Make sure to feed in the GTSRB dataset as the image directory, and use the Desktop to view the visualization of final training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f916d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_logger(mod_name):\n",
    "    logger = logging.getLogger(mod_name)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_module_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f8b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Download and process tf files')\n",
    "parser.add_argument('-d', '--imdir', required=True, type=str,\n",
    "                    help='data directory')\n",
    "parser.add_argument('-e', '--epochs', default=10, type=int,\n",
    "                    help='Number of epochs')\n",
    "args = parser.parse_args()    \n",
    "\n",
    "logger.info(f'Training for {args.epochs} epochs using {args.imdir} data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa130c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image,label):\n",
    "    \"\"\" small function to normalize input images \"\"\"\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0994d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(imdir):\n",
    "    \"\"\" extract GTSRB dataset from directory \"\"\"\n",
    "    train_dataset = image_dataset_from_directory(imdir, \n",
    "                                       image_size=(32, 32),\n",
    "                                       batch_size=32,\n",
    "                                       validation_split=0.2,\n",
    "                                       subset='training',\n",
    "                                       seed=123,\n",
    "                                       label_mode='int')\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(imdir, \n",
    "                                        image_size=(32, 32),\n",
    "                                        batch_size=32,\n",
    "                                        validation_split=0.2,\n",
    "                                        subset='validation',\n",
    "                                        seed=123,\n",
    "                                        label_mode='int')\n",
    "    train_dataset = train_dataset.map(process)\n",
    "    val_dataset = val_dataset.map(process)\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a037944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datasets\n",
    "train_dataset, val_dataset = get_datasets(args.imdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7873596",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LrLogger()\n",
    "callbacks = [logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f50014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    net = tf.keras.models.Sequential()\n",
    "    input_shape = [32, 32, 3]\n",
    "    net.add(Conv2D(6, kernel_size=(3, 3), strides=(1, 1), activation='relu', \n",
    "                   input_shape=input_shape))\n",
    "    net.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    net.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1), activation='relu'))   \n",
    "    net.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(120, activation='relu'))\n",
    "    net.add(Dense(84, activation='relu'))\n",
    "    net.add(Dense(43))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d455e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `training.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f729752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, callbacks = exponential_decay(model, callbacks)\n",
    "model, callbacks = step_decay(model, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_dataset, \n",
    "                    epochs=args.epochs, \n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b984013",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Udacity's `utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b019a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(history):\n",
    "    \"\"\" plot loss and accuracy from keras history object \"\"\"\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].plot(history.history['loss'], linewidth=3)\n",
    "    ax[0].plot(history.history['val_loss'], linewidth=3)\n",
    "    ax[0].set_title('Loss', fontsize=16)\n",
    "    ax[0].set_ylabel('Loss', fontsize=16)\n",
    "    ax[0].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[0].legend(['train loss', 'val loss'], loc='upper right')\n",
    "    ax[1].plot(history.history['accuracy'], linewidth=3)\n",
    "    ax[1].plot(history.history['val_accuracy'], linewidth=3)\n",
    "    ax[1].set_title('Accuracy', fontsize=16)\n",
    "    ax[1].set_ylabel('Accuracy', fontsize=16)\n",
    "    ax[1].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[1].legend(['train acc', 'val acc'], loc='upper left')\n",
    "    ax[2].plot(history.history['lr'], linewidth=3)\n",
    "    ax[2].set_title('Learning rate', fontsize=16)\n",
    "    ax[2].set_ylabel('Learning Rate', fontsize=16)\n",
    "    ax[2].set_xlabel('Epoch', fontsize=16)\n",
    "    ax[2].legend(['learning rate'], loc='upper right')\n",
    "    # ax[2].ticklabel_format(axis='y', style='sci')\n",
    "    ax[2].yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56c340",
   "metadata": {},
   "source": [
    "## Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdb602",
   "metadata": {},
   "source": [
    "You can find pre-implemented schedulers (Keras naming convention for learning rate annealing strategies) \n",
    "[here](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40663c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f02419ab",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eede121",
   "metadata": {},
   "source": [
    "This assignment was prepared by Thomas Hossler et al., Winter 2021 (link [here](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)).\n",
    "\n",
    "Helpful resources:\n",
    "* [Learning Rate Schedule in Practice: an example with Keras and TensorFlow 2.0 by B. Chen | Medium](https://towardsdatascience.com/learning-rate-schedule-in-practice-an-example-with-keras-and-tensorflow-2-0-2f48b2888a0c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
