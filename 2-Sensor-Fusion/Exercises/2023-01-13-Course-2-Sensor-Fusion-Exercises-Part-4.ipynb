{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e00099",
   "metadata": {},
   "source": [
    "# Course 2: Sensor Fusion\n",
    "## Part 4: Unscented Kalman Filter (UKF)\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356551f1",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8fbff-7666-4865-b891-4ae5153ad231",
   "metadata": {},
   "source": [
    "* Work out the [Unscented Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter#Unscented_Kalman_filter) (UKF) predict and innovation / update equations;\n",
    "* Understand and apply the Constant Turn Rate and Velocity Magnitude (CTRV) motion model to our problem formulation;\n",
    "* Implement a radar sensor measurement and noise model;\n",
    "* Apply the UKF algorithm to the CTRV model and perform state / covariance estimation prediction using nonlinear functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d4f32",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8290dcc",
   "metadata": {},
   "source": [
    "### 1.1. Unscented Kalman Filter (UKF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf815099",
   "metadata": {},
   "source": [
    "#### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f369220",
   "metadata": {},
   "source": [
    "In this lesson, we will be building on our knowledge of the [extended Kalman filter](https://en.wikipedia.org/wiki/Extended_Kalman_filter) (EKF) [1] in order to implement an [Unscented Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter#Unscented_Kalman_filter)\n",
    " (UKF) [2][3] for object tracking with non-linear process and measurement models.\n",
    " \n",
    "Rather than linearising a non-linear process model, the Unscented Kalman filter [3] use a deterministic sampling technique known as an [unscented transformation](https://en.wikipedia.org/wiki/Unscented_transform) to pick a minimum set of sample points (known as sigma points) around the mean of the covariance. As a bit of history, this technique was first proposed in the Julier 1997 [2] paper as an efficient means of representing the probability distribution of a system in a Kalman filter. The paper by Wan et al., 2000 [3] builds on this by introducing a full definition of the Unscented Kalman filter (UKF) which uses a nonlinear transformation of sigma points to more accurately approximate the system's probability distribution. With these sigma point estimates we evaluate the original non-linear process model $\\mathcal{f}$ to estimate a new mean and covariance. The UKF approach is often more accurate than the extended Kalman filter (EKF) and avoids the computation of the Jacobians, which for some nonlinear high-dimensional / non-differentiable models is not possible.\n",
    "\n",
    "The origin of the UKF's name is somewhat up for debate, but one theory from Sebastian Thrun suggests that the filter was named out of distaste for the extended Kalman filter's linearisation technique. The EKF's linearisation about a single working point, and the need for Jacobian derivations, was said to be considered a \"stinky\" approach by the UKF's authors. Therefore, the UKF provided a (euphemistically) \"unscented\", i.e., more appealing, technique which better estimated a non-linear distribution. An alternative take on the UKF's name by Hao Li in their 2014 pre-print [4] suggests that the name is itself rooted in the \"scented\" process (verb: to _impart_ a pleasant scent onto) by which the extended Kalman filter emitted state estimations. Rather than gradually \"imparting\" (losing) desirable information about the true state of the object being estimated, the UKF provides an \"unscented\" (and presumably lossless) emission of state estimates without the loss of the true statistics of the object's actual state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ed384",
   "metadata": {},
   "source": [
    "#### From Extended- to Unscented Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef66253",
   "metadata": {},
   "source": [
    "The UKF uses the same prediction and update equations found in the extended Kalman filter [1]. The difference between the two, however, is how the UKF deals with non-linear process and measurement models. Rather than linearising the non-linear functions using a first-order Taylor expansion and deriving a Jacobian matrix, we instead sample a set of \"sigma points\" from a Gaussian distribution centred about the mean of the covariance given for the non-linear process model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef4379",
   "metadata": {},
   "source": [
    "#### UKF Process Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351e097",
   "metadata": {},
   "source": [
    "Given a state vector mean $x_{k\\vert k}$ and state covariance $\\mathrm{P}_{k\\vert k}$ at time-step $k$. Our goal with the UKF is to predict the mean state $x_{k+1 \\vert k}$ and covariance $\\mathrm{P}_{k+1\\vert k}$ to the next time-step $k+1$. Note that here we use the pipe \"$\\vert$\" notation to represent on the left-hand side the current estimated time-step, and on the right-hand side the latest considered measurement. For $x_{k\\vert k}$ and $\\mathrm{P}_{k\\vert k}$, we say that the estimation is for time-step $k$ and the measurement at time-step $k$ has already been taken into account — this is commonly referred to as the _posterior estimation_. On the other hand, for $x_{k+1\\vert k}$ and $\\mathrm{P}_{k+1\\vert k}$, we have the estimation for time-step $k+1$ which takes into account the measurement from the previous time-step $k$ — this is commonly referred to as the _a priori estimation_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc09345",
   "metadata": {},
   "source": [
    "<img src=\"figures/Exercises/2023-01-13-Figure-1-Unscented-Kalman-Filter-Estimation.png\" alt=\"Figure 1. The Unscented Kalman Filter — Posterior and A priori distributions formed by the state mean and covariance before- and after the estimation at time-step k+1.\">\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textrm{Figure 1. The Unscented Kalman Filter — Posterior and A priori distributions formed by the state mean and covariance before- and after estimation at time-step k+1.}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a2b7e",
   "metadata": {},
   "source": [
    "The two ellipses in Figure 1 above visualise the distribution of the uncertainty; all points along the perimeter of the ellipse have the same probability density. If the uncertainty is normally-distributed these points form the shape of the ellipse, as shown above (often called the \"error ellipse\"). The _A priori_ estimation is what is obtained after the prediction step of the UKF has been performed. These two ellipses can be seen as the visualisation of the covariance matrix $\\mathrm{P}$. Assuming a linear process model, we have a prediction step given by the equations:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1} &= \\mathrm{F}x_{k} + \\nu_{k}, \\\\\n",
    "\\mathcal{Q} &= E\\left[\\nu_{k} \\cdot \\nu_{k}^{\\top}\\right].\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here, $\\mathcal{Q}$ is the covariance matrix of the process noise. In the linear case, the Kalman filter is used to solve the prediction problem. A solution can be found with the following set of equations:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1 \\vert k} &= \\mathrm{F}x_{k \\vert k}, \\\\\n",
    "\\mathrm{P}_{k+1 \\vert k} &= \\mathrm{F}\\mathrm{P}_{k\\vert k}\\mathrm{F}^{\\top} + \\mathcal{Q}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "When the process model is non-linear, as in the case of our problem, we have the prediction step given as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1} &= \\mathcal{f}\\left(x_{k} + \\nu_{k}\\right), \\\\\n",
    "\\mathcal{Q} &= E\\left[\\nu_{k} \\cdot \\nu_{k}^{\\top}\\right].\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since the prediction step of a non-linear process model results in a non-linear distribution, it is no longer possible to directly represent the predicted state distribution, i.e., the a priori estimation, as a normal distribution forming an ellipse. We no longer have an analytical path, and therefore we need to find an approximate normal distribution that represents the original non-linear distribution as closely as possible. In order to do so, we find a normal distribution characterised by the same mean value and the covariance matrix as the _real_ predicted distribution. The question is, how do we derive this mean vector and this covariance matrix? This is what the unscented transformation does for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29ad55",
   "metadata": {},
   "source": [
    "###### Unscented Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f894072",
   "metadata": {},
   "source": [
    "To deal with non-linear functions, the UKF uses an [unscented transformation](https://en.wikipedia.org/wiki/Unscented_transform). The unscented transformation provides the mean state vector and covariance matrix needed to estimate the a priori normal distribution. By using sigma points, we are able to approximate the non-linear distribution using only a set of point estimates. These point estimates, called sigma points, are transformed into the predicted state-space using the non-linear process model function $\\mathcal{f}$. The sigma points are chosen relative to the mean state and are defined with respect to the standard deviation signal of every state dimension. This is why these points are called _sigma_ points; they serve as representatives of the whole distribution.\n",
    "\n",
    "Once the set of sigma points has been transformed into the predicted state-space by the non-linear function $\\mathcal{f}$, all that is left to do is calculate the mean and covariance of the sampled sigma points. The mean and covariance of the sigma points serves as only an approximation of the _real_ predicted distribution — but in most cases we get a useful estimation to work with.\n",
    "\n",
    "Another great thing about the unscented transformation and sigma point estimation is that, in the linear case, the _exact_ solution to the real predicted distribution can be derived. Thus, for a linear process model, the sigma points provide the exactly the same solution as the standard Kalman filter. Pretty neat, huh? While all this sounds great, using sigma points in the linear case isn't an entirely sound decision, since their added complexity weighs things down in terms of calculation time.\n",
    "\n",
    "As a recap, sigma points provide a way to estimate a non-linear distribution, providing the best possible mean and covariance estimates for a normal distribution assumption. Now, with the general idea of sigma points out of the way, let's dive into the meat of the Unscented Kalman filter — the _prediction_ and _update_ steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3217cc9",
   "metadata": {},
   "source": [
    "###### Prediction and Innovation of Sigma Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e956f",
   "metadata": {},
   "source": [
    "Starting with a state mean vector $x_{k \\vert k}$ and covariance $\\mathrm{P}_{k \\vert k}$, the prediction and update (also called _innovation_) steps of the UKF give us the updated state vector $x_{k+1 \\vert k}$ and covariance matrix $\\mathrm{P}_{k+1 \\vert k}$ predicted into the next time-step $k+1$. This is essential to applications such as object tracking where we must reliably estimate the change in vehicle position and orientation over a given time period $\\Delta t$.\n",
    "\n",
    "Since we begin the UKF process chain with the _prediction_ step, we split this into three parts: first, we need to know a good way to choose the sigma points. Secondly, we need to know how to predict the sigma points into the actual state-space of the process model. Lastly, we need to know how to calculate the prediction mean and covariance from the sigma point estimations.\n",
    "\n",
    "We start with prediction off with the posterior state $x_{k\\vert k}$ and the posterior covariance matrix $\\mathrm{P}_{k \\vert k}$ of the vehicle from the previous iteration. They represent the distribution of our vehicle's current state. This distribution is a linear, normal distribution from which we can generate our sigma points. The number of sigma points we generate at this step depends on the dimension of the state vector $n_{x}$. Since we describe in Sect 1.2. the CTRV model with state vector of dimension $5$, we say here that $n_{x} = 5$. We choose a number of sigma points\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "n_{\\sigma} &= 2*n_{x} + 1 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which, for the CTRV model gives us a total of $n_{\\sigma} = 2*\\left(5\\right) + 1 = 11$ points to generate. This corresponds to _one_ sigma point to represent the mean of the state, and another two sigma points for each dimension of the state. Each of these two sigma points are spread in opposite directions, and their \"spread\" is determined by a design parameter $\\lambda$ which governs their distance from the centre of the distribution (the mean point). Assuming a state vector of only the position $x_{k} = \\left[p_{x} p_{y}\\right]$, we can illustrate the rule for the sigma point matrix as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{X}_{k\\vert k} &= \\begin{bmatrix} x_{k\\vert k} & x_{k\\vert k} + \\sqrt{\\left(\\lambda + n_{x}\\right)\\mathrm{P}_{k\\vert k}} & x_{k \\vert k} - \\sqrt{\\left(\\lambda + n_{x}\\right)\\mathrm{P}_{k\\vert k}}\\end{bmatrix},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "such that the columns of the sigma point matrix $\\mathcal{X}_{k\\vert k}$ contain the set of $n_{\\sigma} = 5$ sigma points corresponding to the state dimension of the position coordinates of $n_{x} = 2$. The \"spreading factor\" in the square-root $\\left(\\lambda + n_{x}\\right)$ governs the spread of the sigma points, where $\\lambda = 3 - n_{x}$ is commonly chosen to compute this value. While it isn't directly relevant here, we will be using the [Cholesky decomposition](https://en.wikipedia.org/wiki/Cholesky_decomposition#Kalman_filters) to compute the square-root of the covariance matrix $\\mathrm{P}_{k \\vert k}$ as given by the decomposition $\\mathrm{A} = \\mathrm{L}\\mathrm{L}^{\\top}$ where the columns of $\\mathrm{L}$ are added and subtracted to the mean $x$ to form a set of $2*n_{x}$ vectors. Here, $\\mathrm{L}$ is the [lower triangular matrix](https://en.wikipedia.org/wiki/Lower_triangular_matrix) and, when $\\mathrm{A}$ is assumed to be a real (hence, symmetric positive-definite) matrix, $\\mathrm{L}$ is has real-valued positive entries along the diagonal. Also important to note for our later implementation of this sigma point generator function is that the first column of the matrix $\\mathcal{X}_{k\\vert k}$ is the mean of the distribution $x_{k\\vert k}$, the second through $n_{x} + 1$ column will be given by the second term above (with the addition sign between the mean and the square-root term), and the last $n_{x} + 2$ through $2 * n_{x} + 1$ columns will be given by the third term above (with the subtraction sign between the mean and the square-root term)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa393201",
   "metadata": {},
   "source": [
    "##### UKF Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71feb78b",
   "metadata": {},
   "source": [
    "Now that we know how to represent the uncertainty of the posterior state estimation using sigma points, accomplishing the second step of the UKF _prediction_ is nearly complete. Just plug in each sigma point into the non-linear process function $\\mathcal{f}$ to obtain the next-state estimation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1} &= \\mathcal{f}\\left(x_{k}, \\nu_{k}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "However, we have yet to consider the effect of the non-linear process noise vector $\\nu_{k}$. Fortunately, with the UKF we are able to handle non-linear process noise in a step known as _UKF augmentation_. To start, we recall the expression of the independent noise processes as stochastic properties (this will be covered in the next section for the CTRV model). From here, we write the process noise covariance matrix as the expression:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{Q} &= E\\left\\{\\nu_{k}\\cdot \\nu_{k}^{\\top}\\right\\} = \\begin{bmatrix}\\sigma_{a}^{2} & 0 \\\\ 0 & \\sigma_{\\ddot{\\psi}^{2}}\\end{bmatrix},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is a matrix that contains the variances of the noise processes for the longitudinal acceleration and change in yaw angle. Here, we consider the white-noise processes independent from each other (hence, the $0$ values along the diagonal).\n",
    "\n",
    "In the augmentation step, we form the _augmented_ state $x_{a}$ by adding the noise vector $\\nu_{k}$ to the state vector $x_{k}$. Repeating the sigma point generation for this augmented state vector $x_{a, k}$ and covariance matrix $\\mathrm{P}_{a, k \\vert k}$, we obtain a new set of sigma points representing the uncertainty caused by the sigma points. Note that the number of augmented sigma points computed here differs than in the first calculation, since we have an additional two terms added to the augmented state vector, resulting in the dimensions $n_{a} = n_{x} + 2$. From our earlier example, we obtain $n_{\\sigma_{a}} = 2*7 + 1 = 15$ augmented sigma points. This results in an augmented covariance matrix $\\mathrm{P}_{a, k\\vert k}$ of dimensions $7 \\times 7$ such that\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{P}_{a, k\\vert k} &= \\begin{bmatrix} \\mathrm{P}_{k, \\vert k} & 0 \\\\ 0 & \\mathcal{Q} \\end{bmatrix},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where the upper-left of the matrix is given as the original covariance matrix, and the lower-right of the matrix is the independent process noise covariance matrix defined above. The remaining values in the matrix are therefore set to zero.\n",
    "\n",
    "Lastly, we compute these sigma points in the exact same way as before. Just evaluate the expression for the previous sigma point matrix to get the augmented sigma point matrix $\\mathcal{X}_{a, k\\vert k}$. No need to modify the scaling factor on this one. Once the augmented sigma point matrix has been formed, simply plug these points into the process model $\\mathrm{f}$ using the process noise vector $\\nu_{k}$ to obtain the predicted sigma point matrix $\\mathcal{X}_{k+1\\vert k}$. You'll see in the following Sect. 1.2 the derivation of the state-space form of the process model $\\mathcal{f}$ and the expression for the next-state prediction, which we will evaluate in order to obtain this matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0ac13",
   "metadata": {},
   "source": [
    "##### Prediction and Innovation of Mean and Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac080e",
   "metadata": {},
   "source": [
    "Before jumping into the innovation step of the UKF, we finish off the prediction step by calculating the mean and covariance of the predicted state from the augmented sigma points we just derived. The standard rule for calculating the mean and covariance of a group of state samples is given by the following equations:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1\\vert k} &= \\sum_{i=0}^{n_{a}} w_{i}\\mathcal{X}_{k+1\\vert k, i}, \\\\\n",
    "\\mathrm{P}_{k+1 \\vert k} &= \\sum_{i=0}^{n_{a}} w_{i} \\left(\\mathcal{X}_{k+1\\vert k, i} - x_{k+1\\vert k}\\right)\\left(\\mathcal{X}_{k+1\\vert k, i} - x_{k+1\\vert k}\\right)^{\\top}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here, we compute the sum over the columns of the predicted sigma point matrix (hence, the sum from $i=0$ to $i=n_{a}$ where $n_{a}$ corresponds to the number of augmented sigma points). In these expressions is the use of a weight vector $w$ with values given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "w_{i} &= \n",
    "\\begin{cases}\n",
    "    \\frac{\\lambda}{\\lambda + n_{\\mathrm{aug}}}, & \\text{if} \\quad i = 0 \\\\\n",
    "    \\frac{1}{2}\\left(\\lambda + n_{\\mathrm{aug}}\\right), & \\text{otherwise}. \\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where the weight expression differs for the first element of the vector and all other elements $i = 1,\\ldots, n_{\\mathrm{aug}}$. Note that the dimension $n_{\\mathrm{aug}}$ is the dimension of the augmented state vector, which previously we assumed to be $n_{\\mathrm{aug}} = n_{x} + 2$. These weight values also depend on the spreading parameter $\\lambda$ which is used in the sigma point generation. This is to recover the covariance by inverting the spreading of the sigma points. There's more than one way to define these weights in literature, but for our implementation we use the expressions above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2867cab",
   "metadata": {},
   "source": [
    "##### Prediction of the Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba8d74",
   "metadata": {},
   "source": [
    "We have successfully arrived at the first step of the UKF _innovation_ / update process. Here, our goal is to transform the predicted state into the measurement space. The function that defines this transformation is the _measurement model_. Of course, here is now where we must consider the type of measurement we are transforming the predictions with respect to. For our later implementation we will be using a radar sensor model whose measurement vector $z_{k+1\\vert k}$ and expression of the measurement function $\\mathcal{h}$ are given as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z_{k+1\\vert k} &= \\begin{bmatrix} \\rho & \\phi & \\dot{\\rho} \\end{bmatrix}^{\\top}, \\\\\n",
    "\\\n",
    "z_{k+1} &= \\mathcal{h}\\left(x_{k+1}\\right) + \\omega_{k+1}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here, the $\\rho$ term is the measured radial distance ($\\mathrm{m}$), the $\\phi$ term is the heading angle ($\\mathrm{rad}$), and $\\dot{\\rho}$ as the rate-of-change of radial distance (i.e., velocity, $\\mathrm{m}/\\mathrm{s}^{2}$).\n",
    "\n",
    "This transformation process is very similar to the problem we had in the prediction step; we need to transform a distribution through a non-linear function $\\mathcal{h}$. Therefore, we apply the exact same unscented transformation approach as we did before during the state prediction. However, this time we take two shortcuts here: (1) we repeat the sigma point generation using the predicted mean and covariance matrix, and (2) hold out computing the effect of measurement noise on the radar model.\n",
    "\n",
    "Along the path of shortcut (1) we re-use the sigma points we have already generated from the prediction step and skip generating new sigma points all-together for the radar measurement. This allows us to also skip the augmentation step entirely with shortcut (2), since we assume here a purely _linear_ additive effect of measurement noise on the radar measurement model. This gives an easier way to consider measurement noise which we will jump back to later in the calculation of the measurement covariance matrix using matrix $\\mathrm{R}$. So for now, set the $\\omega_{k+1}$ term to be $0$.\n",
    "\n",
    "With these two simplifications, we only have to transform the individual sigma points we previously derived into the radar measurement space. Then, we use them to calculate the mean $z_{k+1\\vert k}$ and covariance $\\mathrm{S}$ of the predicted radar measurement. The re-used sigma points, after using them to evaluate the measurement model $\\mathcal{h}$, are stored in the radar sigma point matrix $\\mathcal{Z}_{k+1\\vert k}$.\n",
    "\n",
    "Applying the equations to our original problem formulation, we obtain a predicted sigma point matrix $\\mathcal{X}_{k+1 \\vert k}$ of dimensions $5 \\times 15$ and a transformed sigma point matrix into measurement space $\\mathcal{Z}_{k+1\\vert k}$ of dimensions $3 \\times 15$. The last step we have to do involving these sigma point matrices is to compute the predicted measurement mean $z_{k+1 \\vert k}$ and the predicted measurement covariance $\\mathrm{S}_{k+1\\vert k}$, as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "z_{k+1\\vert k} &= \\sum_{i=1}^{n_{\\sigma}} w_{i}\\mathcal{Z}_{k+1\\vert k, i}, \\\\\n",
    "\\mathrm{S}_{k+1\\vert k} &= \\sum_{i=0}^{n_{\\sigma}} w_{i}\\left(\\mathcal{Z}_{k+1 \\vert k, i} - z_{k+1\\vert k}\\right)\\left(\\mathcal{Z}_{k+1\\vert k, i} - z_{k+1\\vert k}\\right)^{\\top} + \\mathrm{R}. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In the above prediction equations we have the measurement noise covariance $\\mathrm{R}$ which follows $\\mathrm{R} = E\\{\\omega_{k} \\cdot \\omega_{k}^{\\top}\\}$. This applies to our case since the measurement noise of the radar sensor is linear and has a purely additive effect on the measurement model. Therefore, we obtain the covariance as the following:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{R} &= E\\{\\omega_{k} \\cdot \\omega_{k}^{\\top}\\} = \\begin{bmatrix}\\sigma_{\\rho}^{2} & 0 & 0 \\\\ 0 & \\sigma_{\\phi}^{2} & 0 \\\\ 0 & 0 & \\sigma_{\\dot{\\rho}}^{2}\\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1470f90",
   "metadata": {},
   "source": [
    "##### UKF Update Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e6bc8",
   "metadata": {},
   "source": [
    "We are finally at the last step of the UKF. This step is needed to update the state and covariance matrix using the received measurement. To recap, we have derived the predicted state mean $x_{k+1\\vert k}$ and the predicted covariance $\\mathrm{P}_{k+1\\vert k}$, as well as the predicted measurement mean $z_{k+1\\vert k}$ and measurement covariance $\\mathrm{S}_{k+1\\vert k}$. At time-step $k+1$ we receive a radar measurement $z_{k+1}$ which we will now use to update these four terms. Assuming we know the incoming measurement sensor type, we evaluate the respective measurement model and look into the measurement values. With this, we proceed to evaluate the standard Kalman filter update step equations but with just a slight caveat — the expression for the Kalman gain $\\mathrm{K}$ and consequently the state update $x_{k+1\\vert k+1}$ and covariance matrix update $\\mathrm{P}_{k+1\\vert k+1}$ rely on the computation of a cross-correlation matrix $\\mathrm{T}_{k+1\\vert k}$. This cross-correlation matrix is given as the difference between the sigma points defined in state-space $\\mathcal{X}_{k+1\\vert k}$ and the sigma points in measurement space $\\mathcal{Z}_{k+1\\vert k}$ and is as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T_{k+1\\vert k} &= \\sum_{i=0}^{n_{\\sigma}} w_{i}\\left(\\mathcal{X}_{k+1\\vert k, i} - x_{k+1\\vert k}\\right)\\left(\\mathcal{Z}_{k+1\\vert k, i} - z_{k+1\\vert k}\\right)^{\\top},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is used in the standard Kalman filter update equations:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{K}_{k+1\\vert k} &= \\mathrm{T}_{k+1\\vert k}\\mathrm{S}^{-1}_{k+1\\vert k}, \\\\\n",
    "x_{k+1 \\vert k+1} &= x_{k+1\\vert k} + \\mathrm{K}_{k+1\\vert k} \\left(z_{k+1} - z_{k+1\\vert k}\\right), \\\\\n",
    "P_{k+1\\vert k+1} &= \\mathrm{P}_{k+1\\vert k} - \\mathrm{K}_{k+1 \\vert k}\\mathrm{S}_{k+1\\vert k}\\mathrm{K}^{\\top}_{k+1\\vert k},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which are the expressions for the Kalman gain $\\mathrm{K}_{k+1\\vert k}$, the state update $x_{k+1\\vert k+1}$, and the covariance matrix update $\\mathrm{P}_{k+1\\vert k+1}$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1148f406",
   "metadata": {},
   "source": [
    "##### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533449bd",
   "metadata": {},
   "source": [
    "Congratulations! If you made it this far, you know have every equation and every detail needed to dive right into the implementation of the UKF in C++. While this was a long, enduring endeavour, I promise that the equations above serve almost their exact definitions when translated into C++ code (thanks to our use of the [Eigen](https://en.wikipedia.org/wiki/Eigen_\\(C%2B%2B_library\\)) matrix manipulation library). \n",
    "\n",
    "Ready to take on this challenge with us in Sect. 2.1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b932f",
   "metadata": {},
   "source": [
    "### 1.2. Constant Turn Rate and Velocity Magnitude (CTRV) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446db14",
   "metadata": {},
   "source": [
    "#### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efa399",
   "metadata": {},
   "source": [
    "As with most constant velocity models, the Constant Turn Rate and Velocity Magnitude (CTRV) model is a simplification of how objects actually navigate in real-world environments. The CTRV model assumes that an object (here, a vehicle), moves along a path with a constant turn-rate and constant velocity. Rather than a strict constant velocity, constant direction model, we allow the vehicle to travel a curved path with a constant heading / yaw angle. This additional assumption allows us to represent vehicle motion on roads with turns.  \n",
    "\n",
    "We will see in Figure 1 in the later part of this section that here we approximate the vehicle's constant turn-rate $\\psi$ with respect to a constant velocity $v$. In Figure 1 this is shown as a line tangential to the vehicle's actual (assumed) motion along a curved path. For now, just know that the CTRV model provides a decent starting point for representing vehicle behaviour in real traffic scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9a5ef",
   "metadata": {},
   "source": [
    "#### State equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753fed51",
   "metadata": {},
   "source": [
    "Using the CTRV model, a vehicle state at a given point in time can be represented with the following state vector: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x = \\begin{bmatrix}p_{x} & p_{y} & v & \\psi & \\dot{\\psi}\\end{bmatrix}^{\\top},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where the 2D vehicle position is given by $\\left(p_{x}, p_{y}\\right)$, the magnitude of velocity $v$, the orientation $\\psi$ (i.e., the yaw angle of the velocity component), and the rate-of-change of the orientation $\\dot{\\psi}$.\n",
    "\n",
    "##### Process model\n",
    "In order to represent a state change of the vehicle from time-step $k$ to $k+1$, we use the transition function:\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1\\vert k} &= \\mathcal{f}\\left(x_{k}, \\nu_{k}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The goal of the process model function represented above is to predict the state of the vehicle $x_{k+1 \\vert k}$ at the new time-step. To evaluate the process model $\\mathcal{f}$, we use the current vehicle state $x_{k}$ and the process noise $\\nu_{k}$ as inputs. In order to compute the state change, we must form an expression for the change-rate of the state $\\dot{x}$, given as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dot{x} &= \\begin{bmatrix}\\dot{p}_{x} & \\dot{p}_{y} & \\dot{v} & \\dot{\\psi}, & \\ddot{\\psi} \\end{bmatrix}^{\\top}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "From this relation we can directly derive the change-rate $\\dot{x}$ in terms of a differential equation $\\dot{x} = g\\left(x\\right)$.\n",
    "\n",
    "We can re-write each of the terms of the state differential independently of any of the state elements in $x$. For example, we can write $\\dot{p}_{x}$, i.e., the change in velocity along the $x$-axis, as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dot{p}_{x} = v_{x} = \\cos(\\psi)\\cdot v,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "assuming a constant direction from the current vehicle state $x_{k}$ and the predicted vehicle state $x_{k+1}$. With this, we form a trigonometric relation an derive the expressions of the other state variables as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dot{x} &= \n",
    "\\begin{bmatrix} \\dot{p}_{x} \\\\ \\dot{p}_{y} \\\\ \\dot{v} \\\\ \\dot{\\psi} \\\\ \\ddot{\\psi} \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\cos(\\psi) \\cdot v \\\\ \\sin(\\psi) \\cdot v \\\\ 0 \\\\ \\dot{\\psi} \\\\ 0 \n",
    "\\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Since we assume a constant turn-rate and a constant velocity, our expression for the rate-of-change of both these state variables is therefore equal to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09297013",
   "metadata": {},
   "source": [
    "In order to form an expression for the state change over time, we must define our time-step $\\Delta t$ as the change in time from $t_{k}$ to $t_{k+1}$. Our expression for the next-state $x_{k+1}$ is therefore:\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1} &= x_{k} + \\int_{t_{k}}^{t_{k+1}} \\begin{bmatrix} \\dot{p}_{x}(t), \\  \\dot{p}_{y}(t), \\ \\dot{v}(t), \\ \\dot{\\psi}(t), \\ \\ddot{\\psi}(t) \\end{bmatrix}^{\\top}dt.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Expanding the integral and replacing the derivative terms in the next-state vector, then solving for the integral terms, we obtain:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1} &= x_{k} + \\begin{bmatrix}v_{k}\\int_{t_{k}}^{t_{k+1}} \\mathrm{cos}\\left(\\psi_{k} + \\dot{\\psi} \\cdot\\left(t - t_{k}\\right)\\right) dt \n",
    "\\\\ v_{k}\\int_{t_{k}}^{t_{k+1}} \\mathrm{sin}\\left(\\psi_{k} + \\dot{\\psi} \\cdot\\left(t - t_{k}\\right)\\right) dt \n",
    "\\\\ 0 \n",
    "\\\\ \\dot{\\psi}_{k}\\cdot \\Delta t \n",
    "\\\\ 0 \\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "\\frac{v_{k}}{\\dot{\\psi}_{k}}\\left(\\mathrm{sin}\\left(\\psi_{k} + \\dot{\\psi}_{k}\\Delta t\\right) - \\mathrm{sin}\\left(\\psi_{k}\\right)\\right)\n",
    "\\\\ \\frac{v_{k}}{\\dot{\\psi}_{k}}\\left(-\\mathrm{cos}\\left(\\psi_{k} + \\dot{\\psi}_{k}\\Delta t\\right) + \\mathrm{cos}\\left(\\psi_{k}\\right)\\right)\n",
    "\\\\ 0\n",
    "\\\\ \\dot{\\psi}_{k} \\cdot \\Delta t\n",
    "\\\\ 0\n",
    "\\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "When the rate-of-change of the yaw angle $\\dot{\\psi}_{k} = 0 \\ \\mathrm{rad}/\\mathrm{s}^{2}$, the first two terms of the final state vector are reduced to $v_{k}\\cos\\left(\\psi_{k}\\right)\\cdot \\Delta t$ and $v_{k}\\tan\\left(\\psi_{k}\\right)\\cdot \\Delta t$, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327c4ef",
   "metadata": {},
   "source": [
    "<img src=\"figures/Exercises/2023-01-13-Figure-2-Constant-Turn-Rate-Constant-Velocity-Model.png\" alt=\"Figure 2. The Constant Turn Rate Constant Velocity (CTRV) model visualised.\">\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textrm{Figure 2. The Constant Turn Rate and Velocity Magnitude model.}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c24fa",
   "metadata": {},
   "source": [
    "In the above figure we depict the CTRV model assumption applied to the vehicle state at time-step $k$ to time-step $k+1$. The state transition is given by the process model $f$ which predicts the next-state of the vehicle at time $k+1$ using a constant velocity assumption — that is, assuming the vehicle proceeds to the next time-step with a constant heading angle $\\psi$ and a constant velocity $v$. The CTRV model assumption allows us to simplify the calculation of the velocity to its magnitude rather than in either the $x$- and $y$-direction. The CTRV model gives us a basis for the estimation by exploiting the geometry of the assumed next-state trajectory. With a rate-of-change of the yaw angle $\\ddot{\\psi}$, our state transition equation with vector $\\dot{x}$ becomes:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1} = x_{k} + \n",
    "\\begin{bmatrix}\n",
    "v_{k}\\cos\\left(\\psi_{k}\\right)\\Delta t \\\\\n",
    "v_{k}\\sin\\left(\\psi_{k}\\right)\\Delta t \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which completes our definition of the deterministic part of the process model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fb6ba",
   "metadata": {},
   "source": [
    "##### Uncertainty of the process model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d91c2",
   "metadata": {},
   "source": [
    "The stochastic part of the process model is defined with respect to a process noise vector $\\nu_{k} = \\left[\\nu_{a, k} \\nu_{\\ddot{\\psi}, k}\\right]^{\\top}$, which describe the two independent scalar noise processes. The first noise process is the longitudinal acceleration noise $\\nu_{a, k}$ which influences the longitudinal speed of the vehicle and it randomly changes its value at every time step $k$. The longitudinal acceleration is a normally-distributed white-noise with zero-mean and variance given by $\\sigma_{a}^{2}$. The other noise process is the yaw acceleration noise $\\nu_{\\ddot{\\psi}}$ which is also a normally-distributed white-noise with zero-mean and a variance given by $\\sigma_{\\ddot{\\psi}}^{2}$, i.e., \n",
    "$$\n",
    "\\begin{align}\n",
    "\\nu_{a, k} &\\sim \\mathcal{N}\\left(0, \\sigma_{a}^{2}\\right), \\\\\n",
    "\\nu_{\\ddot{\\psi}, k} &\\sim \\mathcal{N}\\left(0, \\sigma_{\\ddot{\\psi}}^{2}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The influence of the noise processes on the process model can be expressed in state-space form as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{k+1} = x_{k} + \n",
    "\\begin{bmatrix}\n",
    "\\frac{v_{k}}{\\dot{\\psi}_{k}} \\left(\\sin\\left(\\psi_{k} + \\dot{\\psi}_{k}\\Delta t\\right) - \\sin\\left(\\psi_{k}\\right)\\right) \\\\\n",
    "\\frac{v_{k}}{\\dot{\\psi}_{k}} \\left(-\\cos\\left(\\psi_{k} + \\dot{\\psi}_{k}\\Delta t\\right) + \\cos\\left(\\psi_{k}\\right)\\right) \\\\\n",
    "0 \\\\ \n",
    "\\dot{\\psi}_{k} \\Delta t\\\\\n",
    "0\n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{2}\\left(\\Delta t\\right)^{2} \\cos\\left(\\psi_{k}\\right)\\cdot \\nu_{a, k} \\\\\n",
    "\\frac{1}{2}\\left(\\Delta t\\right)^{2} \\sin\\left(\\psi_{k}\\right)\\cdot \\nu_{a, k} \\\\\n",
    "\\Delta t \\cdot \\nu_{a, k} \\\\\n",
    "\\frac{1}{2}\\left(\\Delta t\\right)^{2} \\cdot \\nu_{\\ddot{\\psi}, {k}} \\\\\n",
    "\\Delta t \\cdot \\nu_{\\ddot{\\psi}, k} \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and relies on the constant turn-rate assumption of the CTRV model, i.e., that the vehicle travels straight at time $t_{k+1}$ along the hypotenuse of the right-triangle formed in Figure 1 above. Note that this also assumes the effect of the yaw acceleration on the position to be zero, which in the non-zero case will result in the vehicle being on either side of the hypotenuse (since the non-zero yaw acceleration changes the radius of the circle formed by the trajectory the vehicle is travelling on)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c53015",
   "metadata": {},
   "source": [
    "With the CTRV model equations covered, we can now move onto the implementation of the Unscented Kalman filter (UKF). As we learned earlier, the UKF does not require us to compute the Jacobian matrix to linearise the non-linear process or measurement models. Instead, we form the representative sigma points sampled from a Gaussian distribution. These points will be then plugged into the non-linear process model equation above in order to estimate a new state mean and covariance using very similar equations to the standard Kalman filter for both the predict and innovation / update steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ce18a",
   "metadata": {},
   "source": [
    "##### Choosing process noise design parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a71b6",
   "metadata": {},
   "source": [
    "For the CTRV model, we have two design parameters representing process noise: $\\sigma_{a}^{2}$ and $\\sigma_{\\ddot{\\phi}}^{2}$. These are the longitudinal acceleration (i.e., linear acceleration) noise, and the yaw acceleration (i.e., angular acceleration) noise variances, respectively. In this part we will briefly cover the [estimation of these parameters](https://en.wikipedia.org/wiki/Kalman_filter#Estimation_of_the_noise_covariances_Qk_and_Rk). \n",
    "\n",
    "In order to \"tune\" these parameters to achieve optimal performance (the \"best\" covariance estimations), we have to first consider both the object and the scenario in which we are attempting to operate. For example, if we were designing a UKF to track a bicycle, we would want to select these two design parameters' values much differently than if we were designing for a vehicle tracking application. This is because of vehicle behaviour and object kinematics (motion assumptions). Additionally, we would want to select these two design parameters' values based on the driving scenario we are operating in. For example, we might expect a vehicle yaw angle to change much less frequently on a highway with nominal traffic conditions than in an urban environment with heavy traffic, where a vehicle might experience much more frequent sudden changes in speed and direction. Let's start by defining several rules-of-thumb for each parameter.\n",
    "\n",
    "The linear acceleration noise $\\sigma_{a}^{2}$ has the units $\\mathrm{m}^{2} / \\mathrm{s}^{4}$. If we take the square-root of the linear acceleration noise, i.e., $\\sqrt{\\sigma_{a}^{2}}$, we end up with a set of units $\\mathrm{m} / \\mathrm{s}^{2}$, which matches the units of acceleration. This will help us put our noise value into a frame of reference we can interpret using object kinematics. Next, we exploit the process noise model to derive insight about the distribution of the noise values. Since we chose to model the linear acceleration noise as a white-noise, normally-distributed process represented by a zero-mean Gaussian distribution parameterised by the standard deviation $\\sigma_{a} = \\pm\\sqrt{\\sigma_{a}^{2}} \\mathrm{m}/\\mathrm{s}^{2}$, we know that approximately 95% of our noise values are assumed to be within the standard deviation of $2\\sigma_{a}$. Therefore, if we select a $\\left(\\sigma_{a}\\right)^{2} = \\left(9 \\mathrm{m}/{\\mathrm{s}^{2}}\\right)^{2}$, then we know from our noise process assumption that we have a linear acceleration noise between $2\\times \\sqrt{\\sigma_{a}^{2}} =  \\pm 6 \\mathrm{m}/{\\mathrm{s}^{2}}$ roughly 95% of the time. With this we can choose a respective linear acceleration design parameter $\\sigma_{a}^{2}$ based on the expected behaviour of the object in the scenario we are attempting to model. As a rule-of-thumb, this parameter should be given a value in relation to the amount of expected maximum change in linear velocity. For vehicles in highly-dynamic environments with lots of stop-and-go braking / acceleration, such as in urban settings with dense traffic conditions, a choice of $\\left(\\sigma_{a}\\right)^{2} = \\left(9 \\mathrm{m}/\\mathrm{s}^{2}\\right)^{2}$ might be sufficient. For less-dynamic, more infrequent stop-and-go braking / acceleration, such an on highways with nominal traffic conditions, a choice of $\\left(\\sigma_{a}\\right)^{2} = \\left(3 \\mathrm{m}/\\mathrm{s}^{2}\\right)^{2}$ might be sufficient.\n",
    "\n",
    "The yaw acceleration noise $\\sigma_{\\ddot{\\psi}}^{2}$ has the units $\\mathrm{rad}/\\mathrm{s}^{2}$. This gives us an expression for the expected rate-of-change in the object's direction due to noise in the process model. Considering both the environment in which the system will operate — such as in an urban city, or along a highway, and the dynamics of the environment — such as the amount of turns / changes in direction expected, can help one select this yaw acceleration noise value appropriately. In highway driving scenarios with nominal traffic conditions, a choice of yaw acceleration noise $\\left(\\sigma_{\\ddot{\\psi}}\\right)^{2} = \\left(0.1 \\mathrm{rad}/\\mathrm{s}^{2}\\right)^{2}$ might be sufficient. For more-dynamic environments with dense traffic and tight city blocks, a choice of $\\left(\\sigma_{\\ddot{\\psi}}\\right)^{2} = \\left(0.3\\mathrm{rad}/\\mathrm{s}^{2}\\right)^{2}$ might be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c562b1",
   "metadata": {},
   "source": [
    "##### Evaluating design parameter values with Normalised Innovation Squared (NIS) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88738e62",
   "metadata": {},
   "source": [
    "Choosing process noise design parameters blindly, or with faulty / incorrect assumptions can lead to poor performance and consistency in the UKF. Therefore, a consistency check called the [Normalised Innovation Squared](https://kalman-filter.com/normalized-innovation-squared/) (NIS) method can be applied to determine if the Kalman filter is consistent with the current measurement residual $\\nu\\left(k\\right) = \\left(z_{k+1} - z_{k+1\\vert k}\\right)$ and the measurement covariance matrix $\\mathrm{S}_{k+1\\vert k}$. The resulting consistency score $\\epsilon_{\\nu}$ gives an estimate of the acceptance region in which the normalised difference in the innovation step should be when the Kalman filter is performing as-expected. This score is therefore given as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{NIS}\\left(\\nu\\left(k\\right), \\mathrm{S}_{k}\\right) &= \\epsilon_{\\nu} = \\left(z_{k+1} - z_{k+1\\vert k} \\right)^{\\top}\\cdot \\mathrm{S}_{k+1\\vert k}^{-1}\\cdot \\left(z_{k+1} - z_{k+1\\vert k}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In order to evaluate the NIS error $\\epsilon_{\\nu}$, we first make the assumption that $\\epsilon_{\\nu}$ is sampled from a [chi-square distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution) with dimensions $\\mathrm{dim}\\left(\\nu\\left(k\\right)\\right) = n_{z}$, i.e., the dimension of the measurement vector $z_{k+1}$. Then, a hypothesis test is performed with the following setup:\n",
    "\n",
    "* $\\mathrm{H}_{0}$: The measurement residual $\\nu\\left(k\\right)$ is consistent with the innovation measurement covariance matrix $\\mathrm{S}_{k+1\\vert k}$ and is accepted if $\\epsilon_{\\nu} \\in \\left[r_{1}, r_{2}\\right]$.\n",
    "\n",
    "The acceptance interval is chosen such that the probability $\\mathrm{P}$ that $\\mathrm{H}_{0}$ is accepted is $\\left(1 - \\alpha\\right)$. The confidence interval $\\left[r_{1}, r_{2}\\right]$ is calculated using the inverse of the cumulative distribution function (CDF) of the chi-square distribution as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "r_{1} &= \\mathrm{F}^{-1}\\left(\\frac{\\alpha}{2}, n_{z}\\right), r_{2} = \\mathrm{F}^{-1}\\left(1 - \\frac{\\alpha}{2}, n_{z}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "One can alternatively use a look-up table for the given measurement vector dimension $n_{x}$ and acceptance region $\\left(1-\\alpha\\right)$.\n",
    "\n",
    "Additionally, plotting the NIS score for each time-step $k$ may be a helpful indication of consistency. NIS scores that consistently place near the confidence threshold $\\alpha$ (e.g., $\\alpha = 0.95$) tend to indicate that the selected design parameters are performing well. NIS score values that are _well below_ the $\\alpha$ threshold indicate that the design parameters _overestimate_ the uncertainty, and conversely NIS score values that are consistently _well above_ the $\\alpha$ threshold indicate that the design parameters _underestimate_ the uncertainty.\n",
    "\n",
    "In conclusion, the Normalised Innovation Squared (NIS) test can help one evaluate the consistency of the innovation measurement covariance matrix $\\mathrm{S}_{k+1\\vert k}$. Since this matrix directly influences the Kalman gain $\\mathrm{K}$ and therefore the overall efficiency of the Kalman filter, taking the time to evaluate this metric is generally a great idea. Fun fact before we move on: The NIS test comes from the [Normalised Estimation Error Squared](https://kalman-filter.com/normalized-estimation-error-squared/) (NEES) test, but is practical in settings where ground-truth data is not provided. While the NEES test provides deeper insight in \"truth model simulation\" settings, the NIS test can be used in online real-world applications which do not have access to the true state vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540bd542",
   "metadata": {},
   "source": [
    "#### Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a01090",
   "metadata": {},
   "source": [
    "Before we close this discussion on the Constant Turn Rate and Velocity Magnitude (CTRV) model, we want to mention that there are several other common motion models one may consider. Those are:\n",
    "\n",
    "* **Constant Turn Rate and Acceleration (CTRA)**;\n",
    "* **Constant Steering Angle and Velocity (CSAV)**;\n",
    "* **Constant Curvature and Acceleration (CCA)**.\n",
    "\n",
    "Each model makes a different assumption about the vehicle's motion, and therefore choosing a model is quite an important step. For the remainder of this notebook, we make explicit reference to the CTRV model when designing our Unscented Kalman filter in C++."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e3b42",
   "metadata": {},
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99ef48",
   "metadata": {},
   "source": [
    "In this section we combine our knowledge of the Unscented Kalman filter (UKF) and the Constant Turn Rate and Velocity Magnitude (CTRV) model with our C++ programming skills to implement the filter for vehicle tracking.\n",
    "\n",
    "Here we use the [Eigen](https://en.wikipedia.org/wiki/Eigen_\\(C%2B%2B_library\\)) C++ matrix manipulation library to represent and perform operations on both the vectors and matrices we described earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84ae09",
   "metadata": {},
   "source": [
    "### 2.1. Unscented Kalman Filter in C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae94b17-98ea-4313-a8f6-26e7cc1e0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b1f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* ----------------------------------------------------------------------------\n",
    " * Lesson \"2.5: Unscented Kalman Filters\"\n",
    " * Authors     : Dominik Nuss, Andrei Vatavu.\n",
    " *\n",
    " * Modified by : Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    " *\n",
    " * Purpose of this file: Header file for the Unscented Kalman Filter (UKF).\n",
    " * ----------------------------------------------------------------------------\n",
    " */\n",
    "\n",
    "#include \"include/eigen/Eigen/Dense\"\n",
    "#include <random>\n",
    "#include <cmath>\n",
    "#include <iostream>\n",
    "\n",
    "\n",
    "/* The Unscented Kalman Filter (UKF) class.\n",
    " */\n",
    "class UKF {\n",
    " public:\n",
    "  UKF() {};\n",
    "  virtual ~UKF() {};\n",
    "  // Initalises the UKF instance\n",
    "  void InitFilter();\n",
    "  // Computes the sigma points from the state vector / covariance matrix\n",
    "  void GenerateSigmaPoints(\n",
    "      Eigen::MatrixXd* Xsig_out\n",
    "  );\n",
    "  // Computes the sigma points from the augemnted state / covariance\n",
    "  void AugmentedSigmaPoints(\n",
    "      Eigen::MatrixXd* Xsig_out\n",
    "  );\n",
    "  // Evaluates the state prediction / state transition function \n",
    "  void SigmaPointPrediction(\n",
    "      Eigen::MatrixXd* Xsig_out\n",
    "  );\n",
    "  // Normalises heading angle of state estimation to a value in range [-pi, pi]\n",
    "  Eigen::VectorXd NormaliseHeading(\n",
    "      Eigen::VectorXd Xsig_pred_diff\n",
    "  );\n",
    "  // Performs the prediction of the state estimation and covariance matrix\n",
    "  void PredictMeanAndCovariance(\n",
    "      Eigen::VectorXd* x_pred, \n",
    "      Eigen::MatrixXd* P_pred\n",
    "  );\n",
    "  // Predicts the radar measurement vector and covariance in innovation step\n",
    "  void PredictRadarMeasurement(\n",
    "      Eigen::VectorXd* z_out, \n",
    "      Eigen::MatrixXd* S_out\n",
    "  );\n",
    "  void UpdateState(\n",
    "      Eigen::VectorXd* x_out, \n",
    "      Eigen::MatrixXd* P_out\n",
    "  );\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e0d976",
   "metadata": {},
   "source": [
    "#### 2.1.1. Generating Sigma Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee02227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168a5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Constructs the sigma point matrix.\n",
    " *\n",
    " * Implements the sigma point estimation for use in the prediction step.\n",
    " * The UKF performs an unscented transformation which approximates a normal\n",
    " * distribution from the non-linear posterior state estimation.\n",
    " *\n",
    " * Here the sigma points are determined with respect to the dimension of the\n",
    " * state vector and a spreading factor $\\lambda$. This design parameter\n",
    " * governs how \"close\" a sigma point is to the mean $x_{k\\vert k}$, i.e.,\n",
    " * the posterior state estimation from the previous time-step. The posterior\n",
    " * covariance matrix $\\mathrm{P}_{k\\vert k}$ is also used in the calculation\n",
    " * of the sigma points. The output matrix $\\mathcal{x}_{k\\vert k} stores\n",
    " * the resulting sigma points (`Xsig_out` in the function).\n",
    " * \n",
    " * @param  Xsig_out   Matrix to store resulting sigma points.\n",
    " */\n",
    "void UKF::GenerateSigmaPoints(\n",
    "    Eigen::MatrixXd* Xsig_out\n",
    ") {\n",
    "  // Set the state dimension\n",
    "  int n_x = 5;\n",
    "  // Calculate the number of sigma points to compute\n",
    "  int n_sigma_points = 2 * n_x + 1; \n",
    "  // Define the spreading parameter\n",
    "  double lambda = 3 - n_x;\n",
    "  // Set the state vector values\n",
    "  // Here, this is assumed to be the mean of the posterior state estimation\n",
    "  Eigen::VectorXd x(n_x);\n",
    "  x << 5.7441,\n",
    "       1.3800,\n",
    "       2.2049,\n",
    "       0.5015,\n",
    "       0.3528;\n",
    "  // Set the covariance matrix values\n",
    "  // Here, this is assumed to be the covariance of posterior state estimation\n",
    "  Eigen::MatrixXd P(n_x, n_x);\n",
    "  P << 0.0043,   -0.0013,    0.0030,   -0.0022,   -0.0020,\n",
    "      -0.0013,    0.0077,    0.0011,    0.0071,    0.0060,\n",
    "       0.0030,    0.0011,    0.0054,    0.0007,    0.0008,\n",
    "      -0.0022,    0.0071,    0.0007,    0.0098,    0.0100,\n",
    "      -0.0020,    0.0060,    0.0008,    0.0100,    0.0123;\n",
    "  // Create the sigma point matrix\n",
    "  Eigen::MatrixXd Xsig(n_x, n_sigma_points);\n",
    "  // Calculate square-root of matrix `P`\n",
    "  // `A` is the lower-triangular matrix of the Cholesky decomposition\n",
    "  Eigen::MatrixXd A = P.llt().matrixL();\n",
    "  /*** Calculate the set of sigma points ***/\n",
    "  // Set the first column to the mean of the posterior state estimation\n",
    "  Xsig.col(0) = x;\n",
    "  // Compute the square-root term for the sigma point vector\n",
    "  // The square-root of the spreading term\n",
    "  double spreading_factor = std::sqrt(lambda + n_x);\n",
    "  // Loop through the columns of `A` to compute columns of `Xsig`\n",
    "  for (int i = 0; i < n_x; i++) {\n",
    "    // First, update the lower column terms\n",
    "    // Note the array indexing of `A` starting at 0\n",
    "    Xsig.col(i + 1) = x + spreading_factor * A.col(i);\n",
    "    // Then, update the upper column terms\n",
    "    Xsig.col(i + n_x + 1) = x - spreading_factor * A.col(i);\n",
    "  }\n",
    "  // Print the resulting matrix\n",
    "  // std::cout << \"Xsig = \" << \"\\n\" << Xsig << \"\\n\";\n",
    "  // Update the input pointer to the output result\n",
    "  *Xsig_out = Xsig;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589d051",
   "metadata": {},
   "source": [
    "##### Testing the generate sigma points function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355bc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `5_tests.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f813fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Evaluates the result of the `GenerateSigmaPoints` function.\n",
    " *\n",
    " * The actual sigma points produced by the function are compared to the\n",
    " * expected matrix of sigma point values by computing the Frobenius L2\n",
    " * norm (matrix norm). If the resulting L2 norm value is less than the\n",
    " * `epsilon` threshold, the two matrices are said to be roughly equal.\n",
    " */\n",
    "void test_generate_sigma_points() {\n",
    "  // Create the Unscented Kalman Filter (UKF) instance\n",
    "  UKF ukf;\n",
    "  // Instantiate the sigma point output matrix \n",
    "  Eigen::MatrixXd Xsig(5, 11);\n",
    "  // Generate the sigma points and write them to the output matrix\n",
    "  ukf.GenerateSigmaPoints(&Xsig);\n",
    "  // Print the resulting values\n",
    "  std::cout << \"Xsig = \" << \"\\n\" << Xsig << \"\\n\";\n",
    "  // Perform L2 norm to compare the two matrices\n",
    "  Eigen::MatrixXd Xsig_expected(5, 11);\n",
    "  Xsig_expected <<\n",
    "    5.7441,  5.85768,   5.7441,   5.7441,   5.7441,   5.7441,  5.63052,   5.7441,   5.7441,   5.7441,   5.7441,\n",
    "    1.38,  1.34566,  1.52806,     1.38,     1.38,     1.38,  1.41434,  1.23194,     1.38,     1.38,     1.38,\n",
    "    2.2049,  2.28414,  2.24557,  2.29582,   2.2049,   2.2049,  2.12566,  2.16423,  2.11398,   2.2049,   2.2049,\n",
    "    0.5015,  0.44339, 0.631886, 0.516923, 0.595227,   0.5015,  0.55961, 0.371114, 0.486077, 0.407773,   0.5015,\n",
    "    0.3528, 0.299973, 0.462123, 0.376339,  0.48417, 0.418721, 0.405627, 0.243477, 0.329261,  0.22143, 0.286879;\n",
    "  double epsilon = 0.001;\n",
    "  std::cout << \"Result matches expected by amount `epsilon = \" << epsilon << \"`\";\n",
    "  std::cout << \": \" << std::boolalpha << Xsig.isApprox(Xsig_expected, epsilon) << \"\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8fb90d-0043-4dab-993b-9ff0d4762518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xsig = \n",
      "  5.7441  5.85768   5.7441   5.7441   5.7441   5.7441  5.63052   5.7441   5.7441   5.7441   5.7441\n",
      "    1.38  1.34566  1.52806     1.38     1.38     1.38  1.41434  1.23194     1.38     1.38     1.38\n",
      "  2.2049  2.28414  2.24557  2.29582   2.2049   2.2049  2.12566  2.16423  2.11398   2.2049   2.2049\n",
      "  0.5015  0.44339 0.631886 0.516923 0.595227   0.5015  0.55961 0.371114 0.486077 0.407773   0.5015\n",
      "  0.3528 0.299973 0.462123 0.376339  0.48417 0.418721 0.405627 0.243477 0.329261  0.22143 0.286879\n",
      "Result matches expected by amount `epsilon = 0.001`: true\n"
     ]
    }
   ],
   "source": [
    "// Exercise 2.5.1: Generating Sigma Points\n",
    "test_generate_sigma_points();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc67b7df",
   "metadata": {},
   "source": [
    "#### 2.1.2. UKF Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6092899",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6621c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Constructs the augmented sigma point matrix. \n",
    " *\n",
    " * Implements the sigma point estimation for the process noise $\\nu_{k}$\n",
    " * used in the prediction step of the Unscented Kalman Filter.\n",
    " * \n",
    " * Here the augmented sigma points are determined with respect to the dimension\n",
    " * of the augmented state vector $x_{a, k}$ and augmented process noise\n",
    " * covariance matrix $\\mathrm{P}_{a, k\\vert k}$. The mean of the process noise\n",
    " * is assumed to be zero. The augmented sigma points are computed with a design\n",
    " * parameter $\\lambda$ which governs how \"close\" an augmented sigma point is to\n",
    " * the mean $x_{a, k\\vert k}$.\n",
    " *\n",
    " * @param  Xsig_out   Matrix to store resulting augmented sigma points. \n",
    " */\n",
    "void UKF::AugmentedSigmaPoints(\n",
    "    Eigen::MatrixXd* Xsig_out\n",
    ") {\n",
    "  // Set the state dimension\n",
    "  int n_x = 5;\n",
    "  // Set the augmented dimension\n",
    "  // Process noise $\\nu_{k}$ has the terms $\\nu_{a, k}$, $\\nu_{\\ddot{psi},k}$\n",
    "  int n_a = 2;\n",
    "  // The process noise dimension added to the state vector dimension\n",
    "  int n_aug = n_x + n_a;\n",
    "  // Calculate the number of sigma points to compute\n",
    "  int n_sigma_points = 2 * n_aug + 1;\n",
    "  // Process noise standard deviation of longitudinal acceleration (m/s^2)\n",
    "  double std_a = 0.2;\n",
    "  // Process noise standard deviation of yaw acceleration (rad/s^2)\n",
    "  double std_yawdd = 0.2;\n",
    "  // Define the spreading parameter\n",
    "  double lambda = 3 - n_aug;\n",
    "  // Define the independent noise processes\n",
    "  // Here, both are zero-mean white-noise processes\n",
    "  std::normal_distribution<double> nu_a(0.0, std_a);\n",
    "  std::normal_distribution<double> nu_yawdd(0.0, std_yawdd);\n",
    "  // Define the noise processes vector and set its values\n",
    "  std::default_random_engine rand_gen;\n",
    "  Eigen::VectorXd nu_k(n_a, 1);\n",
    "  nu_k << nu_a(rand_gen),\n",
    "          nu_yawdd(rand_gen);\n",
    "  // Set the state vector values\n",
    "  // Here, this is assumed to be the mean of the posterior state estimation\n",
    "  Eigen::VectorXd x(n_x);\n",
    "  x << 5.7441,\n",
    "       1.3800,\n",
    "       2.2049,\n",
    "       0.5015,\n",
    "       0.3528;\n",
    "  // Set the covariance matrix values\n",
    "  // Here, this is assumed to be the covariance of posterior state estimation\n",
    "  Eigen::MatrixXd P(n_x, n_x);\n",
    "  P << 0.0043,   -0.0013,    0.0030,   -0.0022,   -0.0020,\n",
    "      -0.0013,    0.0077,    0.0011,    0.0071,    0.0060,\n",
    "       0.0030,    0.0011,    0.0054,    0.0007,    0.0008,\n",
    "      -0.0022,    0.0071,    0.0007,    0.0098,    0.0100,\n",
    "      -0.0020,    0.0060,    0.0008,    0.0100,    0.0123;\n",
    "  // Instantiate the augmented mean vector\n",
    "  Eigen::VectorXd x_aug(n_aug);\n",
    "  // Instantiate the augmented state covariance matrix\n",
    "  Eigen::MatrixXd P_aug(n_aug, n_aug);\n",
    "  // Instantiate the augmented sigma point matrix\n",
    "  Eigen::MatrixXd Xsig_aug(n_aug, n_sigma_points);\n",
    "  // Compute the values of the augmented mean state vector\n",
    "  // Set the first `n_x` values to be the state vector \n",
    "  x_aug.head(n_x) = x;\n",
    "  // Set the last values to be the mean of the noise processes\n",
    "  x_aug.row(5) << nu_a.mean();\n",
    "  x_aug.row(6) << nu_yawdd.mean(); \n",
    "  // Compute the values of the augmented covariance matrix\n",
    "  Eigen::MatrixXd Q(n_a, n_a);\n",
    "  Q << std_a * std_a, 0.0,\n",
    "       0.0, std_yawdd * std_yawdd;\n",
    "  P_aug.fill(0.0);\n",
    "  P_aug.topLeftCorner(n_x, n_x) = P;\n",
    "  P_aug.bottomRightCorner(n_a, n_a) = Q;\n",
    "  // Calcualte the square-root of the augmented covariance matrix\n",
    "  // `A` is the lower-triangular matrix of the Cholesky decomposition\n",
    "  Eigen::MatrixXd A_aug = P_aug.llt().matrixL();\n",
    "  /*** Calculate the set of augmented sigma points ***/\n",
    "  // Set the first column as mean of augmented posterior state estimation\n",
    "  Xsig_aug.col(0) = x_aug;\n",
    "  // Compute the square-root term for the augmented sigma point vector\n",
    "  // The square-root of the spreading term\n",
    "  double spreading_factor = std::sqrt(lambda + n_aug);\n",
    "  // Loop through the columns of `A` to compute columns of `Xsig_aug`\n",
    "  for (int i = 0; i < n_aug; i++) {\n",
    "    // First, update the lower column terms\n",
    "    // Note the array indexing of `A` starting at 0\n",
    "    Xsig_aug.col(i + 1) = x_aug + spreading_factor * A_aug.col(i);\n",
    "    // Then, update the upper column terms\n",
    "    Xsig_aug.col(i + n_aug + 1) = x_aug - spreading_factor * A_aug.col(i);\n",
    "  }\n",
    "  // Print the resulting augmented sigma point matrix\n",
    "  // std::cout << \"Xsig_aug = \" << \"\\n\" << Xsig_aug << \"\\n\";\n",
    "  // Update the input pointer to the output result\n",
    "  *Xsig_out = Xsig_aug; \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d43863",
   "metadata": {},
   "source": [
    "##### Testing the sigma point augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2a02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `5_tests.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d3c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Evaluates the result of the `AugmentedSigmaPoints` function.\n",
    " *\n",
    " * The actual augmented sigma points produced by the function are compared\n",
    " * to the expected matrix of augmented sigma point values by computing the\n",
    " * Frobenius L2 norm (matrix norm). If the resulting L2 norm value is less\n",
    " * than the `epsilon` threshold, the two matrices are said to be roughly\n",
    " * equal.\n",
    " */\n",
    "void test_augmented_sigma_points() {\n",
    "  // Create the Unscented Kalman Filter (UKF) instance\n",
    "  UKF ukf;\n",
    "  // Instantiate the augmented sigma point matrix\n",
    "  // Note: We assume the dimension of the augmented state vector to be `7`,\n",
    "  // and the number of augmented sigma points generated to be `15`\n",
    "  Eigen::MatrixXd Xsig_aug(7, 15);\n",
    "  // Generate the augmented sigma points and write them to the output matrix\n",
    "  ukf.AugmentedSigmaPoints(&Xsig_aug);\n",
    "  // Print the resulting values\n",
    "  std::cout << \"Xsig_aug = \" << \"\\n\" << Xsig_aug << \"\\n\";\n",
    "  // Perform the L2 norm to compare the two matrices\n",
    "  Eigen::MatrixXd Xsig_aug_expected(7, 15);\n",
    "  Xsig_aug_expected <<\n",
    "  5.7441,  5.85768,   5.7441,   5.7441,   5.7441,   5.7441,   5.7441,   5.7441,  5.63052,   5.7441,   5.7441,   5.7441,   5.7441,   5.7441,   5.7441,\n",
    "    1.38,  1.34566,  1.52806,     1.38,     1.38,     1.38,     1.38,     1.38,  1.41434,  1.23194,     1.38,     1.38,     1.38,     1.38,     1.38,\n",
    "  2.2049,  2.28414,  2.24557,  2.29582,   2.2049,   2.2049,   2.2049,   2.2049,  2.12566,  2.16423,  2.11398,   2.2049,   2.2049,   2.2049,   2.2049,\n",
    "  0.5015,  0.44339, 0.631886, 0.516923, 0.595227,   0.5015,   0.5015,   0.5015,  0.55961, 0.371114, 0.486077, 0.407773,   0.5015,   0.5015,   0.5015,\n",
    "  0.3528, 0.299973, 0.462123, 0.376339,  0.48417, 0.418721,   0.3528,   0.3528, 0.405627, 0.243477, 0.329261,  0.22143, 0.286879,   0.3528,   0.3528,\n",
    "       0,        0,        0,        0,        0,        0,  0.34641,        0,        0,        0,        0,        0,        0, -0.34641,        0,\n",
    "       0,        0,        0,        0,        0,        0,        0,  0.34641,        0,        0,        0,        0,        0,        0, -0.34641;\n",
    "  // Precision (i.e., max allowed magnitude of the two matrices' L2 distance)\n",
    "  double epsilon = 0.001;\n",
    "  std::cout << \"Result matches expected by amount `epsilon = \" << epsilon << \"`\";\n",
    "  std::cout << \": \" << std::boolalpha << Xsig_aug.isApprox(Xsig_aug_expected, epsilon) << \"\\n\"; \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a6add6-98e0-4cd0-8f01-369cb7d87589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xsig_aug = \n",
      "  5.7441  5.85768   5.7441   5.7441   5.7441   5.7441   5.7441   5.7441  5.63052   5.7441   5.7441   5.7441   5.7441   5.7441   5.7441\n",
      "    1.38  1.34566  1.52806     1.38     1.38     1.38     1.38     1.38  1.41434  1.23194     1.38     1.38     1.38     1.38     1.38\n",
      "  2.2049  2.28414  2.24557  2.29582   2.2049   2.2049   2.2049   2.2049  2.12566  2.16423  2.11398   2.2049   2.2049   2.2049   2.2049\n",
      "  0.5015  0.44339 0.631886 0.516923 0.595227   0.5015   0.5015   0.5015  0.55961 0.371114 0.486077 0.407773   0.5015   0.5015   0.5015\n",
      "  0.3528 0.299973 0.462123 0.376339  0.48417 0.418721   0.3528   0.3528 0.405627 0.243477 0.329261  0.22143 0.286879   0.3528   0.3528\n",
      "       0        0        0        0        0        0  0.34641        0        0        0        0        0        0 -0.34641        0\n",
      "       0        0        0        0        0        0        0  0.34641        0        0        0        0        0        0 -0.34641\n",
      "Result matches expected by amount `epsilon = 0.001`: true\n"
     ]
    }
   ],
   "source": [
    "// Exercise 2.5.2: Generating Augmented Sigma Points\n",
    "test_augmented_sigma_points();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0626f0a3",
   "metadata": {},
   "source": [
    "#### 2.1.3. Sigma Point Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba4846ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd7505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Constructs the predicted state estimation from the augmented sigma points.\n",
    " *\n",
    " * Implements the CTRV model (i.e., Constant Turn Rate and Velocity Magnitude).\n",
    " * Here, the augmented sigma points are used to evaluate the non-linear process\n",
    " * model function $\\mathcal{f}$ w.r.t. $\\Delta t$.\n",
    " * \n",
    " * The resulting point predictions are written to the right-column of the\n",
    " * predicted state estimation matrix (ensuring divide-by-zero does not occur).\n",
    " * \n",
    " * @param  Xsig_out   Matrix to store the resulting sigma point predictions.\n",
    " */\n",
    "void UKF::SigmaPointPrediction(\n",
    "    Eigen::MatrixXd* Xsig_out\n",
    ") {\n",
    "  /*** Set the state variables (values should match across functions) ***/\n",
    "  // Set the state dimension\n",
    "  int n_x = 5;\n",
    "  // Set the augmented dimension\n",
    "  // Process noise $\\nu_{k}$ has the terms $\\nu_{a, k}$, $\\nu_{\\ddot{psi},k}$\n",
    "  int n_a = 2;\n",
    "  // The process noise dimension added to the state vector dimension\n",
    "  int n_aug = n_x + n_a;\n",
    "  // Calculate the number of sigma points to compute\n",
    "  int n_sigma_points = 2 * n_aug + 1;\n",
    "  // Define the spreading parameter\n",
    "  double lambda = 3 - n_aug;\n",
    "  // Get the augmented sigma point matrix\n",
    "  Eigen::MatrixXd Xsig_aug(n_aug, n_sigma_points);\n",
    "  AugmentedSigmaPoints(&Xsig_aug);\n",
    "  /*** Compute the predicted sigma point matrix ***/\n",
    "  // Instantiate the predicted sigma point matrix\n",
    "  Eigen::MatrixXd Xsig_pred(n_x, n_sigma_points);\n",
    "  // Define the delta-time variable (s)\n",
    "  double delta_t = 0.1;\n",
    "  // Write the predicted sigma points into right-column of the output matrix\n",
    "  for (int i = 0; i < n_sigma_points; i++) {\n",
    "    // Get the state vector values from the augmented sigma point matrix\n",
    "    Eigen::VectorXd x_k(n_x, 1);\n",
    "    x_k << Xsig_aug.col(i).head(n_x);\n",
    "    // Get the mean-values of the noise processes\n",
    "    Eigen::VectorXd nu_mean_k(n_a, 1);\n",
    "    // i.e., the last `n_a` values in state vector\n",
    "    nu_mean_k << Xsig_aug.col(i).tail(n_a);\n",
    "    // Predict the sigma point by forming the process model in state-space\n",
    "    // The vector for the state transition equation \n",
    "    Eigen::VectorXd Fx_k(n_x, 1);\n",
    "    // The vector of the process noise values evaluated w.r.t. time\n",
    "    Eigen::VectorXd nu_k(n_x, 1);\n",
    "    // Get the variables w.r.t. this sigma point\n",
    "    double v_k = x_k(2);\n",
    "    double yaw_k = x_k(3);\n",
    "    double yawd_k = x_k(4);\n",
    "    // Avoid a divide-by-zero for $\\dot{\\psi}$ (the yaw angle rate-of-change)\n",
    "    if (yawd_k < 0.0001) {\n",
    "      // Compute the state-space form of the process model\n",
    "      Fx_k << \n",
    "        v_k * std::cos(yaw_k) * delta_t,\n",
    "        v_k * std::sin(yaw_k) * delta_t,\n",
    "        0,\n",
    "        yawd_k * delta_t,\n",
    "        0;\n",
    "      // Compute the contribution of the process noise\n",
    "      nu_k <<\n",
    "        0.5 * std::pow(delta_t, 2) * std::cos(yaw_k) * nu_mean_k(0),\n",
    "        0.5 * std::pow(delta_t, 2) * std::sin(yaw_k) * nu_mean_k(0),\n",
    "        delta_t * nu_mean_k(0),\n",
    "        0.5 * std::pow(delta_t, 2) * nu_mean_k(1),\n",
    "        delta_t * nu_mean_k(1);\n",
    "      // Store the sigma point prediction into the predicted state matrix\n",
    "      Xsig_pred.col(i) << x_k + Fx_k + nu_k;\n",
    "      continue;\n",
    "    }\n",
    "    // Compute the state-space form of the process model\n",
    "    Fx_k <<\n",
    "      (v_k / yawd_k) * (std::sin(yaw_k + yawd_k * delta_t) - std::sin(yaw_k)),\n",
    "      (v_k / yawd_k) * (-std::cos(yaw_k + yawd_k * delta_t) + std::cos(yaw_k)),\n",
    "      0,\n",
    "      yawd_k * delta_t,\n",
    "      0;\n",
    "    // Compute the contribution of the process noise\n",
    "    nu_k << \n",
    "      0.5 * std::pow(delta_t, 2) * std::cos(yaw_k) * nu_mean_k(0),\n",
    "      0.5 * std::pow(delta_t, 2) * std::sin(yaw_k) * nu_mean_k(0),\n",
    "      delta_t * nu_mean_k(0),\n",
    "      0.5 * std::pow(delta_t, 2) * nu_mean_k(1),\n",
    "      delta_t * nu_mean_k(1);\n",
    "    // Store the sigma point prediction into the predicted state matrix\n",
    "    Xsig_pred.col(i) << x_k + Fx_k + nu_k;\n",
    "  }\n",
    "  // Print the resulting predicted sigma point matrix\n",
    "  // std::cout << \"Xsig_pred = \" << \"\\n\" << Xsig_pred << \"\\n\";\n",
    "  // Update the input pointer to the output result\n",
    "  *Xsig_out = Xsig_pred;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a4f87",
   "metadata": {},
   "source": [
    "##### Testing the sigma point prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97dea0ce-773b-4140-ae7d-8cb64df46753",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `5_tests.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ec8d308-b8e8-4dcb-a9b3-a7c4e89fe22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Evaluates the result of the `SigmaPointPrediction` function.\n",
    " *\n",
    " * The state transition function of the CTRV model is evaluated using the\n",
    " * augmented sigma points computed with the `AugmentedSigmaPoints` function. \n",
    " * The state transition function is given in state-space form and is defined\n",
    " * with respect to the $\\Delta t$ parameter. The output of this function, i.e.,\n",
    " * the resulting point predictions, are written to the predicted state\n",
    " * estimation matrix `Xsig_out`. The values of this output matrix are compared\n",
    " * to the expected values defined here using the Frobenius L2 norm. If the\n",
    " * resulting L2 norm value is less than the `epsilon` threshold, the two\n",
    " * matrices are said to be roughly equal.\n",
    " */\n",
    "void test_sigma_point_prediction() {\n",
    "  // Create the Unscented Kalman Filter (UKF) instance\n",
    "  UKF ukf;\n",
    "  // Instantiate the augmented sigma point matrix\n",
    "  // Assumed to be of dimensions (`n_aug`, `n_sigma_points`) which match the\n",
    "  // values set within the `AugmentSigmaPoints` function\n",
    "  Eigen::MatrixXd Xsig_aug(7, 15);\n",
    "  // Generate the augmented sigma points and write them to the output matrix\n",
    "  ukf.AugmentedSigmaPoints(&Xsig_aug);\n",
    "  // Instantiate the output predicted sigma point matrix\n",
    "  // Assumed to be of dimensions (`n_x`, `n_sigma_points`) which match the\n",
    "  // values set within the `SigmaPointPrediction` function \n",
    "  Eigen::MatrixXd Xsig_pred(5, 15);\n",
    "  // Compute the output matrix (the predicted state matrix)\n",
    "  ukf.SigmaPointPrediction(&Xsig_pred);\n",
    "  // Print the resulting values\n",
    "  std::cout << \"Xsig_pred = \" << Xsig_pred << \"\\n\";\n",
    "  // Perform the L2 norm to compare the two matrices\n",
    "  Eigen::MatrixXd Xsig_pred_expected(5, 15);\n",
    "  Xsig_pred_expected <<\n",
    "    5.93553, 6.06251,  5.92217,  5.9415,   5.92361,  5.93516,  5.93705, 5.93553,  5.80832,  5.94481,  5.92935,  5.94553,  5.93589,  5.93401, 5.93553,\n",
    "    1.48939, 1.44673,  1.66484,  1.49719,  1.508,    1.49001,  1.49022, 1.48939,  1.5308,   1.31287,  1.48182,  1.46967,  1.48876,  1.48855, 1.48939,\n",
    "    2.2049,  2.28414,  2.24557,  2.29582,  2.2049,   2.2049,   2.23954, 2.2049,   2.12566,  2.16423,  2.11398,  2.2049,   2.2049,   2.17026, 2.2049,\n",
    "    0.53678, 0.473387, 0.678098, 0.554557, 0.643644, 0.543372, 0.53678, 0.538512, 0.600173, 0.395462, 0.519003, 0.429916, 0.530188, 0.53678, 0.535048,\n",
    "    0.3528,  0.299973, 0.462123, 0.376339, 0.48417,  0.418721, 0.3528,  0.387441, 0.405627, 0.243477, 0.329261, 0.22143,  0.286879, 0.3528, 0.318159;\n",
    "  // Precision (i.e., max allowed magnitude of the two matrices' L2 distance)\n",
    "  double epsilon = 0.001;\n",
    "  std::cout << \"Result matches expected by amount `epsilon = \" << epsilon << \"`\";\n",
    "  std::cout << \": \" << std::boolalpha << Xsig_pred.isApprox(Xsig_pred_expected, epsilon) << \"\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38077932-e325-4ad8-9b17-2324a238f348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xsig_pred =  5.93553   6.0625  5.92217   5.9415  5.92361  5.93516  5.93705  5.93553  5.80833  5.94481  5.92935  5.94553  5.93589  5.93401  5.93553\n",
      " 1.48939  1.44673  1.66483  1.49719    1.508  1.49001  1.49022  1.48939   1.5308  1.31288  1.48182  1.46967  1.48876  1.48855  1.48939\n",
      "  2.2049  2.28414  2.24557  2.29582   2.2049   2.2049  2.23954   2.2049  2.12566  2.16423  2.11398   2.2049   2.2049  2.17026   2.2049\n",
      " 0.53678 0.473388 0.678099 0.554557 0.643644 0.543372  0.53678 0.538512 0.600172 0.395461 0.519003 0.429916 0.530188  0.53678 0.535048\n",
      "  0.3528 0.299973 0.462123 0.376339  0.48417 0.418721   0.3528 0.387441 0.405627 0.243477 0.329261  0.22143 0.286879   0.3528 0.318159\n",
      "Result matches expected by amount `epsilon = 0.001`: true\n"
     ]
    }
   ],
   "source": [
    "// Exercise 2.5.3: Prediction Step with Sigma Point\n",
    "test_sigma_point_prediction();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aec6ee",
   "metadata": {},
   "source": [
    "#### 2.1.4. Prediction Step — Mean and Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fee888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "576f75af-9509-473f-a382-245c451c917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace SigmaPoints {\n",
    "/* Normalises the heading angle of the predicted state estimation.\n",
    " *\n",
    " * The input vector is assumed to be the difference between the predicted and\n",
    " * previous state estimation vector, s.t. the fourth row-wise element of the\n",
    " * input vector is the heading angle to normalise in range [-pi, pi].\n",
    " *\n",
    " * @param    x_diff   Vector of difference values between state estimates.\n",
    " * @returns  Normalised vector of the difference between state estimates. \n",
    " */\n",
    "Eigen::VectorXd NormaliseHeading(\n",
    "  Eigen::VectorXd x_diff\n",
    ") {\n",
    "  while (x_diff(3) < -M_PI) {\n",
    "    x_diff(3) += 2.0 * M_PI;\n",
    "  }\n",
    "  while (x_diff(3) > M_PI) {\n",
    "    x_diff(3) -= 2.0 * M_PI;\n",
    "  }\n",
    "  return x_diff;\n",
    "}\n",
    "}  // namespace SigmaPoints\n",
    "\n",
    "\n",
    "namespace Radar {\n",
    "/* Normalises the heading angle of the radar measurement state estimatation.\n",
    " *\n",
    " * The input vector is assumed to be the radar measurement vector s.t. the\n",
    " * second row-wise element of the input vector is the heading angle to\n",
    " * normalise in range [0, pi].\n",
    " *\n",
    " * @param    z_diff   Vector of difference values between radar measurements.\n",
    " * @returns  Normalised vector of the difference in radar measurements.\n",
    " */\n",
    "Eigen::VectorXd NormaliseHeading(\n",
    "  Eigen::VectorXd z_diff\n",
    ") {\n",
    "  while (z_diff(1) < -M_PI) {\n",
    "    z_diff(1) += 2.0 * M_PI;\n",
    "  }\n",
    "  while (z_diff(1) > M_PI) {\n",
    "    z_diff(1) -= 2.0 * M_PI;\n",
    "  }\n",
    "  return z_diff;\n",
    "}\n",
    "} // namespace Radar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c877aa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f180159e-277f-4b78-9037-5552ed63697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Constructs the predicted the mean state estimation and covariance matrix.\n",
    " *\n",
    " * The mean state vector and covariance matrix are predicted into the next\n",
    " * time-step using the sigma point prediction matrix from the previous step.\n",
    " * The predicted values are computed w.r.t. a weight vector which is defined\n",
    " * in terms of the spreading parameter $\\lambda$. The weights are applied to\n",
    " * \"undo\" the effect of spreading on the covariance and mean state prediction.\n",
    " * \n",
    " * @param  x_out  Vector to store predicted mean state estimation. \n",
    " * @param  P_out  Matrix to store predicted covariance.\n",
    " */\n",
    "void UKF::PredictMeanAndCovariance(\n",
    "    Eigen::VectorXd* x_out, \n",
    "    Eigen::MatrixXd* P_out\n",
    ") {\n",
    "  /*** Set the state variables (values should match across functions) ***/\n",
    "  // Set the state dimension\n",
    "  int n_x = 5;\n",
    "  // Set the augmented dimension\n",
    "  // Process noise $\\nu_{k}$ has the terms $\\nu_{a, k}$, $\\nu_{\\ddot{psi},k}$\n",
    "  int n_a = 2;\n",
    "  // The process noise dimension added to the state vector dimension\n",
    "  int n_aug = n_x + n_a;\n",
    "  // Calculate the number of sigma points to compute\n",
    "  int n_sigma_points = 2 * n_aug + 1;\n",
    "  // Define the spreading parameter\n",
    "  double lambda = 3 - n_aug;\n",
    "  // Get the augmented sigma point matrix\n",
    "  Eigen::MatrixXd Xsig_aug(n_aug, n_sigma_points);\n",
    "  AugmentedSigmaPoints(&Xsig_aug);\n",
    "  /*** Compute the predicted sigma point matrix ***/\n",
    "  // Instantiate the predicted sigma point matrix\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the matrix\n",
    "  // must be set manually using the provided definition \n",
    "  Eigen::MatrixXd Xsig_pred(n_x, n_sigma_points);\n",
    "  // Define the delta-time variable (s)\n",
    "  double delta_t = 0.1;\n",
    "  // Get the predicted sigma points\n",
    "  //SigmaPointPrediction(&Xsig_pred);\n",
    "  Xsig_pred <<\n",
    "     5.9374,  6.0640,   5.925,  5.9436,  5.9266,  5.9374,  5.9389,  5.9374,  5.8106,  5.9457,  5.9310,  5.9465,  5.9374,  5.9359,  5.93744,\n",
    "       1.48,  1.4436,   1.660,  1.4934,  1.5036,    1.48,  1.4868,    1.48,  1.5271,  1.3104,  1.4787,  1.4674,    1.48,  1.4851,    1.486,\n",
    "      2.204,  2.2841,  2.2455,  2.2958,   2.204,   2.204,  2.2395,   2.204,  2.1256,  2.1642,  2.1139,   2.204,   2.204,  2.1702,   2.2049,\n",
    "     0.5367, 0.47338, 0.67809, 0.55455, 0.64364, 0.54337,  0.5367, 0.53851, 0.60017, 0.39546, 0.51900, 0.42991, 0.530188,  0.5367, 0.535048,\n",
    "      0.352, 0.29997, 0.46212, 0.37633,  0.4841, 0.41872,   0.352, 0.38744, 0.40562, 0.24347, 0.32926,  0.2214, 0.28687,   0.352, 0.318159;\n",
    "  /*** Compute the predicted mean state and covariance matrix ***/\n",
    "  // Instantiate the weight vector\n",
    "  Eigen::VectorXd w(n_sigma_points, 1);\n",
    "  // Initialise the predicted mean state vector\n",
    "  Eigen::VectorXd x(n_x);\n",
    "  x.fill(0.0);\n",
    "  // Initialise the predicted covariance matrix\n",
    "  Eigen::MatrixXd P(n_x, n_x);\n",
    "  P.fill(0.0);\n",
    "  // Set the weight vector values\n",
    "  // Computing the first value of the weight value\n",
    "  w(0) = lambda / (lambda + n_aug);\n",
    "  // Computing the rest of the weight values\n",
    "  for (int i = 1; i < n_sigma_points; i++) {\n",
    "    w(i) = 1.0 / (2.0 * (lambda + n_aug));\n",
    "  }\n",
    "  // Perform the mean state estimation vector prediction\n",
    "  for (int i = 0; i < n_sigma_points; i++) {\n",
    "    // Compute the predicted mean state\n",
    "    x += w(i) * Xsig_pred.col(i);\n",
    "  }\n",
    "  // Perform the covariance matrix prediction\n",
    "  for (int i = 0; i < n_sigma_points; i++) {\n",
    "    // Compute the difference between the state estimations\n",
    "    // Then, normalise the resulting heading angle to range [-pi, pi]\n",
    "    Eigen::VectorXd Xsig_pred_diff = (\n",
    "      SigmaPoints::NormaliseHeading(Xsig_pred.col(i) - x)\n",
    "    );\n",
    "    // Compute the predicted covariance matrix\n",
    "    P += w(i) * Xsig_pred_diff * Xsig_pred_diff.transpose();\n",
    "  }\n",
    "  // Print the resulting mean state and covariance matrix predictions\n",
    "  std::cout << \"Predicted state\" << \"\\n\";\n",
    "  std::cout << x << \"\\n\";\n",
    "  std::cout << \"Predicted covariance matrix\" << \"\\n\";\n",
    "  std::cout << P << \"\\n\";\n",
    "  // Update the input pointers to the output results\n",
    "  *x_out = x;\n",
    "  *P_out = P;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6943557",
   "metadata": {},
   "source": [
    "##### Testing the mean and covariance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58ddd568",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `5_tests.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39323529",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Evalautes the result of the `PredictMeanAndCovariance` function.\n",
    " * \n",
    " * The mean state estimation and covariance matrix are predicted into the next\n",
    " * time-step using the predict step equations of the Unscented Kalman Filter.\n",
    " * The prediction relies on the previous sigma point predictions from the\n",
    " * `SigmaPointPrediction` function. The resulting heading angle of the difference\n",
    " * vector between the previous and the predicted state estimation is normalised\n",
    " * to a range [-pi, pi] corresponding to the expected values for the vehicle.\n",
    " */\n",
    "void test_predict_mean_and_covariance() {\n",
    "  // Create the Unscented Kalman Filter (UKF) isntance\n",
    "  UKF ukf;\n",
    "  // Instantiate the predicted state estimation vector\n",
    "  // Assumed to be of dimensions (`n_x`, 1) which match the\n",
    "  // values set within the `PredictMeanAndCovariance` function \n",
    "  Eigen::VectorXd x(5, 1);\n",
    "  // Instantiate the predicted covariance matrix\n",
    "  // Assumed to be of dimensions (`n_x`, `n_x`) which match the\n",
    "  // values set within the `PredictMeanAndCovariance` function\n",
    "  Eigen::MatrixXd P(5, 5);\n",
    "  // Compute the outputs (the predicted state estimation and covariance matrix)\n",
    "  ukf.PredictMeanAndCovariance(\n",
    "      &x,\n",
    "      &P \n",
    "  );\n",
    "  // Printing the resulting values\n",
    "  std::cout << \"x = \" << \"\\n\" << x << \"\\n\";\n",
    "  std::cout << \"P = \" << \"\\n\" << P << \"\\n\";\n",
    "  // Perform the L2 norm to compare the output values\n",
    "  // NOTE: these expected values hold only for the hard-coded `Xsig_pred`\n",
    "  // matrix whose values are given in the Udacity VM workspace as follows:\n",
    "  // Xsig_pred <<\n",
    "  //        5.9374,  6.0640,   5.925,  5.9436,  5.9266,  5.9374,  5.9389,  5.9374,  5.8106,  5.9457,  5.9310,  5.9465,  5.9374,  5.9359,  5.93744,\n",
    "  //          1.48,  1.4436,   1.660,  1.4934,  1.5036,    1.48,  1.4868,    1.48,  1.5271,  1.3104,  1.4787,  1.4674,    1.48,  1.4851,    1.486,\n",
    "  //         2.204,  2.2841,  2.2455,  2.2958,   2.204,   2.204,  2.2395,   2.204,  2.1256,  2.1642,  2.1139,   2.204,   2.204,  2.1702,   2.2049,\n",
    "  //        0.5367, 0.47338, 0.67809, 0.55455, 0.64364, 0.54337,  0.5367, 0.53851, 0.60017, 0.39546, 0.51900, 0.42991, 0.530188,  0.5367, 0.535048,\n",
    "  //         0.352, 0.29997, 0.46212, 0.37633,  0.4841, 0.41872,   0.352, 0.38744, 0.40562, 0.24347, 0.32926,  0.2214, 0.28687,   0.352, 0.318159;\n",
    "  Eigen::VectorXd x_expected(5, 1);\n",
    "  x_expected <<\n",
    "    5.93637,\n",
    "    1.49035,\n",
    "    2.20528,\n",
    "    0.536853,\n",
    "    0.353577;\n",
    "  Eigen::MatrixXd P_expected(5, 5);\n",
    "  P_expected <<\n",
    "    0.00543425, -0.0024053,  0.00341576, -0.00348196, -0.00299378,\n",
    "   -0.0024053,   0.010845,   0.0014923,   0.00980182,  0.00791091,\n",
    "    0.00341576,  0.0014923,  0.00580129,  0.000778632, 0.000792973,\n",
    "   -0.00348196,  0.00980182, 0.000778632, 0.0119238,   0.0112491,\n",
    "   -0.00299378,  0.00791091, 0.000792973, 0.0112491,   0.0126972;\n",
    "  // Precision (i.e., max allowed magnitude of the outputs' L2 difference)\n",
    "  // NOTE: see above caveat (test works only when `Xsig_pred` is set manually) \n",
    "  double epsilon = 0.001;\n",
    "  std::cout << \"Result `x` matches expected amount by `epsilon = \" << epsilon << '`';\n",
    "  std::cout << \": \" << std::boolalpha << x.isApprox(x_expected, epsilon) << \"\\n\";\n",
    "  std::cout << \"Result `P` matches expected amount by `epsilon = \" << epsilon << '`';\n",
    "  std::cout << \": \" << std::boolalpha << P.isApprox(P_expected, epsilon) << \"\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3965183e-4e6c-4d19-b2c5-c744b258955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted state\n",
      " 5.93637\n",
      " 1.49035\n",
      " 2.20528\n",
      "0.536853\n",
      "0.353577\n",
      "Predicted covariance matrix\n",
      " 0.00543425  -0.0024053  0.00341576 -0.00348196 -0.00299378\n",
      " -0.0024053    0.010845   0.0014923  0.00980182  0.00791091\n",
      " 0.00341576   0.0014923  0.00580129 0.000778632 0.000792973\n",
      "-0.00348196  0.00980182 0.000778632   0.0119238   0.0112491\n",
      "-0.00299378  0.00791091 0.000792973   0.0112491   0.0126972\n",
      "x = \n",
      " 5.93637\n",
      " 1.49035\n",
      " 2.20528\n",
      "0.536853\n",
      "0.353577\n",
      "P = \n",
      " 0.00543425  -0.0024053  0.00341576 -0.00348196 -0.00299378\n",
      " -0.0024053    0.010845   0.0014923  0.00980182  0.00791091\n",
      " 0.00341576   0.0014923  0.00580129 0.000778632 0.000792973\n",
      "-0.00348196  0.00980182 0.000778632   0.0119238   0.0112491\n",
      "-0.00299378  0.00791091 0.000792973   0.0112491   0.0126972\n",
      "Result `x` matches expected amount by `epsilon = 0.001`: true\n",
      "Result `P` matches expected amount by `epsilon = 0.001`: true\n"
     ]
    }
   ],
   "source": [
    "// Exercise 2.5.4: Prediction Step with Mean and Covariance\n",
    "test_predict_mean_and_covariance();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20104813-3101-48a8-8422-0ef53bfec7da",
   "metadata": {},
   "source": [
    "### 2.1.5. Innovation Step — Radar Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bfc508e-d659-4fc9-bdbd-873b47de31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fbd02a4-4e8b-4540-a0a3-e2f278fb56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Constructs the radar measurement mean estimation and covariance matrix.\n",
    " * \n",
    " * The radar measurement vector is a three-dimensional vector:\n",
    " *   $z_{k + 1\\vert k} = [\\rho, \\phi, \\dot{\\rho}]$,\n",
    " * where $\\rho$ is the radial distance (m), $\\phi$ is the angle (rad), and\n",
    " * $\\dot{\\rho}$ is the radial velocity (m/s) measured by the radar sensor.\n",
    " * \n",
    " * In order to perform the update / innovation step, several \"shortcuts\" are\n",
    " * used. The first involves the \"recycling\" of the sigma point matrix, which,\n",
    " * due to the purely additive (linear) contribution of the radar measurement\n",
    " * noise, allows us to skip the computation of new sigma points and the UKF\n",
    " * augmentation step all-together. The second \"shortcut\" used here the hold-out\n",
    " * of the measurement noise $\\omega_{k+1}$ from the measurement model function.\n",
    " * Again, due to the linearity of the noise contribution, we neglect the noise\n",
    " * value until the computation of the measurement covariance prediction matrix\n",
    " * $\\mathrm{R}$ in the innovation / correction step.\n",
    " * \n",
    " * The equations for the sigma point-to-radar measurement space are given by:\n",
    " *    $\\rho = \\sqrt{p_{x}^{2} + p_{y}^{2}}$,\n",
    " *    $\\phi = \\arctan(p_{y} / p_{x})$,\n",
    " *    $$\\begin{align}\n",
    " *    \\dot{\\rho} &= \\frac{\n",
    " *        p_{x}\\cos(\\phi)*v + p_{y}\\sin(\\phi)*v\n",
    " *        }{\\sqrt{p_{x}^{2} + p_{y}^{2}}} \\\\\n",
    " *    \\end{align}$$.\n",
    " * \n",
    " * @param  z_out  Vector to store predicted measurement mean state estimation.\n",
    " * @param  S_out  Matrix to store predicted measurement covariance.\n",
    " */\n",
    "void UKF::PredictRadarMeasurement(\n",
    "    Eigen::VectorXd* z_out, \n",
    "    Eigen::MatrixXd* S_out\n",
    ") {\n",
    "  /*** Set the state variables (values should match across functions) ***/\n",
    "  // Set the state dimension\n",
    "  int n_x = 5;\n",
    "  // Set the augmented dimension\n",
    "  // Process noise $\\nu_{k}$ has the terms $\\nu_{a, k}$, $\\nu_{\\ddot{psi},k}$\n",
    "  int n_a = 2;\n",
    "  // The process noise dimension added to the state vector dimension\n",
    "  int n_aug = n_x + n_a;\n",
    "  // Calculate the number of sigma points to compute\n",
    "  int n_sigma_points = 2 * n_aug + 1;\n",
    "  // Set the measurement dimensions\n",
    "  // Note: the radar measurement vector is $[\\rho, \\phi, \\dot{\\rho}]$\n",
    "  // i.e., the measured radial distance, angle, and radial velocity\n",
    "  int n_z = 3;\n",
    "  // Define the spreading parameter\n",
    "  double lambda = 3 - n_aug;\n",
    "  // Set the weight vector values\n",
    "  Eigen::VectorXd w(n_sigma_points, 1);\n",
    "  w(0) = lambda / (lambda + n_aug);\n",
    "  double weight = 1.0 / (2.0 * (lambda + n_aug));\n",
    "  for (int i = 1; i < n_sigma_points; ++i) {  \n",
    "    w(i) = weight;\n",
    "  }\n",
    "  // Standard deviation of the radar measurement noise for $\\rho$ (m)\n",
    "  double std_radr = 0.3;\n",
    "  // Standard deviation of the radar measurment noise for $\\phi$ (rad)\n",
    "  double std_radphi = 0.0175;\n",
    "  // Standard deviation of the radar measurment noise for $\\dot{\\rho}$ (m/s)\n",
    "  double std_radrd = 0.1;\n",
    "  // Define the measurement noise covariance $\\mathrm{R}$\n",
    "  Eigen::MatrixXd R(n_z, n_z);\n",
    "  // Set the measurement noise covariance matrix values\n",
    "  R << std_radr * std_radr, 0.0, 0.0,\n",
    "       0.0, std_radphi * std_radphi, 0.0,\n",
    "       0.0, 0.0, std_radrd * std_radrd;\n",
    "  // Get the predicted sigma point matrix\n",
    "  Eigen::MatrixXd Xsig_pred(n_x, 2 * n_aug + 1);\n",
    "  //SigmaPointPrediction(&Xsig_pred);\n",
    "  Xsig_pred <<\n",
    "     5.9374,  6.0640,   5.925,  5.9436,  5.9266,  5.9374,  5.9389,  5.9374,  5.8106,  5.9457,  5.9310,  5.9465,  5.9374,  5.9359,  5.93744,\n",
    "       1.48,  1.4436,   1.660,  1.4934,  1.5036,    1.48,  1.4868,    1.48,  1.5271,  1.3104,  1.4787,  1.4674,    1.48,  1.4851,    1.486,\n",
    "      2.204,  2.2841,  2.2455,  2.2958,   2.204,   2.204,  2.2395,   2.204,  2.1256,  2.1642,  2.1139,   2.204,   2.204,  2.1702,   2.2049,\n",
    "     0.5367, 0.47338, 0.67809, 0.55455, 0.64364, 0.54337,  0.5367, 0.53851, 0.60017, 0.39546, 0.51900, 0.42991, 0.530188,  0.5367, 0.535048,\n",
    "      0.352, 0.29997, 0.46212, 0.37633,  0.4841, 0.41872,   0.352, 0.38744, 0.40562, 0.24347, 0.32926,  0.2214, 0.28687,   0.352, 0.318159;\n",
    "  // Initialise the sigma point matrix in measurement space\n",
    "  Eigen::MatrixXd Zsig(n_z, n_sigma_points);\n",
    "  Zsig.fill(0.0);\n",
    "  // Initialise the mean predicted measurement vector\n",
    "  Eigen::VectorXd z_pred(n_z);\n",
    "  z_pred.fill(0.0);\n",
    "  // Initialise the measurement covariance matrix S\n",
    "  Eigen::MatrixXd S(n_z, n_z);\n",
    "  S.fill(0.0);\n",
    "  // Transform the sigma points into the radar measurement space\n",
    "  for (int i = 0; i < n_sigma_points; i++) {\n",
    "    // Get the state vector associated with the sigma point\n",
    "    Eigen::VectorXd x_i = Xsig_pred.col(i);\n",
    "    // Store the transformed state vector in measurement space\n",
    "    Eigen::VectorXd Zsig_i(n_z, 1);\n",
    "    // Compute the radial distance $\\rho$ transformation\n",
    "    Zsig_i(0) = std::sqrt(std::pow(x_i(0), 2) + std::pow(x_i(1), 2));\n",
    "    // Compute the angle $\\phi$ transformation\n",
    "    Zsig_i(1) = std::atan(x_i(1) / x_i(0));\n",
    "    // Compute the radial velocity $\\dot{\\rho}$ transformation\n",
    "    Zsig_i(2) = (\n",
    "      x_i(0) * std::cos(x_i(3)) * x_i(2) + x_i(1) * std::sin(x_i(3)) * x_i(2)\n",
    "    ) / std::sqrt(std::pow(x_i(0), 2) + std::pow(x_i(1), 2));\n",
    "    // Update the resulting sigma point in measurment space vector\n",
    "    Zsig.col(i) = Zsig_i;\n",
    "  }\n",
    "  // Calculate the mean predicted measurement vector\n",
    "  for (int i = 0; i < n_sigma_points; i++) {\n",
    "    // Compute the `i`th predicteded measurement mean $z_{k+1 \\vert k}$\n",
    "    z_pred += w(i) * Zsig.col(i);\n",
    "  }\n",
    "  // Calculate the covariance matrix `S` of the innovation / correction step\n",
    "  for (int i = 0; i < n_sigma_points; i++) {\n",
    "    // Compute the difference in measurement mean state estimations\n",
    "    // Then, normalise the resulting heading angle estimate to range [-pi, pi]\n",
    "    Eigen::VectorXd Zsig_meas_diff = (\n",
    "      Radar::NormaliseHeading(Zsig.col(i) - z_pred)\n",
    "    );\n",
    "    // Compute the `i`th covariance matrix $S_{k+1\\vert k}$ step\n",
    "    S += w(i) * Zsig_meas_diff * Zsig_meas_diff.transpose();\n",
    "  }\n",
    "  // Set the additive contribution of the measurement noise to the vector\n",
    "  // as defined by the measurement noise covariance matrix $\\mathrm{R}$\n",
    "  S += R;\n",
    "  // Print the resulting outputs\n",
    "  std::cout << \"z_pred: \" << \"\\n\" << z_pred << \"\\n\";\n",
    "  std::cout << \"S: \" << \"\\n\" << S << \"\\n\";\n",
    "  // Update the input pointers to the output results\n",
    "  *z_out = z_pred;\n",
    "  *S_out = S;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb753364-f060-4e29-86ba-41cd6cf65992",
   "metadata": {},
   "source": [
    "##### Testing the radar measurement prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c459c061-cde5-4de2-a826-f8c32f4580f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Evalautes the result of the `PredictRadarMeasurement` function.\n",
    " */\n",
    "void test_predict_radar_measurement() {\n",
    "  // Create the Unscented Kalman Filter (UKF) isntance\n",
    "  UKF ukf;\n",
    "  // Instantiate the predicted state estimation vector\n",
    "  // Assumed to be of dimensions (`n_z`, 1) which match the\n",
    "  // values set within the `PredictRadarMeasurement` function \n",
    "  Eigen::VectorXd z_pred(3, 1);\n",
    "  // Instantiate the predicted covariance matrix\n",
    "  // Assumed to be of dimensions (`n_z`, `n_z`) which match the\n",
    "  // values set within the `PredictRadarMeasurement` function\n",
    "  Eigen::MatrixXd S(3, 3);\n",
    "  // Compute the outputs (the measurement state estimation / covariance matrix)\n",
    "  // NOTE: must set the `Xsig_pred` matrix to the values defined below in order\n",
    "  // to obtain output `z_pred` and `S` with corresponding expected values\n",
    "  ukf.PredictRadarMeasurement(\n",
    "      &z_pred,\n",
    "      &S\n",
    "  );\n",
    "  // Printing the resulting values\n",
    "  std::cout << \"z_pred = \" << \"\\n\" << z_pred << \"\\n\";\n",
    "  std::cout << \"S = \" << \"\\n\" << S << \"\\n\";\n",
    "  // Perform the L2 norm to compare the output values\n",
    "  // NOTE: these expected values hold only for the hard-coded `Xsig_pred`\n",
    "  // matrix whose values are given in the Udacity VM workspace as follows:\n",
    "  // Xsig_pred <<\n",
    "  //        5.9374,  6.0640,   5.925,  5.9436,  5.9266,  5.9374,  5.9389,  5.9374,  5.8106,  5.9457,  5.9310,  5.9465,  5.9374,  5.9359,  5.93744,\n",
    "  //          1.48,  1.4436,   1.660,  1.4934,  1.5036,    1.48,  1.4868,    1.48,  1.5271,  1.3104,  1.4787,  1.4674,    1.48,  1.4851,    1.486,\n",
    "  //         2.204,  2.2841,  2.2455,  2.2958,   2.204,   2.204,  2.2395,   2.204,  2.1256,  2.1642,  2.1139,   2.204,   2.204,  2.1702,   2.2049,\n",
    "  //        0.5367, 0.47338, 0.67809, 0.55455, 0.64364, 0.54337,  0.5367, 0.53851, 0.60017, 0.39546, 0.51900, 0.42991, 0.530188,  0.5367, 0.535048,\n",
    "  //         0.352, 0.29997, 0.46212, 0.37633,  0.4841, 0.41872,   0.352, 0.38744, 0.40562, 0.24347, 0.32926,  0.2214, 0.28687,   0.352, 0.318159;\n",
    "  Eigen::VectorXd z_pred_expected(3, 1);\n",
    "  z_pred_expected <<\n",
    "    6.12155,\n",
    "    0.245993,\n",
    "    2.10313;\n",
    "  Eigen::MatrixXd S_expected(3, 3);\n",
    "  S_expected <<\n",
    "    0.0946171,  -0.000139448,  0.00407016,\n",
    "   -0.000139448, 0.000617548, -0.000770652,\n",
    "    0.00407016, -0.000770652,  0.0180917;\n",
    "  // Precision (i.e., max allowed magnitude of the outputs' L2 difference)\n",
    "  // NOTE: see above caveat (test works only when `Xsig_pred` is set manually) \n",
    "  double epsilon = 0.0001;\n",
    "  std::cout << \"Result `z_pred` matches expected amount by `epsilon = \" << epsilon << '`';\n",
    "  std::cout << \": \" << std::boolalpha << z_pred.isApprox(z_pred_expected, epsilon) << \"\\n\";\n",
    "  std::cout << \"Result `S` matches expected amount by `epsilon = \" << epsilon << '`';\n",
    "  std::cout << \": \" << std::boolalpha << S.isApprox(S_expected, epsilon) << \"\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20ef9807-84c6-473d-b896-ea3cd26965d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_pred: \n",
      " 6.12155\n",
      "0.245993\n",
      " 2.10313\n",
      "S: \n",
      "   0.0946171 -0.000139448   0.00407016\n",
      "-0.000139448  0.000617548 -0.000770652\n",
      "  0.00407016 -0.000770652    0.0180917\n",
      "z_pred = \n",
      " 6.12155\n",
      "0.245993\n",
      " 2.10313\n",
      "S = \n",
      "   0.0946171 -0.000139448   0.00407016\n",
      "-0.000139448  0.000617548 -0.000770652\n",
      "  0.00407016 -0.000770652    0.0180917\n",
      "Result `z_pred` matches expected amount by `epsilon = 0.0001`: true\n",
      "Result `S` matches expected amount by `epsilon = 0.0001`: true\n"
     ]
    }
   ],
   "source": [
    "// Exercise 2.5.5: Innovation Step with Radar Measurement\n",
    "test_predict_radar_measurement();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd073223-9195-43ac-973f-8bfaa61aaace",
   "metadata": {},
   "source": [
    "### 2.1.6. Innovation Step — Update Mean and Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e49de696-b480-41d8-be14-c2a3b08cc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `ukf.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ce668a8-6c16-454d-88a8-2a6e7fc8a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Performs the UKF Innovation step to update the state mean and covariance.\n",
    " * \n",
    " * The Innovation step of the Unscented Kalman Filter (UKF) differs from\n",
    " * the standard Kalman filter (KF) only by a cross-correlation term\n",
    " * computed between the state- and measurement space of the sigma points.\n",
    " * This term is used in the equation for the Kalman gain given by:\n",
    " * $$\\begin{align}\n",
    " * \\mathrm{K}_{k+1\\vert k} &= \\mathrm{T}_{k+1\\vert k} \n",
    " *                            * \\mathrm{S}^{\\inv}_{k+1\\vert k}. \n",
    " * \\end{align}$$\n",
    " * \n",
    " * The state update equation for the time-step $k+1$ is given by:\n",
    " * $$\\begin{align}\n",
    " * x_{k+1\\vert k+1} = x_{k+1\\vert k}\n",
    " *                    + \\mathrm{K}_{k+1\\vert k}\n",
    " *                    * (z_{k+1} - z_{k+1\\vert k}).\n",
    " * \\end{align}$$\n",
    " * \n",
    " * The covariance matrix update equation for time-step $k+1$ is given by:\n",
    " * $$\\begin{align}\n",
    " * \\mathrm{P}_{k+1\\vert k+1} = \\mathrm{P}_{k+1\\vert k}\n",
    " *                             - \\mathrm{K}_{k+1 \\ k}\n",
    " *                             * \\mathrm{S}_{k+1 \\vert k}\n",
    " *                             * \\mathrm{K}^{\\top}_{k+1 \\vert k}.\n",
    " * \\end{align}$$\n",
    " * \n",
    " * The cross-correlation matrix between the sigma points in state- and\n",
    " * measurement-space is given as:\n",
    " * $$\\begin{align}\n",
    " * \\mathrm{T}_{k+1\\vert k} = \n",
    " * \\sum_{i=0}^{2*n_{a}} w_{i} \n",
    " *                      * (\\mathcal{x}_{k+1\\vert k,i} - x_{k+1\\vert k})\n",
    " *                      * (\\mathcal{z}_{k+1\\vert k,i} - z_{k+1\\vert k})^{\\top}.\n",
    " * \\end{align}$$\n",
    " * \n",
    " * @param  x_out    Vector to store the updated mean state estimate. \n",
    " * @param  P_out    Matrix to store the updated covariance matrix estimate.\n",
    " */\n",
    "void UKF::UpdateState(\n",
    "    Eigen::VectorXd* x_out,\n",
    "    Eigen::MatrixXd* P_out\n",
    ") {\n",
    " /*** Set the state variables (values should match across functions) ***/\n",
    "  // Set the state dimension\n",
    "  int n_x = 5;\n",
    "  // Set the augmented dimension\n",
    "  // Process noise $\\nu_{k}$ has the terms $\\nu_{a, k}$, $\\nu_{\\ddot{psi},k}$\n",
    "  int n_a = 2;\n",
    "  // The process noise dimension added to the state vector dimension\n",
    "  int n_aug = n_x + n_a;\n",
    "  // Calculate the number of sigma points to compute\n",
    "  int n_sigma_points = 2 * n_aug + 1;\n",
    "  // Set the measurement dimensions\n",
    "  // Note: the radar measurement vector is $[\\rho, \\phi, \\dot{\\rho}]$\n",
    "  // i.e., the measured radial distance, angle, and radial velocity\n",
    "  int n_z = 3;\n",
    "  // Define the spreading parameter\n",
    "  double lambda = 3 - n_aug;\n",
    "  // Set the weight vector values\n",
    "  Eigen::VectorXd w(n_sigma_points, 1);\n",
    "  w(0) = lambda / (lambda + n_aug);\n",
    "  double weight = 1.0 / (2.0 * (lambda + n_aug));\n",
    "  for (int i = 1; i < n_sigma_points; ++i) {  \n",
    "    w(i) = weight;\n",
    "  }\n",
    "  /*** Compute the predicted sigma point matrix ***/\n",
    "  // Define the delta-time variable (s)\n",
    "  double delta_t = 0.1;\n",
    "  // Instantiate the predicted sigma point matrix\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the matrix\n",
    "  // must be set manually using the provided definition\n",
    "  Eigen::MatrixXd Xsig_pred(n_x, n_sigma_points);\n",
    "  Xsig_pred <<\n",
    "     5.9374,  6.0640,   5.925,  5.9436,  5.9266,  5.9374,  5.9389,  5.9374,  5.8106,  5.9457,  5.9310,  5.9465,  5.9374,  5.9359,  5.93744,\n",
    "       1.48,  1.4436,   1.660,  1.4934,  1.5036,    1.48,  1.4868,    1.48,  1.5271,  1.3104,  1.4787,  1.4674,    1.48,  1.4851,    1.486,\n",
    "      2.204,  2.2841,  2.2455,  2.2958,   2.204,   2.204,  2.2395,   2.204,  2.1256,  2.1642,  2.1139,   2.204,   2.204,  2.1702,   2.2049,\n",
    "     0.5367, 0.47338, 0.67809, 0.55455, 0.64364, 0.54337,  0.5367, 0.53851, 0.60017, 0.39546, 0.51900, 0.42991, 0.530188,  0.5367, 0.535048,\n",
    "      0.352, 0.29997, 0.46212, 0.37633,  0.4841, 0.41872,   0.352, 0.38744, 0.40562, 0.24347, 0.32926,  0.2214, 0.28687,   0.352, 0.318159;\n",
    "  // Get the predicted sigma points\n",
    "  //SigmaPointPrediction(&Xsig_pred);\n",
    "  /*** Compute the predicted mean state and covariance matrix ***/\n",
    "  // Initialise the predicted mean state vector\n",
    "  Eigen::VectorXd x(n_x);\n",
    "  x.fill(0.0);\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the vector\n",
    "  // must be set manually using the provided definition\n",
    "  x <<\n",
    "     5.93637,\n",
    "     1.49035,\n",
    "     2.20528,\n",
    "    0.536853,\n",
    "    0.353577;\n",
    "  // Initialise the predicted covariance matrix\n",
    "  Eigen::MatrixXd P(n_x, n_x);\n",
    "  P.fill(0.0);\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the matrix\n",
    "  // must be set manually using the provided definition\n",
    "  P <<\n",
    "    0.0054342,  -0.002405,  0.0034157, -0.0034819, -0.00299378,\n",
    "    -0.002405,    0.01084,   0.001492,  0.0098018,  0.00791091,\n",
    "    0.0034157,   0.001492,  0.0058012, 0.00077863, 0.000792973,\n",
    "   -0.0034819,  0.0098018, 0.00077863,   0.011923,   0.0112491,\n",
    "   -0.0029937,  0.0079109, 0.00079297,   0.011249,   0.0126972;\n",
    "  //PredictMeanAndCovariance(&x, &P);\n",
    "  /*** Obtain the measurement vector and covariance matrix estimations ***/\n",
    "  // Instantiate the measurement matrix\n",
    "  Eigen::MatrixXd Zsig(n_z, n_sigma_points);\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the matrix\n",
    "  // must be set manually using the provided definition\n",
    "  Zsig <<\n",
    "    6.1190,  6.2334,  6.1531,  6.1283,  6.1143,  6.1190,  6.1221,  6.1190,  6.0079,  6.0883,  6.1125,  6.1248,  6.1190,  6.1188,  6.12057,\n",
    "   0.24428,  0.2337, 0.27316, 0.24616, 0.24846, 0.24428, 0.24530, 0.24428, 0.25700, 0.21692, 0.24433, 0.24193, 0.24428, 0.24515, 0.245239,\n",
    "    2.1104,  2.2188,  2.0639,   2.187,  2.0341,  2.1061,  2.1450,  2.1092,  2.0016,   2.129,  2.0346,  2.1651,  2.1145,  2.0786,  2.11295;\n",
    "  // Instantiate the mean measurement vector\n",
    "  Eigen::VectorXd z_pred(n_z);\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the vector\n",
    "  // must be set manually using the provided definition\n",
    "  z_pred <<\n",
    "    6.12155,\n",
    "     0.245993,\n",
    "     2.10313;\n",
    "  // Instantiate the predicted measurement covariance matrix\n",
    "  Eigen::MatrixXd S(n_z, n_z);\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the matrix\n",
    "  // must be set manually using the provided definition\n",
    "  S <<\n",
    "      0.0946171, -0.000139448,   0.00407016,\n",
    "   -0.000139448,  0.000617548, -0.000770652,\n",
    "     0.00407016, -0.000770652,    0.0180917;\n",
    "  //PredictRadarMeasurement(&z_pred, &S);\n",
    "  // Instantiate the incoming radar measurement vector\n",
    "  Eigen::VectorXd z(n_z);\n",
    "  // NOTE: if running unit test in `5_tests.cc`, the values of the vector\n",
    "  // must be set manually using the provided definition\n",
    "  z <<\n",
    "     5.9214,   // rho in m\n",
    "     0.2187,   // phi in rad\n",
    "     2.0062;   // rho_dot in m/s\n",
    "  /*** Compute the updated state and covariance (innovation step) ***/\n",
    "  // Initialise the cross-correlation matrix\n",
    "  Eigen::MatrixXd Tc(n_x, n_z);\n",
    "  Tc.fill(0.0);\n",
    "  // Calculate the cross-correlation matrix\n",
    "  for (int i = 0; i < n_sigma_points; i++) {\n",
    "    // Compute the difference in the sigma points in state-space\n",
    "    Eigen::VectorXd x_diff = SigmaPoints::NormaliseHeading(Xsig_pred.col(i) - x); \n",
    "    // Compute the difference in the sigma points in measurement-space\n",
    "    Eigen::VectorXd z_diff = Radar::NormaliseHeading(Zsig.col(i) - z_pred);\n",
    "    // Compute the cross-correlation for this sigma point\n",
    "    Tc += w(i) * x_diff * z_diff.transpose(); \n",
    "  }\n",
    "  // Calculate the Kalman gain matrix `K`\n",
    "  Eigen::MatrixXd K = Tc * S.inverse();\n",
    "  // Compute the residual\n",
    "  // i.e., the difference in predicted and received measurement state\n",
    "  Eigen::VectorXd z_diff = Radar::NormaliseHeading(z - z_pred);\n",
    "  // Perform the state mean update\n",
    "  x += K * z_diff;\n",
    "  // Perform the covariance matrix update\n",
    "  P -= K * S * K.transpose();\n",
    "  // Print the resulting outputs\n",
    "  std::cout << \"Updated state x: \" << \"\\n\" << x << \"\\n\";\n",
    "  std::cout << \"Updated state covariance P: \" << \"\\n\" << P << \"\\n\";\n",
    "  // Update the input pointers to the outputs\n",
    "  *x_out = x;\n",
    "  *P_out = P;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83c2be-0ab3-489c-ae02-05bd1c8d429c",
   "metadata": {},
   "source": [
    "##### Testing the mean and covariance update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8acc2316-ae0e-401f-8192-cb6e2ab2492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// From J. Moran's `5_tests.cc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96d7ad23-7ad8-45e9-a82e-2b0507de0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "/* Evaluates the result of the mean and covariance update.\n",
    " *\n",
    " * Performs the second and final part of the UKF innovation step.\n",
    " * The mean state and covariance matrix are updated w.r.t. the incoming\n",
    " * radar measurement using the unscented transformation of the sigma points.\n",
    " * Here, we assume a purely additive contribution of measurement noise on the\n",
    " * radar measurement model. This allows us to simplify the update step and\n",
    " * estimate a noise covariance $\\mathrm{R}$ to be added in the update of the\n",
    " * covariance matrix $\\mathrm{P}$. Also defined relative to our model\n",
    " * assumptions is the use of the cross-correlation matrix $\\mathrm{T}$ which\n",
    " * is the cross-correlation difference in the sigma points in state-space and\n",
    " * the sigma points in measurement space. This term is used to modify the\n",
    " * standard Kalman filter update equations for gain $\\mathrm{K}$ and\n",
    " * consequently covariance $\\mathrm{P}$ and state $x$.\n",
    " */\n",
    "void test_update_state() {\n",
    "  // Create the Unscented Kalman Filter (UKF) instance\n",
    "  UKF ukf;\n",
    "  /*** Set the state variables (values should match across functions) ***/\n",
    "  // Set the state dimension\n",
    "  int n_x = 5;\n",
    "  // Set the augmented dimension\n",
    "  // Process noise $\\nu_{k}$ has the terms $\\nu_{a, k}$, $\\nu_{\\ddot{psi},k}$\n",
    "  int n_a = 2;\n",
    "  // The process noise dimension added to the state vector dimension\n",
    "  int n_aug = n_x + n_a;\n",
    "  // Calculate the number of sigma points to compute\n",
    "  int n_sigma_points = 2 * n_aug + 1;\n",
    "  // Set the measurement dimensions\n",
    "  // Note: the radar measurement vector is $[\\rho, \\phi, \\dot{\\rho}]$\n",
    "  // i.e., the measured radial distance, angle, and radial velocity\n",
    "  int n_z = 3;\n",
    "  // Define the spreading parameter\n",
    "  double lambda = 3 - n_aug;\n",
    "  // Define the delta-time variable (s)\n",
    "  double delta_t = 0.1;\n",
    "  // Define the incoming radar measurement vector\n",
    "  // assumed to be the same in `UpdateState`\n",
    "  Eigen::VectorXd z(n_z);\n",
    "  z <<\n",
    "     5.9214,   // rho in m\n",
    "     0.2187,   // phi in rad\n",
    "     2.0062;   // rho_dot in m/s\n",
    "  // Instantiate the updated state estimation\n",
    "  Eigen::VectorXd x(n_x, 1);\n",
    "  // Instantiate the updated covariance matrix\n",
    "  Eigen::MatrixXd P(n_x, n_x);\n",
    "  /*** Define the variables needed for the test case ***/\n",
    "  // NOTE: the following values must be set inside `UpdateState`\n",
    "  // in order for the expected test case values to hold\n",
    "  Eigen::MatrixXd Xsig_pred(n_x, n_sigma_points);\n",
    "  Xsig_pred <<\n",
    "     5.9374,  6.0640,   5.925,  5.9436,  5.9266,  5.9374,  5.9389,  5.9374,  5.8106,  5.9457,  5.9310,  5.9465,  5.9374,  5.9359,  5.93744,\n",
    "       1.48,  1.4436,   1.660,  1.4934,  1.5036,    1.48,  1.4868,    1.48,  1.5271,  1.3104,  1.4787,  1.4674,    1.48,  1.4851,    1.486,\n",
    "      2.204,  2.2841,  2.2455,  2.2958,   2.204,   2.204,  2.2395,   2.204,  2.1256,  2.1642,  2.1139,   2.204,   2.204,  2.1702,   2.2049,\n",
    "     0.5367, 0.47338, 0.67809, 0.55455, 0.64364, 0.54337,  0.5367, 0.53851, 0.60017, 0.39546, 0.51900, 0.42991, 0.530188,  0.5367, 0.535048,\n",
    "      0.352, 0.29997, 0.46212, 0.37633,  0.4841, 0.41872,   0.352, 0.38744, 0.40562, 0.24347, 0.32926,  0.2214, 0.28687,   0.352, 0.318159;\n",
    "  //Eigen::VectorXd x(n_x);\n",
    "  x <<\n",
    "     5.93637,\n",
    "     1.49035,\n",
    "     2.20528,\n",
    "    0.536853,\n",
    "    0.353577;\n",
    "  //Eigen::MatrixXd P(n_x, n_x);\n",
    "  P <<\n",
    "    0.0054342,  -0.002405,  0.0034157, -0.0034819, -0.00299378,\n",
    "    -0.002405,    0.01084,   0.001492,  0.0098018,  0.00791091,\n",
    "    0.0034157,   0.001492,  0.0058012, 0.00077863, 0.000792973,\n",
    "   -0.0034819,  0.0098018, 0.00077863,   0.011923,   0.0112491,\n",
    "   -0.0029937,  0.0079109, 0.00079297,   0.011249,   0.0126972;\n",
    "  Eigen::MatrixXd Zsig(n_z, n_sigma_points);\n",
    "  Zsig <<\n",
    "    6.1190,  6.2334,  6.1531,  6.1283,  6.1143,  6.1190,  6.1221,  6.1190,  6.0079,  6.0883,  6.1125,  6.1248,  6.1190,  6.1188,  6.12057,\n",
    "   0.24428,  0.2337, 0.27316, 0.24616, 0.24846, 0.24428, 0.24530, 0.24428, 0.25700, 0.21692, 0.24433, 0.24193, 0.24428, 0.24515, 0.245239,\n",
    "    2.1104,  2.2188,  2.0639,   2.187,  2.0341,  2.1061,  2.1450,  2.1092,  2.0016,   2.129,  2.0346,  2.1651,  2.1145,  2.0786,  2.11295;\n",
    "  Eigen::VectorXd z_pred(n_z);\n",
    "  z_pred <<\n",
    "    6.12155,\n",
    "     0.245993,\n",
    "     2.10313;\n",
    "  Eigen::MatrixXd S(n_z, n_z);\n",
    "  S <<\n",
    "      0.0946171, -0.000139448,   0.00407016,\n",
    "   -0.000139448,  0.000617548, -0.000770652,\n",
    "     0.00407016, -0.000770652,    0.0180917;\n",
    "  /*** Perform the UKF Innovation step ***/\n",
    "  ukf.UpdateState(&x, &P);\n",
    "  // Perform the L2 norm to compare the output values\n",
    "  Eigen::VectorXd x_expected(5, 1);\n",
    "  x_expected <<\n",
    "    5.92276,\n",
    "    1.41823,\n",
    "    2.15593,\n",
    "    0.489274,\n",
    "    0.321338;\n",
    "  Eigen::MatrixXd P_expected(5, 5);\n",
    "  P_expected <<\n",
    "    0.00361579, -0.000357881, 0.00208316, -0.000937196, -0.00071727,\n",
    "   -0.000357881, 0.00539867,  0.00156846,  0.00455342,   0.00358885,\n",
    "    0.00208316,  0.00156846,  0.00410651,  0.00160333,   0.00171811,\n",
    "   -0.000937196, 0.00455342,  0.00160333,  0.00652634,   0.00669436,\n",
    "   -0.00071719,  0.00358884,  0.00171811,  0.00669426,   0.00881797;\n",
    "  // Precision (i.e., max allowed magnitude of the outputs' L2 difference)\n",
    "  // NOTE: test works only when all variables above are set manually \n",
    "  double epsilon = 0.0001;\n",
    "  std::cout << \"Result `x` matches expected amount by `epsilon = \" << epsilon << '`';\n",
    "  std::cout << \": \" << std::boolalpha << x.isApprox(x_expected, epsilon) << \"\\n\";\n",
    "  std::cout << \"Result `P` matches expected amount by `epsilon = \" << epsilon << '`';\n",
    "  std::cout << \": \" << std::boolalpha << P.isApprox(P_expected, epsilon) << \"\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b212efa-ee8a-4fb8-9d00-240b62c00b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated state x: \n",
      " 5.92276\n",
      " 1.41823\n",
      " 2.15593\n",
      "0.489274\n",
      "0.321338\n",
      "Updated state covariance P: \n",
      "  0.00361579 -0.000357881   0.00208316 -0.000937196  -0.00071727\n",
      "-0.000357881   0.00539867   0.00156846   0.00455342   0.00358885\n",
      "  0.00208316   0.00156846   0.00410651   0.00160333   0.00171811\n",
      "-0.000937196   0.00455342   0.00160333   0.00652634   0.00669436\n",
      " -0.00071719   0.00358884   0.00171811   0.00669426   0.00881797\n",
      "Result `x` matches expected amount by `epsilon = 0.0001`: true\n",
      "Result `P` matches expected amount by `epsilon = 0.0001`: true\n"
     ]
    }
   ],
   "source": [
    "// Exercise 2.5.6: Innovation Step with State and Covariance Update\n",
    "test_update_state();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4ccd1",
   "metadata": {},
   "source": [
    "## 3. Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b334ba",
   "metadata": {},
   "source": [
    "##### Alternatives\n",
    "* Consider different values of the design parameter $\\lambda$.\n",
    "\n",
    "##### Extensions of task\n",
    "* Apply the UKF algorithm to vehicle tracking with real-world data;\n",
    "* Use the [Normalised Innovation Squared](https://kalman-filter.com/normalized-innovation-squared/) (NIS) method to measure UKF consistency w.r.t. the design parameters' experimental values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd624f6",
   "metadata": {},
   "source": [
    "## 4. Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d220eee",
   "metadata": {},
   "source": [
    "- ✅ Consider different values of the noise processes $\\sigma_{a}^{2}$ and $\\sigma_{\\ddot{\\psi}}^{2}$ for use in e.g., highway / urban / congested traffic environments;\n",
    "- ⬜️ Consider different values of the sigma point design parameter $\\lambda$ for use in e.g., highway / urban / congested traffic environments;\n",
    "- ⬜️ Use the [Normalised Innovation Squared](https://kalman-filter.com/normalized-innovation-squared/) (NIS) method to measure UKF consistency w.r.t. the design parameters' experimental values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1780e6a",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d56fce",
   "metadata": {},
   "source": [
    "This assignment was prepared by Dominik Nuss, Andrei Vatavu et al., 2020 (link [here](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)).\n",
    "\n",
    "\n",
    "References\n",
    "* [1] Kalman, R.E. A New Approach to Linear Filtering and Prediction Problems. Journal of Basic Engineering. 82(1):25-45. 1960. [doi:10.1115/1.3662552](https://doi.org/10.1115/1.3662552).\n",
    "* [2] Julier, S.J., et al. New Extension of the Kalman Filter to Nonlinear Systems. Proceedings Signal Processing, Sensor Fusion, and Target Recognition. SPIE. 3068(6):182-193. 1997. [doi:10.1117/12.280797](https://doi.org/10.1117/12.280797).\n",
    "* [3] Wan, E.A., et al. The Unscented Kalman Filter for Nonlinear Estimation. Proceeds of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and Control (Cat. No.00EX373). 2000. [doi:10.1109/ASSPCC.2000.882463](https://doi.org/10.1109/ASSPCC.2000.882463).\n",
    "* [4] Li, H. A Brief Tutorial on Recursive Estimation With Examples From Intelligent Vehicle Applications (Part III): Handling Nonlinear Estimation Problems and the Unscented Kalman Filter. 2014. [hal:01054709](https://hal.archives-ouvertes.fr/hal-01054709).\n",
    "\n",
    "Helpful resources:\n",
    "* [CTRV Model | Blog post](https://fjp.at/process%20models/model/bicycle-model/ctrv-model/);\n",
    "* [The Unscented Kalman Filter: Anything EKF can do I can do it better by H. S. Chadha | Medium](https://towardsdatascience.com/the-unscented-kalman-filter-anything-ekf-can-do-i-can-do-it-better-ce7c773cf88d);\n",
    "* [Mathematical Formula Note of Unscented Kalman Filter with CTRV model | Blog post by @fevemania](https://fevemania.github.io/blog/mathematic-formula-note-of-unscented-kalman-filter/);\n",
    "* [Normalizing Angles in UKF Robot Localization Implementation — Issue #114 | GitHub](https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/issues/114);\n",
    "* [Normalised Innovation Squared (NIS) by S. Dingler | Kalman filter for Professionals](https://kalman-filter.com/normalized-innovation-squared/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
