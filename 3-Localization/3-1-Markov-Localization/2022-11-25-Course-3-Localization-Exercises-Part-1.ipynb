{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb852bd",
   "metadata": {},
   "source": [
    "# Course 3: Localization\n",
    "## Part 1: Markov Localization in Theory\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27344dc",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd76202",
   "metadata": {},
   "source": [
    "* Apply the [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) to vehicle localisation;\n",
    "* Practise computing posterior probabilities for several observations;\n",
    "* Use the [Markov assumption](https://en.wikipedia.org/wiki/Markov_chain) and [law of total probability](https://en.wikipedia.org/wiki/Law_of_total_probability) to initialise a [Bayes' filter](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation) with meaningful estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99295b",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19f8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a5950b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f4d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d473c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting environment variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33a7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_COLAB = False               # True if running in Google Colab instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335e937c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jonathanmoran/Development/ND0013-Self-Driving-Car-Engineer/3-Localization/3-1-Markov-Localization'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Root directory\n",
    "DIR_BASE = '' if not ENV_COLAB else '/content/3-Localization'\n",
    "DIR_BASE = os.path.abspath(DIR_BASE)\n",
    "DIR_BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c2ee8",
   "metadata": {},
   "source": [
    "In this part of the Markov Localization course we set up the foundations necessary to implement the [Bayes' filter](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation) for robot localisation. In this notebook we will not be writing much code, as we leave our C++ implementation tasks to the second notebook, [`2022-11-25-Course-3-Localization-Exercises-Part-2.ipynb`](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/3-Localization/3-1-Markov-Localization/2022-11-25-Course-3-Localization-Exercises-Part-2.ipynb). Instead, we will be practising working out the Bayes' theorem calculations by hand using probability values computed for simulated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c936e9e0",
   "metadata": {},
   "source": [
    "### 1.1. Bayes' Filter for Localisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb116d7",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7965710",
   "metadata": {},
   "source": [
    "In order to apply the [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) to vehicle localisation, we must first define our state and observation variables:\n",
    "* **Observation vector**: $z_{1:t}$ — contains the sensor data, e.g., range measurements, bearing angles, images, etc., from time $t=0$ to present;\n",
    "* **Control vector**: $u_{1:t}$ — contains the vehicle control data, e.g., yaw / pitch / roll rates, velocity, etc., from time $t=0$ to present;\n",
    "* **Map**: $m$ — the map data, e.g., discretised grid space, feature maps, landmark data, etc.;\n",
    "* **Vehicle pose**: $x_{t}$ — the vehicle pose data, e.g., the 2D position $(x, y)$ and orientation angle $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d36b2",
   "metadata": {},
   "source": [
    "#### The belief state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d355f7",
   "metadata": {},
   "source": [
    "We define the belief state $bel\\left(x_{t}\\right)$, i.e., where we think the vehicle is at the current time-step $x_{t}$, as the likelihood given all prior observation and control history, including the world state information provided by the map $m$. Putting this into an expression, we obtain:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "bel\\left(x_{t}\\right) = p\\left(x_{t} \\vert z_{1:t}, u_{1:t}, m\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Given this expression we know that in order to work out the belief state update, we need all prior observation and control history. When these vectors $z_{1:t}$ and $u_{1:t}$ cover a short duration of time, say, a duration of $t=1$ to $t=10$ seconds, the belief state update can be computed without much hesitation. However, when a vehicle has been collecting data over a longer period of time, say, the six-hour long road trip from Los Angeles to San Francisco, the belief state update quickly becomes computationally intractable. Let's demonstrate this in a quick example...\n",
    "\n",
    "Suppose our test vehicle is sent on a six-hour test drive from Los Angeles to San Francisco. Assuming we have a LiDAR sensor refreshing at $10 Hz$ (i.e., 10 observations per second), which is capturing 100000 data points per observation. We also know that each of the 100000 observation data points contain five readings (points `id`, range, two inclination angles, and reflectivity info) — each of which are four bytes each. Computing the total data captured over this six-hour ride, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "size(z_{1:t}) &= 6 \\textrm{ hours} \\times \\frac{3600 \\textrm{ seconds}}{\\textrm{hour}} \\times \\frac{10 \\textrm{ cycles}}{\\textrm{seconds}} \\times \\frac{100000 \\textrm{ observation}}{\\textrm{cycle}} \\times \\frac{5 \\textrm{ data points}}{\\textrm{observation}} \\times \\frac{4 \\textrm{ bytes}}{\\textrm{data point}},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In other words, during that six-hour drive we accumulate a measurement vector $z_{1:t}$ size of $432,000,000,000$ bytes, or $\\approx 400$ GiB. That's a **lot** of data — so much so, that we'd need hundreds of GiBs of space just to store a _single_ update of the localisation posterior. This clearly won't scale beyond a few seconds of driving time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a993f2",
   "metadata": {},
   "source": [
    "#### Bayes' theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8496a08",
   "metadata": {},
   "source": [
    "In the above example we learned that the observation vector $z_{1:t}$ can be extremely large in data size, and therefore we will not want to carry the entire observation history in order to estimate the state beliefs. In this section we show that by manipulating the localisation posterior $p\\left(x_{t} \\vert z_{1:t}, u_{1:t}, m\\right)$ we obtain a recursive state estimator. In other words, we can reduce the current belief as an expression of the belief state from only one step earlier, i.e., $bel\\left(x_{t-1}\\right)$. Then, we update the current belief $bel\\left(x_{t}\\right)$ with only new observation data. With this, we are able to restrict the update to only the measurement and control data from the previous time-step.\n",
    "\n",
    "To achieve this recursive structure, we apply the [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) and [law of total probability](https://en.wikipedia.org/wiki/Law_of_total_probability). The first step in reducing our dependence on the entire observation history is to split up the vector $z_{1:t}$ into the recursive form, i.e., $z_{1:t} \\rightarrow z_{t}, z_{1:t-1}$. Applying Bayes' theorem with multiple distributions (i.e., the likelihood, prior, and normalising constant), we are able to form the following expression of the Bayes' formula:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(x_{t} \\vert z_{t}, z_{1:t-1}, u_{1:t}, m\\right) = \\frac{p\\left(z_{t} \\vert x_{t}, z_{1:t-1}, u_{1:t}, m\\right)p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right)}{p\\left(z_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here we have swapped the state and observation vectors with their previous state at $t-1$, then conditioned the probabilities based on the random variables $u_{1:t}$ and $m$. We call the likelihood term the observation model which describes the probability distribution of the observation vector under the assumption that the previous state $x_{t}$, all previous observations $z_{1:t-1}$ and all controls $u_{1:t}$, as well as the map $m$ are given. The prior probability here is the motion model, i.e., the probability distribution of current state $x_{t}$ given all previous observations $z_{1:t-1}$, all controls $u_{1:t}$, and the map $m$. Note that no current observations $z_{t}$ are included in the motion model assumption here. For the normalisation term, we define a factor $\\eta$ such that,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(x_{t} \\vert z_{t}, z_{1:t-1}, u_{1:t}, m\\right) &= \\mathrm{\\large \\eta} \\times \\frac{p\\left(z_{t} \\vert x_{t}, z_{1:t-1}, u_{1:t}, m\\right)p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right)}{1}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Summing the products of the observation and motion models over all possible states $x_{t}^{(i)}$ we obtain,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathrm{\\Large \\eta} &= \\frac{1}{p\\left(z_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right)}  = \\frac{1}{\\sum_{i} p\\left(z_{t} \\vert x_{t}^{(i)}, z_{1:t-1}, u_{1:t}, m\\right) p\\left(x_{t}^{(i)} \\vert z_{1:t-1}, u_{1:t}, m\\right)}.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a4d79",
   "metadata": {},
   "source": [
    "#### Law of total probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08a510",
   "metadata": {},
   "source": [
    "In order to estimate the vehicle state at time $t=0$, we need prior probabilities and likelihoods at a previous time-step $t-1$. Using the law of total probability, we obtain\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right) = \\int p\\left(x_{t}, x_{t-1}, z_{1:t-1}, u_{1:t}, m\\right)p\\left(x_{t-1}, z_{1:t-1}, u_{1:t}, m\\right) dx_{t-1},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "On initialisation, i.e., at time $t=0$, we can eliminate from the integral the conditions $z_{1:t-1}, u_{1:t}, m$ and the probability distribution of $x_{t-1}$ itself. However, since we have conditions in our target distribution, we have to assume that we (hypothetically) know the state at which the system is in at time-step $t-1$. We can therefore eliminate the need for past observations $z_{1:t-1}$, and controls $u_{1:t-1}$, since they would not provide us additional information needed to estimate the posterior $x_{t}$ as they were already used to estimate the previous state $x_{t-1}$. With this first assumption we simplify $p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right)$ to $p\\left(x_{t} \\vert x_{t-1}, u_{t}, m\\right)$.\n",
    "\n",
    "We also make a second assumption — since we consider $u_{t}$ from the previous time-step $t-1$, we can eliminate this term as it does not provide us with any additional information we could use to form an estimate about the previous time-step $x_{t-1}$. Therefore, we simplify $p\\left(x_{t-1} \\vert z_{1:t-1}, u_{1:t}, m\\right)$ to $p\\left(x_{t-1} \\vert z_{1:t-1}, u_{1:t-1}, m\\right)$, which restricts the controls vector to information up to only the previous time-step given for $x_{t-1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4716d89",
   "metadata": {},
   "source": [
    "#### Markov assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab194d0",
   "metadata": {},
   "source": [
    "We now have the basis needed to form a recursive state estimator. Using the first-order Markov assumption, we estimate the posterior $p\\left(x_{t} \\vert x_{1:t-1}\\right)$ using a Markov chain. In other words, we form a prediction of the current state $x_{t}$ given only the state $x_{t-1}$ at the previous time-step. With the Markov assumption we know that the previous time-step serves as the best predictor for the next-time step, and with a complete state assumption we eliminate all preceding / successive states before and after the chain formed by $x_{t-1} \\leftrightarrow x_{t}$.\n",
    "\n",
    "Since we assume that $x_{t}$ only depends on the previous state $x_{t-1}$, we can re-write the posterior as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(x_{t}\\vert x_{1:t-1}\\right) = p\\left(x_{t}\\vert x_{t-1}\\right),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In order to apply this to the motion model, we need to split the motion model $u_{1:t}$ into the current $u_{t}$ and all previous control states $u_{1:t-1}$. Following suit with the simplifications in the law of total probability steps, we re-write the integral expression of the probability distribution of $x_{t}$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " p\\left(x_{t}, x_{t-1}, z_{1:t-1}, u_{1:t}, m\\right) \\rightarrow p\\left(x_{t} \\vert x_{t-1}, u_{t}, m\\right),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "such that it is no longer conditioned on all previous observations and all previous controls. Applying the Markov assumption the first time, we obtain:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right) &= \\int p\\left(x_{t} \\vert x_{t-1}, u_{t}, m\\right) p\\left(x_{t-1} \\vert z_{1:t-1}, u_{1:t}, m\\right) dx_{t-1}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The first-order Markov assumption we derived is commonly referred to as the system/transition model. We further simplify this expression by eliminating the map $m$ from the first term in the integral as it does not influence the likelihood of the state $x_{t}$. We also simplify the second term, i.e., the posterior distribution of $x_{t-1}$ by applying the Markov assumption again. We assume that $u_{t}$ tells us nothing about $x_{t-1}$, since it is with respect to a \"future\" time-step. Therefore, we can ignore $u_{t}$ in the estimate of the previous state $x_{t-1}$ and re-write the motion model as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right) &= \\int p\\left(x_{t} \\vert x_{t-1}, u_{t}, m\\right) p\\left(x_{t-1} \\vert z_{1:t-1}, u_{1:t-1}, m\\right) dx_{t-1}.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b08418",
   "metadata": {},
   "source": [
    "The result of applying the Markov assumption twice gives us an expression of the posterior $p\\left(x_{t-1} \\vert z_{1:t-1}, u_{1:t-1}, m\\right)$ which is nothing but the belief $x_{t-1}$ from the previous time-step. Therefore, we have successfully achieved a recursive structure,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    " p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right) &= \\int p\\left(x_{t} \\vert x_{t-1}, u_{t}, m\\right) bel\\left(x_{t-1}\\right) dx_{t-1},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is completely independent from the entire control and observation history. Putting together the new recursive structure of the motion model and the previous derivation of the belief state $bel\\left(x\\right)$ given by the Bayes' formula, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "bel\\left(x\\right) = p\\left(x_{t} \\vert z_{t}, z_{1:t-1}, u_{1:t}, m\\right) = \\frac{p\\left(z_{t} x_{t}, z_{1:t-1}, u_{1:t}, m\\right) \\times p\\left(x_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right)}{p\\left(z_{t} \\vert z_{1:t-1}, u_{1:t}, m\\right)}.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba10085",
   "metadata": {},
   "source": [
    "### 1.2. Discretised Motion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8065e2",
   "metadata": {},
   "source": [
    "We will be using the following equations to represent the motion and transition models in the 1-D case:\n",
    "* **Discretised motion model**: $\\sum_{i}p\\left(x_{t} \\vert x_{t-1}^{(i)}, u_{t}, m\\right)bel\\left(x_{t-1}^{(i)}\\right)$;\n",
    "* **Transition model**: $p\\left(x_{t} \\vert x_{t-1}^{(i)}, u_{t}, m\\right)$;\n",
    "* **Motion model probability for the ith step**: $p\\left(x_{t} \\vert x_{t-1}^{(i)}, u_{t}, m\\right)*bel\\left(x_{t-1}^{(i)}\\right)$.\n",
    "\n",
    "From the discretised motion model we compute the probability that a vehicle is now at a given location, $x_{t}$. In the expression we see that the prior vehicle location $x_{t-1}$ is considered for all possible priors $x_{t-1}^{(1)}, \\ldots, x_{t-1}^{(n)}$. For each possible prior location in the list, the summation yields the **total probability** that the vehicle really did start at the prior location $x_{t-1}^(i)$ and had wound up at current position $x_{t}$. Therefore, we can reduce the expression to the likelihood of the vehicle starting at position $x_{t-1}$ and arriving at $x_{t}$ as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(x_{t} \\vert x_{t-1}^{(i)}\\right)*p\\left(x_{t-1}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We modify the expression for likelihood when incorporating all knowledge of the world state (i.e., with the inclusion of the map $m$ and the control vector $u_{t}$) with the following:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(x_{t} \\vert x_{t-1}^{(i)}, u_{t}, m\\right)*bel\\left(x_{t-1}^{(i)}\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In summary, each of the $n$ total discretised motion model calculations are the product nothing but the product of the transition probability and the belief state at the $i$th step. Taking the sum of all products $i=0,\\ldots,n$, we obtain the final position probability for the recursive structure of the motion model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38465c4b",
   "metadata": {},
   "source": [
    "### 1.3. Markov Assumption for the Observation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d31411",
   "metadata": {},
   "source": [
    "From the recursive form of the Bayes' filter derived in Part 1.1, we finalise its form with one additional step.\n",
    "\n",
    "The observation model $p\\left(z_{t} \\vert x_{t}, z_{1:t-1}, u_{1:t}, m\\right)$ becomes $p\\left(z_{t}, x_{t}, m\\right)$. Re-writing the observation model for the given vector of observations $z_{t}$ at the current time-step, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(z_{t} \\vert x_{t}, m\\right) = p\\left(z_{t}^{1}, \\ldots, z_{t}^{K} \\vert x_{t}, m\\right).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Assuming that the noise behaviour of the individual range measurements $z_{t}^{1}, \\ldots, z_{t}^{K}$ we can represent the observation model as a product of the individual probability distribution terms of each range measurement as such:\n",
    "\n",
    "$$\n",
    "p\\left(z_{t}^{1}, \\ldots, z_{t}^{K} \\vert x_{t}, m\\right) = \\prod_{k=1}^{K}p\\left(z_{t}^{k} \\vert x_{t}, m\\right).\n",
    "$$\n",
    "\n",
    "Note that each sensor (e.g., camera, LiDAR, radar, ultrasonics) will have a unique noise profile and performance. Furthermore, the observation model depends also on the map type, e.g., discretised, dense 2D or 3D grid maps, or sparse feature-based maps. In this notebook we assume that our map is a 1D range map representing the distances to the $n$ closest objects in the direction of the vehicle heading (motion). We assume in this case that our range measurement noise follows a Gaussian distribution with a standard deviation of $\\sigma_{z_{t}} = 1.0 m$. We also assume that our on-board sensor can measure distances from $0$ to $100$ metres in front of the ego-vehicle.\n",
    "\n",
    "To implement this observation model, we use the state $x_{t}$ and the given map $m$ to estimate the so-called pseudo-ranges $z_{t}^{*}$, which — when assuming the vehicle state $x_{t}$ is within the map $m$ at a specific position — represent the true range values. We define the likelihood of the pseudo-range measurements with respect to the ground-truth values as a normal distribution $p\\left(z_{t}^{k} \\vert x_{t}, m\\right) \\sim \\mathcal{N}\\left(z_{t}^{k}; z_{t}^{*k}, \\sigma_{z_{t}}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2de1c",
   "metadata": {},
   "source": [
    "### 1.4. Markov Localisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57387ec",
   "metadata": {},
   "source": [
    "We have covered a lot of information up to this point. In summary, we simplified the observation model to eliminate the dependence on all prior information. For the motion model, we used the law of total probability and the Markov assumption in order to get the desired recursive structure. In this last part, we write the general form of the Bayes' filter for localisation and express the belief state $bel\\left(x_{t}\\right)$ as the product of the simplified observation model, the update step, and the simplified motion model, the prediction step — which we write in reduced form as $\\hat{bel}\\left(x_{t}\\right)$. This gives us:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "bel\\left(x_{t}\\right) \\ &= \\ p\\left(x_{t}\\vert z_{t}, z_{1:t-1}, u_{1:t}, m\\right)\n",
    "\\ = \\ \\mathrm{\\large\\eta} \\times p\\left(z_{t} \\vert x_{t}, m\\right)\\hat{bel}\\left(x_{t}\\right). \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72b446",
   "metadata": {},
   "source": [
    "With the above expression we complete our derivation of the 1D Markov Localisation filter.\n",
    "\n",
    "Together with the Kalman filter we derived in the [last course](), we have covered in detail the general framework for recursive state estimation. Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e463f",
   "metadata": {},
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01d471",
   "metadata": {},
   "source": [
    "In this assignment we will be calculating the missing probability values in each of the tables provided below. We will use the derivations above to compute probability values given incomplete information. Good luck! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fadb9b",
   "metadata": {},
   "source": [
    "### 2.1. Calculate Localization Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a145c",
   "metadata": {},
   "source": [
    "To continue developing our intuition for this filter and prepare for later coding exercises, let's walk through the calculations for determining posterior probabilities at several pseudo-positions $x$, for a single time-step. We will start with a time-step after the filter has already been initialised and run a few times. We will cover initialisation of the filter in an upcoming concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f973ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_to_decimal(value):\n",
    "    if value in {'NULL', '?', 'None'}:\n",
    "        return np.nan\n",
    "    return '%.2E' % Decimal(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba8b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(DIR_BASE, 'data/2022-11-25-Lesson-3-1-Markov-Localization-Calculate-Localization-Posterior.csv') \n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "df = df.applymap(value_to_decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb3ef06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(location)</th>\n",
       "      <th>P(observation | location)</th>\n",
       "      <th>Raw P(location | observation)</th>\n",
       "      <th>Normalized P(location | observation)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudo_position (x)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.67E-02</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86E-02</td>\n",
       "      <td>6.99E-03</td>\n",
       "      <td>NAN</td>\n",
       "      <td>2.59E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.90E-02</td>\n",
       "      <td>8.52E-02</td>\n",
       "      <td>4.18E-03</td>\n",
       "      <td>4.01E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.86E-02</td>\n",
       "      <td>NAN</td>\n",
       "      <td>5.42E-03</td>\n",
       "      <td>5.21E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>3.13E-02</td>\n",
       "      <td>5.31E-04</td>\n",
       "      <td>5.10E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.51E-03</td>\n",
       "      <td>9.46E-04</td>\n",
       "      <td>6.16E-06</td>\n",
       "      <td>NAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NAN</td>\n",
       "      <td>3.87E-06</td>\n",
       "      <td>6.55E-08</td>\n",
       "      <td>6.29E-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.86E-02</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    P(location) P(observation | location)  \\\n",
       "pseudo_position (x)                                         \n",
       "1                      1.67E-02                  0.00E+00   \n",
       "2                      3.86E-02                  6.99E-03   \n",
       "3                      4.90E-02                  8.52E-02   \n",
       "4                      3.86E-02                       NAN   \n",
       "5                      1.69E-02                  3.13E-02   \n",
       "6                      6.51E-03                  9.46E-04   \n",
       "7                           NAN                  3.87E-06   \n",
       "8                      3.86E-02                  0.00E+00   \n",
       "\n",
       "                    Raw P(location | observation)  \\\n",
       "pseudo_position (x)                                 \n",
       "1                                        0.00E+00   \n",
       "2                                             NAN   \n",
       "3                                        4.18E-03   \n",
       "4                                        5.42E-03   \n",
       "5                                        5.31E-04   \n",
       "6                                        6.16E-06   \n",
       "7                                        6.55E-08   \n",
       "8                                        0.00E+00   \n",
       "\n",
       "                    Normalized P(location | observation)  \n",
       "pseudo_position (x)                                       \n",
       "1                                               0.00E+00  \n",
       "2                                               2.59E-02  \n",
       "3                                               4.01E-01  \n",
       "4                                               5.21E-01  \n",
       "5                                               5.10E-02  \n",
       "6                                                    NAN  \n",
       "7                                               6.29E-06  \n",
       "8                                               0.00E+00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a61fa",
   "metadata": {},
   "source": [
    "Recall the general form of the Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P\\left(a\\vert b\\right) = \\frac{P\\left(b \\vert a\\right)P\\left(a\\right)}{P\\left(b\\right)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For the localisation problem, we have the following terms:\n",
    "* $P\\left(\\textrm{location} \\ \\vert \\ \\textrm{observation}\\right)$ — the posterior probability $P\\left(a \\vert b\\right)$, i.e., the _normalised_ probability of a position given the observation;\n",
    "* $P\\left(\\textrm{observation} \\ \\vert \\ \\textrm{location}\\right)$ — the likelihood $P\\left(b \\vert a\\right)$, i.e., the probability of an observation given a position;\n",
    "* $P\\left(\\textrm{location}\\right)$ — the prior probability $P\\left(a\\right)$, i.e., the probability of a position;\n",
    "* $P\\left(\\textrm{observation}\\right)$ — the prior probability $P\\left(b\\right)$, i.e., the probability of an observation.\n",
    "\n",
    "Note that in the table above we have the **Normalized P(location | observation)** term, which is the **Raw P(location | observation)** term after dividing by the $P\\left(\\textrm{observation}\\right)$ value — the total probability of $P\\left(b\\right)$. In other words, the entire fraction given on the right-hand side of the Bayes' rule.  Consequently, the **Raw P(location | observation)** term is the posterior probability prior to dividing by the total probability $P\\left(\\textrm{observation}\\right)$, i.e., the numerator of the fraction on the right-hand side of the Bayes' rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d2cba",
   "metadata": {},
   "source": [
    "#### The observation likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c65c8c",
   "metadata": {},
   "source": [
    "To compute the observation likelihood term, $P\\left(\\textrm{observation} \\ \\vert \\ \\textrm{location} \\right)$, for the pseudo-position $x=4$, we use the following relation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P\\left(\\textrm{b} \\vert \\textrm{a}\\right) = \\frac{P\\left(a \\vert b\\right)}{P\\left(a\\right)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which we obtain after re-arranging the general form of the Bayes' rule. Note that here this corresponds to dividing the posterior term **Raw P(location | observation)** by the location prior probability **P(location)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4a7f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(location)                             3.86E-02\n",
       "P(observation | location)                    NAN\n",
       "Raw P(location | observation)           5.42E-03\n",
       "Normalized P(location | observation)    5.21E-01\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The pseudo-position x=4\n",
    "x_4 = df.iloc[3]\n",
    "x_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdece140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.40E-01'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculating the probability value\n",
    "x_4 = x_4.astype(np.float64)\n",
    "p_4 = value_to_decimal(x_4['Raw P(location | observation)'] / x_4['P(location)'])\n",
    "p_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68212660",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the value in the DataFrame\n",
    "df['P(observation | location)'][4] = p_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e7278",
   "metadata": {},
   "source": [
    "#### The posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79be349",
   "metadata": {},
   "source": [
    "To compute the raw posterior probability term, **Raw P(location | observation)**, for the pseudo-position $x = 2$, we use the following relation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P\\left(\\textrm{posterior}\\right) = P\\left(b \\vert a\\right) * P\\left(a\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is non-normalised expression on the right-hand side of the Bayes' rule. In other words, the product of the likelihood $P\\left(b \\vert a\\right)$ and prior probability $P\\left(a\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfa39dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(location)                             3.86E-02\n",
       "P(observation | location)               6.99E-03\n",
       "Raw P(location | observation)                NAN\n",
       "Normalized P(location | observation)    2.59E-02\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The pseudo-position x=2\n",
    "x_2 = df.iloc[1]\n",
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d2faab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.70E-04'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculating the probability value\n",
    "x_2 = x_2.astype(np.float64)\n",
    "p_2 = value_to_decimal(x_2['P(observation | location)'] * x_2['P(location)'])\n",
    "p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b213bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the value in the DataFrame\n",
    "df['Raw P(location | observation)'][2] = p_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457ee89",
   "metadata": {},
   "source": [
    "#### The normalised posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177944f",
   "metadata": {},
   "source": [
    "To compute the normalised posterior probability for the pseudo-position $x = 6$, we have to first obtain the sum of the **Raw P(location | observation)** terms to get the total posterior probability. Using the expression for the normalising constant $P\\left(b\\right) we have:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p\\left(\\theta\\right) = \\int p\\left(x \\vert \\theta\\right)p\\left(\\theta\\right)d\\theta = \\sum_{x=1}^{n} p\\left(x \\vert a\\right)p\\left(a\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is the sum over all non-normalised posterior values as given by the [law of total probability](https://en.wikipedia.org/wiki/Bayesian_statistics#Bayes'_theorem). Assuming we have a discrete distribution given by psuedo-position variable $x$, this is nothing but the sum over the product of the likelihood and prior probability value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1585804",
   "metadata": {},
   "source": [
    "Therefore, we add all values **Raw P(location | observation)** from $x=1$ to $x=8$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b380e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pseudo_position (x)\n",
       "1    0.000000e+00\n",
       "2    2.700000e-04\n",
       "3    4.180000e-03\n",
       "4    5.420000e-03\n",
       "5    5.310000e-04\n",
       "6    6.160000e-06\n",
       "7    6.550000e-08\n",
       "8    0.000000e+00\n",
       "Name: Raw P(location | observation), dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_posterior_raw = df['Raw P(location | observation)'].astype(np.float64)\n",
    "P_posterior_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77443f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0104072255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Summing the non-normalised total posterior probability\n",
    "p_sum = P_posterior_raw.sum()\n",
    "p_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53a98c",
   "metadata": {},
   "source": [
    "Then, to find the normalised posterior probability, we divide the raw posterior probability value **Raw P(location | observation)** at the given pseduo-position $x = 6$ by the total probability normalisation term we computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7750d23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.92E-04'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculating the normalised posterior probability\n",
    "p_6 = value_to_decimal(P_posterior_raw[6] / p_sum)\n",
    "p_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b828eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the value in the DataFrame\n",
    "df['Normalized P(location | observation)'][6] = p_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e1478a",
   "metadata": {},
   "source": [
    "#### The prior position probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635face",
   "metadata": {},
   "source": [
    "To compute the prior position probability for the pseudo-position $x = 7$, we can divide the posterior probability $P\\left(\\textrm{posterior}\\right)$ by the prior observation probability $P\\left(b\\right)$. Recalling the formula for $P\\left(\\textrm{posterior}\\right)$,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P\\left(\\textrm{posterior}\\right) = P\\left(b \\vert a\\right) * P\\left(a\\right),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and knowing that **Normalized P(location | observation)** is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P\\left(a \\vert b\\right) = \\frac{P\\left(b \\vert a\\right) * P\\left(a\\right)}{P\\left(b\\right)},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "we obtain the prior position probability by dividing the posterior **Raw P(location | observation)** by the observation likelihood **P(observation | location)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3dc3557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(location)                                  NAN\n",
       "P(observation | location)               3.87E-06\n",
       "Raw P(location | observation)           6.55E-08\n",
       "Normalized P(location | observation)    6.29E-06\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The pseudo-position x=7\n",
    "x_7 = df.iloc[6]\n",
    "x_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee946b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.69E-02'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculating the prior position probability\n",
    "x_7 = x_7.astype(np.float64)\n",
    "p_7 = value_to_decimal(\n",
    "    x_7['Raw P(location | observation)'] / x_7['P(observation | location)']\n",
    ")\n",
    "p_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2d355db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the value in the DataFrame\n",
    "df['P(location)'] = p_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89d053",
   "metadata": {},
   "source": [
    "#### The final DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac26d6",
   "metadata": {},
   "source": [
    "With the above calculations, we obtain a complete probability distribution with values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee7545f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(location)</th>\n",
       "      <th>P(observation | location)</th>\n",
       "      <th>Raw P(location | observation)</th>\n",
       "      <th>Normalized P(location | observation)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudo_position (x)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>6.99E-03</td>\n",
       "      <td>2.70E-04</td>\n",
       "      <td>2.59E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>8.52E-02</td>\n",
       "      <td>4.18E-03</td>\n",
       "      <td>4.01E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>1.40E-01</td>\n",
       "      <td>5.42E-03</td>\n",
       "      <td>5.21E-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>3.13E-02</td>\n",
       "      <td>5.31E-04</td>\n",
       "      <td>5.10E-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>9.46E-04</td>\n",
       "      <td>6.16E-06</td>\n",
       "      <td>5.92E-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>3.87E-06</td>\n",
       "      <td>6.55E-08</td>\n",
       "      <td>6.29E-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.69E-02</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "      <td>0.00E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    P(location) P(observation | location)  \\\n",
       "pseudo_position (x)                                         \n",
       "1                      1.69E-02                  0.00E+00   \n",
       "2                      1.69E-02                  6.99E-03   \n",
       "3                      1.69E-02                  8.52E-02   \n",
       "4                      1.69E-02                  1.40E-01   \n",
       "5                      1.69E-02                  3.13E-02   \n",
       "6                      1.69E-02                  9.46E-04   \n",
       "7                      1.69E-02                  3.87E-06   \n",
       "8                      1.69E-02                  0.00E+00   \n",
       "\n",
       "                    Raw P(location | observation)  \\\n",
       "pseudo_position (x)                                 \n",
       "1                                        0.00E+00   \n",
       "2                                        2.70E-04   \n",
       "3                                        4.18E-03   \n",
       "4                                        5.42E-03   \n",
       "5                                        5.31E-04   \n",
       "6                                        6.16E-06   \n",
       "7                                        6.55E-08   \n",
       "8                                        0.00E+00   \n",
       "\n",
       "                    Normalized P(location | observation)  \n",
       "pseudo_position (x)                                       \n",
       "1                                               0.00E+00  \n",
       "2                                               2.59E-02  \n",
       "3                                               4.01E-01  \n",
       "4                                               5.21E-01  \n",
       "5                                               5.10E-02  \n",
       "6                                               5.92E-04  \n",
       "7                                               6.29E-06  \n",
       "8                                               0.00E+00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a327f15",
   "metadata": {},
   "source": [
    "From the [law of total probability](https://en.wikipedia.org/wiki/Law_of_total_probability) we know that our posterior probability values for the discrete 1-D case should add up to $1.0$. \n",
    "\n",
    "To verify this, we take the sum of the resulting normalised posterior values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d425889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994982900000001"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Summing the normalised posterior values\n",
    "df['Normalized P(location | observation)'].astype(np.float64).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4c46b",
   "metadata": {},
   "source": [
    "such that we obtain a resulting total probability very close to $1.0$.\n",
    "\n",
    "Hooray! This was a great start to Bayesian statistics, which we will use together with the [Markov Assumption](https://en.wikipedia.org/wiki/Markov_chain) to perform inference over the map range space using a [Bayes' filter](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation). This will allow us to estimate vehicle location using nothing but a single pair of consecutive measurements and a 1-D range map, i.e., a set of landmark positions defined relative to the ego-vehicle heading. Let's go! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd09e85",
   "metadata": {},
   "source": [
    "### 2.2. Initialize Belief State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374f443",
   "metadata": {},
   "source": [
    "To help develop an intuition for this filter and prepare for later coding exercises, let's walk through the process of initialising our prior belief state. That is, what values should our initial belief state take on for each possible position?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6aeed",
   "metadata": {},
   "source": [
    "#### Warmup example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ad13d1",
   "metadata": {},
   "source": [
    "Suppose we have a 1D map extending from $0$ to $25$ metres. We have landmarks at $x = 5.0$, $x=10.0$ and $x=20.0$ metres, with a position standard deviation of $1.0$ metre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72ec751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_map = 25\n",
    "landmarks = [4, 9, 19]    # Indexing starting at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "876aa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialising the position vector\n",
    "positions = np.zeros((len_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b7e66",
   "metadata": {},
   "source": [
    "Assuming that we know our initial vehicle position is at one of these three landmarks, how should we define our initial belief state?\n",
    "\n",
    "Given that we know our vehicle is parked next to a landmark, we can set our probability of being next to a landmark to $1.0$. Accounting for a position standard deviation of $\\pm 1.0$ metres, this results in three non-zero initial position estimates, each within the range $\\left[4, 6\\right]$, $\\left[9, 11\\right]$ and $\\left[19, 21\\right]$. All other positions not in these ranges, i.e., positions not within $\\pm 1.0$ metre from a landmark, are initialised to $0.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "383535f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Setting the landmarks\n",
    "positions[landmarks] = 1.0\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11fe5811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Setting the landmarks' neighbouring positions +/- 1.0m away\n",
    "positions[np.array(landmarks) - 1] = 1.0    # Left of the landmarks\n",
    "positions[np.array(landmarks) + 1] = 1.0    # Right of the landmarks\n",
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a9ab3",
   "metadata": {},
   "source": [
    "We then divide each position probability value by the total number of possible non-zero position probabilities such that the normalised total probability sums to $1.0$. In this case, we have $9$ non-zero position probabilities from $3$ landmarks, resulting in an individual position probability value of $1.0 / 9 = 1.11\\mathrm{E}{-01}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86fba18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the prior position probability\n",
    "prior = 1.0 / np.count_nonzero(positions)\n",
    "positions *= prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aaaac3",
   "metadata": {},
   "source": [
    "Therefore, we have the following belief state vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f2b461a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "       0.11111111, 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "       0.11111111, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "       0.11111111, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c03e309",
   "metadata": {},
   "source": [
    "#### Quiz question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2746ebf",
   "metadata": {},
   "source": [
    "To reinforce this concept, let's practice with a quiz.\n",
    "\n",
    "Here we define the problem statement:\n",
    "* **Map size**: $100$ metres;\n",
    "* **Landmark positions**: $\\{8, 15, 30, 70, 80\\}$;\n",
    "* **Position standard deviation**: $2.0$ metres.\n",
    "\n",
    "We also assume that the vehicle starts out parked at one of the five possible landmarks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2868cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_map = 100                      # Range [0, 99] metres\n",
    "landmarks = [7, 14, 29, 69, 79]    # Indexing starting at 0\n",
    "stdev = 2                          # +/- 2.0m position precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1f6f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialising the position vector\n",
    "positions = np.zeros((len_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45bc4ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d54b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the landmarks and their neighbouring positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f7ba563",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = np.array(landmarks)\n",
    "for i in range(0, stdev + 1):\n",
    "    positions[landmarks - i] = 1.0\n",
    "    positions[landmarks + i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17a99e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0312a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the prior position probability\n",
    "prior = 1.0 / np.count_nonzero(positions)\n",
    "positions *= prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7c7d0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.04, 0.04, 0.04, 0.04, 0.  ,\n",
       "       0.  , 0.04, 0.04, 0.04, 0.04, 0.04, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.04, 0.04, 0.04, 0.04, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.04, 0.04, 0.04, 0.04, 0.04, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2da212",
   "metadata": {},
   "source": [
    "##### The initial position probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fc50b",
   "metadata": {},
   "source": [
    "To compute the prior probability for the position $x = 11$, we can simply fetch the corresponding probability value at the given position in the belief state vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6ab29a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00E+00'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fetching the prior position probability for x = 11\n",
    "p_11 = positions[10]    # Indexing starting at 0\n",
    "value_to_decimal(p_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecdd4dc",
   "metadata": {},
   "source": [
    "To compute the prior probability for the position $x = 71$, we can simply fetch the corresponding probability value at the given position in the belief state vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26552372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.00E-02'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fetching the prior position probability for x = 11\n",
    "p_71 = positions[70]    # Indexing starting at 0\n",
    "value_to_decimal(p_71)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e63c6",
   "metadata": {},
   "source": [
    "In summary, we can obtain the initial position probability by dividing the total probability $1.0$ by the number of non-zero position probabilities. Here, that is $1.0$ divided by the total number of positions within $2.0$ metres of a landmark. Since we have $5$ landmarks with a standard deviation of $\\pm 2.0$ metres, that yields $5$ potentially occupied positions at each landmark position (i.e., the landmark plus two positions on each side). Therefore, we have $25$ total possible non-zero positions, resulting in a prior probability value of $1.0 / 25 = 4.00\\mathrm{E}{-02}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a3dc8",
   "metadata": {},
   "source": [
    "### 2.3. Motion Model Probability II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392d4ff",
   "metadata": {},
   "source": [
    "Applying the discretised motion model we derived at the beginning of this notebook, we will see how we can use the belief from the previous time-step $bel\\left(x_{t-1}\\right)$ to estimate the state transition probabilities between a pre-pseudo and pseudo position **delta position**. Let's fetch the data from our problem statement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "453a23cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre-pseudo_position</th>\n",
       "      <th>delta position</th>\n",
       "      <th>P(transition)</th>\n",
       "      <th>bel(xt−1​)</th>\n",
       "      <th>P(position)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudo_position (x)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>8.270000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>7.440000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>2.460000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.660000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.00179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pre-pseudo_position  delta position  P(transition)  \\\n",
       "pseudo_position (x)                                                       \n",
       "7                                      1             6.0       0.000001   \n",
       "7                                      2             5.0       0.000134   \n",
       "7                                      3             4.0       0.004430   \n",
       "7                                      4             NaN       0.054000   \n",
       "7                                      5             2.0            NaN   \n",
       "7                                      6             1.0       0.399000   \n",
       "7                                      7             0.0       0.242000   \n",
       "7                                      8            -1.0       0.054000   \n",
       "\n",
       "                     bel(xt−1​)   P(position)  \n",
       "pseudo_position (x)                            \n",
       "7                       0.05560  8.270000e-08  \n",
       "7                       0.05560  7.440000e-06  \n",
       "7                       0.05560  2.460000e-04  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                           NaN  1.660000e-03  \n",
       "7                       0.00179           NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(\n",
    "    DIR_BASE,\n",
    "    'data/2022-11-25-Lesson-3-1-Markov-Localization-Motion-Model-Probability-II.csv'\n",
    ")\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "df.applymap(value_to_decimal)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debff5bf",
   "metadata": {},
   "source": [
    "#### The position deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752ae28",
   "metadata": {},
   "source": [
    "In order to compute the delta position $x$, we subtract the **pseudo_position (x)** value from the **pre-pseudo_position** to obtain the values in the **delta position** column.\n",
    "\n",
    "For example, we have the following delta position for a pseudo-position $x$ of $7$ and a pre-pseudo position of $4$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ff62be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pre-pseudo_position    4.000\n",
       "delta position           NaN\n",
       "P(transition)          0.054\n",
       "bel(xt−1​)             0.000\n",
       "P(position)            0.000\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pseudo = 7\n",
    "x_pre_pseudo = 4\n",
    "x_7_4 = df.loc[x_pseudo].iloc[x_pre_pseudo - 1]    # Indexing starting at zero\n",
    "x_7_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c59e17ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculating the delta position\n",
    "d_4 = x_pseudo - x_pre_pseudo\n",
    "d_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88ac7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the delta position in the DataFrame\n",
    "df['delta position'][x_pseudo].iloc[x_pre_pseudo - 1] = d_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4488ce4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre-pseudo_position</th>\n",
       "      <th>delta position</th>\n",
       "      <th>P(transition)</th>\n",
       "      <th>bel(xt−1​)</th>\n",
       "      <th>P(position)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudo_position (x)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>8.270000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>7.440000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>2.460000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.660000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.00179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pre-pseudo_position  delta position  P(transition)  \\\n",
       "pseudo_position (x)                                                       \n",
       "7                                      1             6.0       0.000001   \n",
       "7                                      2             5.0       0.000134   \n",
       "7                                      3             4.0       0.004430   \n",
       "7                                      4             3.0       0.054000   \n",
       "7                                      5             2.0            NaN   \n",
       "7                                      6             1.0       0.399000   \n",
       "7                                      7             0.0       0.242000   \n",
       "7                                      8            -1.0       0.054000   \n",
       "\n",
       "                     bel(xt−1​)   P(position)  \n",
       "pseudo_position (x)                            \n",
       "7                       0.05560  8.270000e-08  \n",
       "7                       0.05560  7.440000e-06  \n",
       "7                       0.05560  2.460000e-04  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                           NaN  1.660000e-03  \n",
       "7                       0.00179           NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b4a74",
   "metadata": {},
   "source": [
    "#### The transition probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a73b3",
   "metadata": {},
   "source": [
    "Suppose we have a pseudo-position $x=7$ and a pre-pseduo position of $x = 5$. We can use the probability distribution function (PDF) of a continuous normal distribution to determine a corresponding transition probability value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba68de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pseudo = 7\n",
    "x_pre_pseudo = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d16fc1d",
   "metadata": {},
   "source": [
    "To determine the transition probability for a pseudo-position $x= 7$ and a pre-pseudo position of $x = 5$, we evaluate the probability distribution function (PDF) with a control parameter of $1.0$ and a position standard deviation of $1.0$. Note that we are evaluating the PDF of the normal distribution at the _delta_ position $x = 7 - 5 = 2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bc41037",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_delta = x_pseudo - x_pre_pseudo\n",
    "control_parameter = 1.0\n",
    "stdev_position = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4025b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c2990d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.42E-01'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Obtaining the transition probability for the delta position\n",
    "p_t_delta = norm.pdf(x_delta, loc=control_parameter, scale=stdev_position)\n",
    "value_to_decimal(p_t_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df92b2",
   "metadata": {},
   "source": [
    "Note that we can also use the `normpdf` function we wrote previously in C++ from the [`2022-11-25-Course-3-Localization-Exercises-Part-2.ipynb`]() to evaluate the PDF and obtain the transition probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6310a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the transition probability in the DataFrame\n",
    "df['P(transition)'][x_pseudo].iloc[x_pre_pseudo - 1] = p_t_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c32946",
   "metadata": {},
   "source": [
    "#### The belief state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a417f",
   "metadata": {},
   "source": [
    "To calculate the belief state of a given $x_{t-1}$, we can use the following relation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{P(position)} = \\textbf{P(transition)} * \\textbf{bel(xt-1)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Rearranging the above in terms of the **bel(xt-1)**, we obtain an expression for the belief state equal to the position probability **P(position)** divided by the transition probability **P(transition)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22784f8f",
   "metadata": {},
   "source": [
    "Calculating the belief state for the second-to-last row in our table, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7769fff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pre-pseudo_position    7.00000\n",
       "delta position         0.00000\n",
       "P(transition)          0.24200\n",
       "bel(xt−1​)                 NaN\n",
       "P(position)            0.00166\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pseudo = 7\n",
    "x_pre_pseudo = 7\n",
    "x_7_7 = df.loc[x_pseudo].iloc[x_pre_pseudo - 1]    # Indexing starting at zero\n",
    "x_7_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d99e0aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.86E-03'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Computing the belief state\n",
    "x_7_7 = x_7_7.astype(np.float64)\n",
    "p_bel = x_7_7['P(position)'] / x_7_7['P(transition)']\n",
    "value_to_decimal(p_bel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a0578e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the belief state in the DataFrame\n",
    "df['bel(xt−1​)'][x_pseudo].iloc[x_pre_pseudo - 1] = p_bel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899a4dc",
   "metadata": {},
   "source": [
    "#### The position probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16577887",
   "metadata": {},
   "source": [
    "To determine the discretised position probability for a pseudo-position $x-7$ and a pre-pseudo position of $x=8$, we can calculate the position probability with the following relation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\textbf{P(position)} = \\textbf{P(transition)} * \\textbf{bel(xt-1)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore we have,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2ff9d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pre-pseudo_position    8.00000\n",
       "delta position        -1.00000\n",
       "P(transition)          0.05400\n",
       "bel(xt−1​)             0.00179\n",
       "P(position)                NaN\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pseudo = 7\n",
    "x_pre_pseudo = 8\n",
    "x_7_8 = df.loc[x_pseudo].iloc[x_pre_pseudo - 1]    # Indexing starting at zero\n",
    "x_7_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "701fdd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pre-pseudo_position', 'delta position', 'P(transition)', 'bel(xt−1​)',\n",
       "       'P(position)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_7_8.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35b6c802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.666e-05"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Computing the position probability\n",
    "x_7_8 = x_7_8.astype(np.float64)\n",
    "p_pos = x_7_8['P(transition)'] * x_7_8['bel(xt−1​)']\n",
    "p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "942a93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the position probability in the DataFrame\n",
    "df['P(position)'][x_pseudo].iloc[x_pre_pseudo - 1] = p_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff404ba",
   "metadata": {},
   "source": [
    "#### The aggregated discretised position probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a911a",
   "metadata": {},
   "source": [
    "Given our complete table of probability values, we can compute the total probability returned by the motion model as the sum of the discrete probability values from the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "369f2139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre-pseudo_position</th>\n",
       "      <th>delta position</th>\n",
       "      <th>P(transition)</th>\n",
       "      <th>bel(xt−1​)</th>\n",
       "      <th>P(position)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudo_position (x)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>8.270000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>7.440000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.05560</td>\n",
       "      <td>2.460000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.241971</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.00686</td>\n",
       "      <td>1.660000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.00179</td>\n",
       "      <td>9.666000e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pre-pseudo_position  delta position  P(transition)  \\\n",
       "pseudo_position (x)                                                       \n",
       "7                                      1             6.0       0.000001   \n",
       "7                                      2             5.0       0.000134   \n",
       "7                                      3             4.0       0.004430   \n",
       "7                                      4             3.0       0.054000   \n",
       "7                                      5             2.0       0.241971   \n",
       "7                                      6             1.0       0.399000   \n",
       "7                                      7             0.0       0.242000   \n",
       "7                                      8            -1.0       0.054000   \n",
       "\n",
       "                     bel(xt−1​)   P(position)  \n",
       "pseudo_position (x)                            \n",
       "7                       0.05560  8.270000e-08  \n",
       "7                       0.05560  7.440000e-06  \n",
       "7                       0.05560  2.460000e-04  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                       0.00000  0.000000e+00  \n",
       "7                       0.00686  1.660000e-03  \n",
       "7                       0.00179  9.666000e-05  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2ab774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.01E-03'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Computing the total discretised position probability\n",
    "p_total = df['P(position)'].sum()\n",
    "value_to_decimal(p_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afafaa57",
   "metadata": {},
   "source": [
    "The total position probability we obtained approximates the probability value extracted from a continuous normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931132f",
   "metadata": {},
   "source": [
    "### 2.4. Observation Model Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e23c0",
   "metadata": {},
   "source": [
    "We will complete the Bayes' filter exercises by implementing the observation model. The observation model uses psuedo-range measurement estimates $z_{t}^{*}$ and observation measurements $z_{t}$ as inputs.\n",
    "\n",
    "In order to implement the observation model, we must perform the following at each time-step:\n",
    "1. Collect measurements from the vehicle in the forward direction of motion;\n",
    "2. Estimate the pseudo-range of each landmark by subtracting the pseudo- position from the true landmark position;\n",
    "3. Associate each pseudo-range estimate to its nearest observation measurement;\n",
    "4. Calculate the probability of each pseudo-range / observation measurement pair;\n",
    "5. Return the product of all individual probabilities.\n",
    "\n",
    "The final probability must factor in all pseudo-range / observation pairs. Therefore, by taking the [product](https://bio.libretexts.org/Bookshelves/Introductory_and_General_Biology/Book%3A_General_Biology_(Boundless)/12%3A_Mendel's_Experiments_and_Heredity/12.01%3A_Mendels_Experiments_and_the_Laws_of_Probability/12.1E%3A_Rules_of_Probability_for_Mendelian_Inheritance#:~:text=The%20product%20rule%20of%20probability,of%20each%20event%20occurring%20alone.) of the individual probability values in Step 5, we compute the intersection of the individual events and obtain an estimate that reflects the overall belief state.\n",
    "\n",
    "\n",
    "Let's practice this with an example. Assuming the following:\n",
    "* **Pseudo-position**: $x_{t} = 10m$ — position of vehicle relative to the map range;\n",
    "* **Landmark positions vector**: $X_{m} = \\left[6, 15, 21, 40\\right]$ — relative distance (metres) to the landmarks in direction of vehicle heading;\n",
    "* **Observation measurements vector**: $z_{t_{k}} = \\left[5.5, 11.0\\right]$ — relative distances (metres) to the objects (landmarks);\n",
    "* **Observation standard deviation**: $\\sigma_{t_{k}} = 1.0 m$ — the observation measurement error.\n",
    "\n",
    "We will compute the individual quantities needed to form the final observation probability. Defining the problem statement, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "114f8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pseudo-position\n",
    "x_t = 10\n",
    "# The landmark positions\n",
    "X_m = [6, 15, 21, 40]\n",
    "# The observation measurements\n",
    "z_t = [5.5, 11.0]\n",
    "# The observation standard deviation\n",
    "sigma_t = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba5ad3",
   "metadata": {},
   "source": [
    "#### The pseudo-range estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8826d9",
   "metadata": {},
   "source": [
    "Given the vector of landmark positions $X_{m}$ located on the map $m$, we calculate the pseudo-range estimates using the observation probability distribution $p\\left(z_{t}^{k} \\vert x_{t}, m\\right) \\sim \\mathcal{N}\\left(z_{t}^{k}; z_{t}^{*k}, \\sigma_{z_{t}}\\right)$.\n",
    "\n",
    "In order to estimate the pseudo-ranges, we first limit the landmark positions vector to only the positions in front of the vehicle at its current position.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e16aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 21, 40])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Filtering landmarks to those in front of vehicle \n",
    "X_m = np.array(X_m)\n",
    "X_t = X_m[np.where(X_m >= x_t)]\n",
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e6111ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11, 30])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting the landmark positions relative to the vehicle\n",
    "landmarks_rel = X_t - x_t\n",
    "landmarks_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b523ed",
   "metadata": {},
   "source": [
    "#### Association"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ef0f5",
   "metadata": {},
   "source": [
    "Given a set of observation measurements $z_{t_{k}}$ and estimated pseudo-ranges $z_{t}^{*}$, we perform nearest-neighbour association. In other words, we assign each measurement to the closest landmark using a single closest neighbour assignment (i.e., no re-assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "354d86c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.5, 5), (11.0, 11)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Computing the nearest-neighbour associations\n",
    "l_rel = list(landmarks_rel)\n",
    "pairs = [(z, l_rel.pop(np.argmin(l_rel))) for z in z_t]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f71e62",
   "metadata": {},
   "source": [
    "#### The association probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd22f30",
   "metadata": {},
   "source": [
    "Using the probability distribution function (PDF) of the Gaussian normal distribution, we can compute the association likelihood values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ab2efda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.52E-01', '3.99E-01']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Computing the association probabilities\n",
    "probs = [\n",
    "    norm.pdf(observation_measurement, pseudo_range_estimate, sigma_t)\n",
    "    for observation_measurement, pseudo_range_estimate in pairs\n",
    "]\n",
    "[value_to_decimal(p) for p in probs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00cfef5",
   "metadata": {},
   "source": [
    "#### The observation model probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b5dad",
   "metadata": {},
   "source": [
    "Recall that the overall observation probability is given as the product of the individual association probabilities. Therefore, we obtain the estimate of the overall belief state as the intersection of the individual observation measurement / pseudo-range estimate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6760e2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.40E-01'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.prod(probs)\n",
    "value_to_decimal(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c2729",
   "metadata": {},
   "source": [
    "That's it! We've successfully completed all tasks from this Lesson in Markov Localization. Now, it's time to move onto the coding in C++. See you in [`2022-11-25-Course-3-Markov-Localization-Exercises-Part-2.ipynb`](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/3.1/3-Localization/3-1-Markov-Localization/2022-11-25-Course-3-Localization-Exercises-Part-2.ipynb)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05948f8b",
   "metadata": {},
   "source": [
    "## 3. Closing Remarks\n",
    "##### Alternatives\n",
    "* Implement the particle filter using the [Monte Carlo method](https://en.wikipedia.org/wiki/Monte_Carlo_method);\n",
    "* Use the [log-normal accumulation](https://en.wikipedia.org/wiki/Log-normal_distribution#Multiplication_and_division_of_independent,_log-normal_random_variables) instead of product rule to avoid numerical underflow when computing the observation model probability (i.e., the sensor model) — see pp.9-10 in UT slides linked in Credits.\n",
    "\n",
    "##### Extensions of task\n",
    "* Implement the 1D [recursive Bayes' filter](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation) in C++.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1d1a5",
   "metadata": {},
   "source": [
    "## 4. Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2efc366",
   "metadata": {},
   "source": [
    "* ⬜️ Implement the 1D [recursive Bayes' filter](https://en.wikipedia.org/wiki/Recursive_Bayesian_estimation) (i.e., Markov Localization) in C++."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f90ab",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9007617d",
   "metadata": {},
   "source": [
    "This assignment was prepared by Aaron Brown, Tiffany Huang and Maximilian Muffert of Mercedes-Benz Research & Development of North America (MBRDNA), 2021 (link [here](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)).\n",
    "\n",
    "Helpful resources:\n",
    "* [`2022-11-25-Course-3-Localization-Exercises-Part-2.ipynb` by J. L. Moran | GitHub](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/blob/main/3-Localization/3-1-Markov-Localization/2022-11-25-Course-3-Localization-Exercises-Part-2.ipynb)\n",
    "* [Lecture 5: Markov Localization by B. Kupers | UT CS 395T Lecture Slides](https://www.cs.utexas.edu/~kuipers/handouts/S07/L5%20Markov%20localization.pdf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
