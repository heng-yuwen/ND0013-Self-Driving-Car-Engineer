{"metadata":{"kernelspec":{"display_name":"C++14","language":"C++14","name":"xcpp14"},"language_info":{"codemirror_mode":"text/x-c++src","file_extension":".cpp","mimetype":"text/x-c++src","name":"c++","version":"14"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Course 4: Planning\n## Part 2: Trajectory Generation\n#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\nFrom the Self-Driving Car Engineer Nanodegree programme offered at Udacity.","metadata":{},"id":"772f1688-85f3-44b0-9a84-680484f2c2d6"},{"cell_type":"markdown","source":"## Objectives","metadata":{},"id":"83339853-8fb1-4578-a24c-49eb96ed557d"},{"cell_type":"markdown","source":"* Form a strong understanding of the basics of motion planning algorithms;\n* Review the hybrid [A*](https://en.wikipedia.org/wiki/A*_search_algorithm) and its use in the Stanford Junior;\n* Implement the hybrid [A*](https://en.wikipedia.org/wiki/A*_search_algorithm) search algorithm in Python and C++.","metadata":{},"id":"4174bb53-027b-441d-aa60-8ef96e82ca5b"},{"cell_type":"markdown","source":"## 1. Introduction","metadata":{},"id":"5d7e9039-ef41-4082-adab-ec4c8af986a9"},{"cell_type":"markdown","source":"### 1.1. Types of Motion Planning Algorithms","metadata":{},"id":"7acbd64d-332d-422b-8077-0c3fee414d77"},{"cell_type":"markdown","source":"#### Background","metadata":{},"id":"9e9b7644-bc84-4cc3-957e-3505640fa50e"},{"cell_type":"markdown","source":"In this lesson, we cover the basics of [motion planning](https://en.wikipedia.org/wiki/Motion_planning) algorithms; here we move from behaviour selection to full trajectory generation. In order to produce not only trajectory curves but also the time-sequence at which a robot executes these curves, we employ a variety of motion planning algorithms and direct our attention towards the areas of safety, feasibility, comfort and efficiency while generating vehicle trajectories.","metadata":{},"id":"809fe6e1-09b4-4efe-a625-0a5960d5b1db"},{"cell_type":"markdown","source":"#### Properties and problem set-up","metadata":{},"id":"8591a786-3b51-457a-85f7-274b949cb452"},{"cell_type":"markdown","source":"Several important properties of motion planning algorithms are _completeness_ and _optimality_. The _completness_ assumption asserts that if a solution exists, the motion planner is guaranteed to always find the solution. In scenarios where no solution exists, the algorithm will correctly report so.  The _optimality_ assumption asserts that, for a given cost function evaluating sequences of actions, the motion planner is guaranteed to always return a feasible (i.e., executable) sequence of actions with minimal cost. Several other assumptions exist for specific algorithms, namely the resolution completeness and probabilistic completeness in the case of sampling-based planning algorithms.  \n\nIn order to enforce these constraints, we need a well-defined problem — the [_configuration space_](https://en.wikipedia.org/wiki/Configuration_space_\\(physics\\)) defines all possible configurations a robot can make in the world coordinate frame. In a 2D environment, this corresponds to each and every position $\\left[x, y\\right]$. In 3D, we extend the 2D position to include an orientation angle $\\left[x, y, \\theta\\right]$. We must also define a _start_ and _goal configuration_; the start configuration $q_{\\mathrm{start}}$ is usually initialised from a localisation algorithm using sensor data, whereas the goal configuration $q_{\\mathrm{goal}}$ is selected w.r.t. the behaviour planner defining where to move and at which speed. In practise, motion planning problem definitions usually consider additional constraints, such as the sequence of actions predicted for non-vehicles and pedestrians, which can be obtained via map and traffic data as well as kinematic / physics-based models.","metadata":{},"id":"db882d6a-d7a8-427a-bd54-5f2bec85fdc0"},{"cell_type":"markdown","source":"#### Types of motion planning algorithms","metadata":{},"id":"9ce93a17-308d-4a64-aae1-591de982966a"},{"cell_type":"markdown","source":"Several well-known types motion planning algorithms are as follows:\n* [Combinatorial methods](http://msl.cs.uiuc.edu/planning/ch6.pdf): combinatorial approaches to motion planning find paths through the continuous configuration space without resorting to approximations — for special classes such as 2D robot planning, combinatorial methods provide _complete_, efficient, approximation-independent solutions over sampling-based planning methods [1];\n    * Relies on a _roadmap_ assumption through cell decomposition (i.e., partitioning the search space into cells) and several properties regarding accessibility and connectivity of the discrete graph search sapce; \n* [Artificial potential fields](https://en.wikipedia.org/wiki/Motion_planning#Artificial_potential_fields): this type of reactive method defines obstacles as electrostatic point charges which generate potential fields — the robot navigates the anti-gravity field around e.g., pedestrians, bicyclists, using a [navigation function](https://en.wikipedia.org/wiki/Navigation_function).\n    * A disadvantage with this class of algorithms (aside from harmonic potential field-based implementations) is their sensitivity to local minima, which might prevent the planner from arriving at the intended goal state;\n* [Optimal control](https://en.wikipedia.org/wiki/Optimal_control): a set of methods for [trajectory optimisation](https://en.wikipedia.org/wiki/Trajectory_optimization) using either [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming) and principle of optimality assumption (in closed-loop), or [calculus of variations](https://en.wikipedia.org/wiki/Calculus_of_variations) (in open-loop);\n    * Solves both the motion planning and control input generation problems in one approach using dynamic vehicle model with a start- and end configuration;\n    * Here a sequence of control inputs (e.g., steering angle, throttle) are generated and optimised with a cost function relative to the configuration of the vehicle (e.g., maximising efficiency, maintaining safe distance to obstacles);\n    * Optimal control relies on numerical approximation methods, or [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning)-based approaches for closed-loop control;\n* [Sampling-based methods](https://en.wikipedia.org/wiki/Motion_planning#Sampling-based_algorithms): unlike combinatorial approaches, these set of algorithms have a runtime that is not explicitly exponentially dependent on the dimensionality of the configuration space $C$ — sampling-based algorithms construct roadmaps using a less-elegant collision dectection test which is _probabilistically complete_. In other words, the probability of a solution approaches $1.0$ as the free search space is exahusted;\n    * For a cell decomposition / discretisation approach, [graph-based search](https://en.wikipedia.org/wiki/Graph_traversal) algorithms (e.g., [A*](https://en.wikipedia.org/wiki/A*_search_algorithm), [Dijkstra's](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm), [D* / D* Lite](https://en.wikipedia.org/wiki/D*), [ARA*](https://en.wikipedia.org/wiki/Anytime_A*), etc.);\n    * For probabilistc methods, i.e., random exploration of configuration and input space, [probabilistic data structures](https://en.wikipedia.org/wiki/Category:Probabilistic_data_structures) are used (e.g., [RRT / RRT*](https://en.wikipedia.org/wiki/Rapidly-exploring_random_tree#Variants), [PRM](https://en.wikipedia.org/wiki/Probabilistic_roadmap), etc.).","metadata":{},"id":"8d101462-8436-4c07-86ed-80868ed645a1"},{"cell_type":"markdown","source":"### 1.2. Hybrid A*","metadata":{},"id":"f3ee88b1-ed5a-4d42-90b6-1f6a248c4508"},{"cell_type":"markdown","source":"#### Background","metadata":{},"id":"08e3b786-38a5-4cde-8b41-deb67b7c8b6c"},{"cell_type":"markdown","source":"Hybrid A* (also known as Hybrid-State A* Search [2]), is a path-planning algorithm adapting the well-known [A* search](https://en.wikipedia.org/wiki/A*_search_algorithm) to 3D kinematic state space of the vehicle. The Hybrid A* search algorithm uses a modified state-update rule to capture the continuous state of the vehicle in the discretised map space (represented as nodes in the A* graph). This guarantees kinematic feasability of the generated trajectory. In other words, Hybrid A* finds a path that a vehicle can actually manoeuvre (e.g., smooth curve-based trajectories) which is favoured by vehicle motion models such as the [kinematic bicycle](https://thomasfermi.github.io/Algorithms-for-Automated-Driving/Control/BicycleModel.html).","metadata":{},"id":"22fd8de2-b7d5-4260-beff-f9de2e18f3f4"},{"cell_type":"markdown","source":"#### Applications in path planning","metadata":{},"id":"2f73a25a-1b65-4384-8c16-5394ff457792"},{"cell_type":"markdown","source":"Unlike the standard A* algorithm, the Hybrid A* is *not* guaranteed to find an minimal-cost solution. It is not _complete_, meaning it does not always find a solution when one exists. Aside from this, Hybrid A* has been implemented in Stanford's _Junior_ [3], the [2007 DARPA Grand Challenge](https://en.wikipedia.org/wiki/DARPA_Grand_Challenge_\\(2007\\)) 2nd Place winner, to perform free-form navigation in abritrary environments (e.g., parking lots). In order to perform trajectory planning, the Hybrid A* algorithm explores / expands discrete states using continuous vehicle coordinates $<x, y, \\theta>$. A prediction $<x^{\\prime}, y^{\\prime}, \\theta^{\\prime}>$ is made with respect to the vehicle heading, and the path selected by Hybrid A* is guided by two additional heuristics: _non-holonomic-without-obstacles_, and the _holonomic-with-obstacles_. In addition to the runtime-, behaviour-, manoeuvre execution- and obstacle distance-based costs of the standard A* search, the Stanford Junior team used these two differential constraints to account for the non-holonomic nature of the ego-vehicle w.r.t. its location, orientation and direction of motion. This heuristic aided Junior in approaching the goal state with the desired heading. The second differential motion heuristic, _holonomic-with-obstacles_, ignores the non-holonomic nature of the vehicle and emphasizes the shortest distance to the goal. This second heuristic is computed online via a dynamic programming algorithm in 2D, whereas the first heuristic is computed entirely offline for the entire 4D space (vehicle location, orientation, and direction of motion). The _non-holonomic-without-obstacles_ heuristic is said to be significantly more efficient than Euclidean distance as it takes into account vehicle orientation, however, this heuristic alone fails to produce executable trajectories in situations with U-shaped dead ends. The addition of the _holonomic-with-obstacles_ heuristic attempts to address this by discovering these obstacles and dead-ends in 2D, which is used to guide the more-expensive 3D search away from these areas [2].\n\nThe Hybrid A* search uses analytic expansions based on the [Reed-Shepp model](http://lavalle.pl/planning/node822.html). This addresses the precision issue resulting from the discretisation of the vehicle control action space. The effect of steering angle discretisation on precision means that the grid resolution must be carefully selected such that a decent approximation of the exact continuous-coordinate goal state can be reached. A node in the tree is expanded by simulating a kinematic model of the car for a given control action over the time-step equal to the resolution of the grid. Then, for some nodes, the optimal Reed-Shepp path is computed from the current- to goal-state (assuming no obstacle-free environment). By selectively applying the Reed-Shepp expansion, this extension of the search tree yields signficant benefits in both planning time and accuracy [2]. Several other path-cost ([Voronoi Field](https://en.wikipedia.org/wiki/Voronoi_diagram#Engineering)) and local optimisation / smoothing functions are applied to the final path planner used in the Stanford _Junior_. ","metadata":{},"id":"561c093a-2a93-4899-895c-74d139b6b2dd"},{"cell_type":"markdown","source":"#### Implementation in Python","metadata":{},"id":"50d0f61e-d9d8-4b42-98bf-d89526ba32d1"},{"cell_type":"markdown","source":"The Python implementation below outlines the [A* search]() algorithm using the [kinematic bicycle motion] model (i.e., the hybrid A* algorithm). The following variables and objects are used:\n* `State(x, y, theta, g, f)`: An object which stores the `x`, `y`, position coordinates, heading angle `theta` (direction) and the current A* `g` and `f` values;\n* `grid`: A binary-valued 2D array — here a value \"1\" indicates the presence of an obstacle, wheras a \"0\" corresponds to free (navigable) space;\n* `SPEED`: The speed of the vehicle used in the bicycle motion model;\n* `LENGTH`: The length of the vehicle used in the bicycle motion model;\n* `NUM_THETA_CELLS`: The number of cells to divide a circle into — used to keep track of which states have already been visited. \n\nThe bulk of the hybrid A* algorithm is defined within the `search` function. The `expand` function takes a `State` instance and a `goal` (not implemented below), and returns a list of possible next-states for a range of steering angles. This function contains the implementation of the bicycle motion model and the A* heuristic function.","metadata":{},"id":"151eadfd-a286-47b7-a33d-f973a3724787"},{"cell_type":"markdown","source":"```python\ndef expand(\n        state, \n        goal\n):\n    \"\"\"Selects a trajectory using the bicycle motion model and heuristic function.\n    \n    :param state: Current position (`x`, `y`), orientation `theta` and heuristic `g`, `f` values.\n    :param goal: Coordinates of the goal location. TODO.\n    \"\"\"\n    \n    next_states = []\n    # Span the next-state space given by the vehicle heading (direction)\n    for delta in range(-35, 40, 5):\n        ### Begin the bicycle motion model\n        delta_rad = deg_to_rad(delta)\n        omega = SPEED / LENGTH * tan(delta_rad)\n        next_x = state.x + SPEED * cos(theta)\n        next_y = state.y + SPEED * sin(theta)\n        next_theta = normalize(state.theta + omega)\n        ### Compute the heuristic evaluation\n        next_g += 1\n        next_f += heuristic(next_x, next_y, goal)\n        ### Create a next-state object\n        state = State(next_x, next_y, next_theta, next_g, next_f)\n        next_states.append(state)\n    return next_states\n    \ndef search(\n        grid, \n        start, \n        goal\n):\n    \"\"\"Performs the A* search with closing and opening / expansion of next-states.\n    \n    The vehicle heading (theta) search space is discretised, i.e., the heading\n    interval [0, +/- 2*pi] is partitioned into `NUM_THETA_CELLS` such that the\n    lower discretised `theta` values are assigned lower stack numbers, whereas\n    the `higher` theta values closer to 2*pi are assigned to larger stack numbers.\n    \n    In order to perform A* search, we sort the remaining states in `states_opened`\n    by lowest f-value; this is crucial to A* as the lowest f-value state indicates\n    an efficient starting point for the search.\n    \n    :param grid: 2D discretised map of cells. TODO.\n    :param start: State object to start the search from (i.e., 2D position and heading).\n    :param goal: Coordinates of the goal location. TODO.\n    \"\"\"\n    \n    # Store the `State` instances to explore\n    states_opened = []\n    # Initialise the 3D map from the 2D grid and discretised heading angle\n    states_closed = [\n        [[0 for x in range(grid[0])] for y in range(len(grid))]\n            for cell in range(NUM_THETA_CELLS)\n    ]\n    # Store the previous visited `State` instances\n    states_came_from = [\n        [[0 for x in range(grid[0])] for y in range(len(grid))]\n        for cell in range(NUM_THETA_CELLS)\n    ]\n    # Create a new starting `State`\n    x = start.x\n    y = start.y\n    theta = start.theta\n    g = 0\n    f = heuristic(start.x, start.y, goal)\n    state = State(x, y, theta, g, f)\n    states_opened.append(state)\n    ### Discretising the theta search space\n    stack_num = theta_to_stack_number(state.theta)\n    states_closed[stack_num][idx(state.x)][idx(state.y)] = state\n    ### Explore the remaining states in `states_opened`\n    while states_opened:\n        # First sort states by lowest f-value in order to start the search\n        # Then, get the state with the lowest f-value\n        states_opened.sort(key=lambda state: state.f)\n        current = states_opened.pop(0)\n        # Check if the goal has been reached\n        if (\n            (idx(current.x) == goal.x)\n            and (idx(current.y) == goal.y)\n        ):\n            return path\n       # Get the set of next-possible states\n       next_states = expand(current, goal)\n       for next_s in next_states:\n           if not in_grid(next_s):\n               # Skip any states not in grid dimensions\n               continue\n           # Check that this state has not previously been visited\n           # and that no obstacle exists at this location\n           stack_num = theta_to_stack_number(next_s.theta)\n           if (\n               (not states_closed[stack_num][idx(next_s.x)][idx(next_s.y)])\n               and (idx(current.y) == goal.y)\n           ):\n               # Add the valid state to the explored states stack\n               states_oppened.append(next_s)\n               # Close the visited `State` tuple\n               states_closed[stack_num][idx(next_s.x)][idx(next_s.y)] = 1\n               # Add the visited state to the trajectory history\n               states_came_from[stack_num][idx(next_s.x)][idx(next_s.y)] = current\n ```    ","metadata":{},"id":"015c5326-8331-462b-b6df-afaa38f8a80e"},{"cell_type":"markdown","source":"In the above Python code we have a near-complete implementation of the hybrid A* search, but note that the following functions are assumed to have been implemented outside of the provided code:\n* `deg_to_rad`: Returns the heading angle converted from degrees to radians;\n* `normalize()`: Returns the normalised vehicle heading (plus a shift amount `omega`);\n* `in_grid`: Returns the boolean indicating whether the given state is within the dimensions of the discretised map;\n* `index()`: Returns the corresponding index of the position coordinate in the grid space;\n* `theta_to_stack_number()`: Returns the corresponding discretised theta angle from range [0, 2*pi] to stack space;\n* `heuristic`: Computes the heuristic value of the evaluated state position relative to the goal state.\n\nWith the variables defined above the Python code-block, we have a complete definition of the hybrid A* search that we can use in Sect. 2.1. to implement in C++ code. ","metadata":{},"id":"6ab4e123-271f-46ab-b06b-d2587c296fe8"},{"cell_type":"markdown","source":"### 1.3. Polynomial Trajectory Generation","metadata":{},"id":"4c75a00a"},{"cell_type":"markdown","source":"#### Background","metadata":{},"id":"a5f0b60c"},{"cell_type":"markdown","source":"In order to design vehicle trajectories that are both comfortable and feasible, we use [polynomial](https://en.wikipedia.org/wiki/Polynomial) curves. These curves allow the vehicle to comfortably accelerate to a desired speed without introducing significant [jerk](https://en.wikipedia.org/wiki/Jerk_\\(physics\\)), which otherwise would result in an unpleasant and potentially dangerous driving experience.","metadata":{},"id":"bc7a3f30"},{"cell_type":"markdown","source":"#### Jerk-Minimising Trajectories","metadata":{"vscode":{"languageId":"plaintext"}},"id":"279101c2-2a6d-4156-a719-68cbfb44db3f"},{"cell_type":"markdown","source":"To design minimised jerk polynomial trajectories, we first make several assumptions about the environment and the coordinate systems used to describe vehicle displacement.\n\nFirst, we assume that the environment the ego-vehicle operates in is _structured_ — i.e., driving lanes, speed limits, controlled intersections, etc. form structure in the driving environment and provide the trajectory planner with useful information a priori. This differs from the unstructured environment — parking lots, for example, where pre-defined rules regarding how to move (e.g., direction of traffic flow, lane boundaries, speed limits) about are not always available or adhered to by others.\n\nNext, we move from the 2D Cartesian coordinate system to the [Frenet](https://fjp.at/posts/optimal-frenet/) coordinate system to describe vehicle position and movement in a more intuitive way. Movement along an arbitrary road surface is described in two dimensions: $d$-axis for side-to-side lateral movements and $s$-axis for longitudinal back-and-forth movements. If we let the centre of a given lane be the origin of our Frenet reference frame, we can represent curvy roads as straight paths. Any ego-vehicle offset in either the $d$- or $s$-axis will be relative to the refererence path followed by the ego-vehicle, and not just the absolute position in 2D Cartesian space. Therefore, we can more easily discern intended vehicle trajectories and design vehicle trajectories independent of the curvature of the road (assuming that a rough estimate of the road curvature is known a priori).\n\nUsing the individual components of the Frenet coordinate frame — the longitudinal and lateral axes — we separate the vehicle trajectories in either axis in order to execute them in a dynamic world reference frame. To create a trajectory, we define both a _start_ and _goal_ state in three dimensions: $s$, $d$ and $t$. The start (initial) state in the lateral direction is denoted $d_{i}$, while the goal (final) state is denoted $d_{f}$. The same applies for the longitudinal direction $s_{i}$, $s_{f}$, respectively. With this, we form our _boundary conditions_, the initial and final states described in the lateral and longitudinal directions. Here we use the three quantities _position_, _velocity_ and _acceleration_ to represent the boundary conditions / constraints, i.e., \n* $s_{i}, d_{i}$: Initial position in the longitudinal and lateral directions;\n* $\\dot{s}_{i}, \\dot{d}_{i}$: Initial velocity in the longitudinal and lateral directions;\n* $\\ddot{s}_{i}, \\ddot{d}_{i}$: Initial acceleration in the longitudinal and lateral directions;\n* $s_{f}, d_{f}$: Final position in the longitudinal and lateral directions;\n* $\\dot{s}_{f}, \\dot{d}_{f}$: Final velocity in the longitudinal and lateral directions;\n* $\\ddot{s}_{f}, \\ddot{d}_{f}$: Final acceleration in the longitudinal and lateral directions.\n\nWith the above boundary conditions, we compute the minimum jerk trajectory with the above as coefficients of the expanded polynomial for the total jerk $d^3{s}/d^{3}t$, such that position $s(t) \\in \\left[0, t_{f}\\right]$. From the total squared jerk equation,\n$$\n\\begin{align}\n\\int_{0}^{t_{f}} \\dddot{s} dt\n\\end{align}\n$$\n\nWe form the polynomial of $s(t) = \\alpha_{0} + \\alpha_{1}t + \\alpha_{2}t^{2} + \\ldots + \\alpha_{n}t^{n} + \\ldots$ as the sum:\n\n$$\n\\begin{align}\ns(t) = \\sum_{n=0}^{\\infty} \\alpha_{n}t^{n}\n\\end{align}\n$$\n\nand incorporating the realisation $d^{m}s/dt^{m} = 0, \\forall m \\geq 6$, we have the following expression for the minimum 1D jerk trajectory:\n$$\n\\begin{align}\ns(t) = \\alpha_{0} + \\alpha_{1}t + \\alpha_{2}t^{2} + \\alpha_{3}t^{3} + \\alpha_{4}t^{4} + \\alpha_{5}t^{5}\n\\end{align}\n$$\n\nwith coefficients:\n$$\n\\begin{align}\n[s_{i}, \\dot{s}_{i}, \\ddot{s}_{i}, s_{f}, \\dot{s}_{f}, \\ddot{s}_{f}], \\quad\n[d_{i}, \\dot{d}_{i}, \\ddot{d}_{i}, d_{f}, \\dot{d}_{f}, \\ddot{d}_{f}].\n\\end{align}\n$$\n\nIn the 1D case, we might make the assumption that the initial and final velocities of a trajectory are zero. For example, a lane change from initial state $s_{i} = d_{i} = 0$ to final state $s_{f} = 30, d_{f} = 10$ can result in a coefficient vector with only one non-zero value, the lateral displacement $s_{f} = 10$.","metadata":{},"id":"bc72ebd0"},{"cell_type":"markdown","source":"#### Deriving Polynomial Coefficients","metadata":{},"id":"bb02e46f"},{"cell_type":"markdown","source":"Starting with our quintic polynomial,\n$$\n\\begin{align}\ns(t) = \\alpha_{0} + \\alpha_{1}t + \\alpha_{2}t^{2} + \\alpha_{3}t^{3} + \\alpha_{4}t^{4} + \\alpha_{5}t^{5}\n\\end{align}\n$$\n\nwe take the first and second derivatives to get the equations with respect to velocity and acceleration:\n$$\n\\begin{align}\n\\dot{s}(t) &= \\alpha_{1} + 2\\alpha_{2}t + 3\\alpha_{3}t^{2} + 4\\alpha_{4}t^{3} + 5\\alpha_{5}t^{4}, \\\\\n\\ddot{s}(t) &= 2\\alpha_{2} + 6\\alpha_{3}t + 12\\alpha_{4}t^{2} + 20\\alpha_{5}t^{3}. \\\\\n\\end{align}\n$$\n\nThen, we set the initial time to zero, i.e., $t_{i} = 0$, and reduce the six unknowns into three. This results in:\n$$\n\\begin{align}\ns_{i} &= s(0) = \\alpha_{0}, \\\\\n\\dot{s}_{i} &= \\dot{s}(0) = \\alpha_{1}, \\\\\n\\ddot{s}_{i} &= \\ddot{s}(0) = 2\\alpha_{2}. \\\\\n\\end{align}\n$$\n\nGathering the unknowns into functions of the start boundary conditions, and assuming the constants $C_{i}$ from the original equations, we have:\n$$\n\\begin{align}\ns(t_{f}) &= s_{f} = \\alpha_{3}t^{3}_{f} + \\alpha_{4}t^{4}_{f} + \\alpha_{5}t^{5}_{f} &+ C_{1}, \\\\\n\\dot{s}(t_{f}) &= \\dot{s}_{f} = 3\\alpha_{3}t^{2}_{f} + 4\\alpha_{4}t^{3}_{f} + 5\\alpha_{5}t^{4}_{f} &+ C_{2}, \\\\ \n\\ddot{s}(t_{f}) &= \\ddot{s}_{f} = 6\\alpha_{3}t_{f} + 12\\alpha_{4}t^{2}_{f} + 20\\alpha_{5}t^{3}_{f} &+ C_{3}.\n\\end{align}\n$$\n\nGiven that we know the final state values $\\left[s_{f}, \\dot{s}_{f}, \\ddot{s}_{f}, t_{f}\\right]$, we form the system of three equations as a matrix equation $A\\mathrm{x} = b$:\n$$\n\\begin{align}\n\\begin{bmatrix}\n    t^{3}_{f} & t^{4}_{f} & t^{5}_{f} \\\\\n    3t^{2}_{f} & 4t^{3}_{f} & 5t^{4}_{f} \\\\\n    6t_{f} & 12t^{2}_{f} & 20t^{3}_{f} \\\\\n\\end{bmatrix} \\times \n    \\begin{bmatrix} \\alpha_{3} \\\\ \\alpha_{4} \\\\ \\alpha_{5} \\end{bmatrix}\n    = \\begin{bmatrix} s_{f} \\\\ \\dot{s}_{f} \\\\ \\ddot{s}_{f} \\end{bmatrix}\n        \\begin{matrix} -C_{1} \\\\ -C_{2} \\\\ -C_{3}\\end{matrix}\n\\end{align}\n$$","metadata":{},"id":"8d1af579"},{"cell_type":"markdown","source":"This matrix equation allows us to solve for the minimum jerk trajectory coefficients needed to design the polynomial trajectories along both the $s$- and $d$-axis. Using a polynomial solver, we can obtain these coefficients for the longitudinal and lateral trajectories.","metadata":{},"id":"de61141a"},{"cell_type":"markdown","source":"## 2. Programming Task","metadata":{},"id":"805705e8-437c-4755-8edf-2f9ebe1cb993"},{"cell_type":"code","source":"#include \"4-2-Trajectory-Generation.h\"","metadata":{"trusted":true},"execution_count":1,"outputs":[],"id":"4c158f5d-315f-4aa4-b02c-04dc5a2c8130"},{"cell_type":"markdown","source":"### 2.1. Hybrid A* in C++","metadata":{},"id":"342d3cc0-8087-4ef2-bf21-7543cf5f50f0"},{"cell_type":"code","source":"// From J. Moran's `2_tests.cc`","metadata":{"trusted":true},"execution_count":2,"outputs":[],"id":"f9688824-1dc1-446b-8a8c-68cad694cb57"},{"cell_type":"code","source":"#include \"4-2-Trajectory-Generation/1_hybrid_breadth_first.h\"","metadata":{"trusted":true},"execution_count":3,"outputs":[],"id":"2d8e4de8-4320-4aaf-8fc2-10446de04eda"},{"cell_type":"code","source":"/* Tests the Hybrid A* algorithm implemented with breadth-first search.\n * \n * Here the 2D grid environment is defined along with a 3D starting pose and\n * a 2D goal position. The Hybrid A* search finds the shortest path by\n * minimising the Manhattan distance cost from the current expansion node to\n * the goal position.\n * \n * CANDO: Modify the maze environment (obstaces / free-space) or use different\n * cost / heuristic functions (e.g., holonomic-with-obstacles, Dolgov 2008).\n *\n */\nvoid test_hybrid_breadth_first() {\n  // Initialising the maze grid\n  int X = 1;\n  int _ = 0;\n  // CANDO: Modify the grid maze to test different expansions.\n  std::vector<std::vector<int>> GRID = {\n    {_,X,X,_,_,_,_,_,_,_,X,X,_,_,_,_,},\n    {_,X,X,_,_,_,_,_,_,X,X,_,_,_,_,_,},\n    {_,X,X,_,_,_,_,_,X,X,_,_,_,_,_,_,},\n    {_,X,X,_,_,_,_,X,X,_,_,_,X,X,X,_,},\n    {_,X,X,_,_,_,X,X,_,_,_,X,X,X,_,_,},\n    {_,X,X,_,_,X,X,_,_,_,X,X,X,_,_,_,},\n    {_,X,X,_,X,X,_,_,_,X,X,X,_,_,_,_,},\n    {_,X,X,X,X,_,_,_,X,X,X,_,_,_,_,_,},\n    {_,X,X,X,_,_,_,X,X,X,_,_,_,_,_,_,},\n    {_,X,X,_,_,_,X,X,X,_,_,X,X,X,X,X,},\n    {_,X,_,_,_,X,X,X,_,_,X,X,X,X,X,X,},\n    {_,_,_,_,X,X,X,_,_,X,X,X,X,X,X,X,},\n    {_,_,_,X,X,X,_,_,X,X,X,X,X,X,X,X,},\n    {_,_,X,X,X,_,_,X,X,X,X,X,X,X,X,X,},\n    {_,X,X,X,_,_,_,_,_,_,_,_,_,_,_,_,},\n    {X,X,X,_,_,_,_,_,_,_,_,_,_,_,_,_,}\n  };\n  std::vector<double> START = {0.0, 0.0, 0.0};\n  std::vector<int> GOAL = {\n    (int)GRID.size() - 1, \n    (int)GRID[0].size() - 1\n  };\n  std::cout << \"Finding path through grid:\" << \"\\n\";\n  // Creates an empty maze to test number of expansions\n  for (int i = 0; i < GRID.size(); ++i) {\n    std::cout << GRID[i][0];\n    for (int j = 1; j < GRID[0].size(); ++j) {\n      std::cout << \",\" << GRID[i][j];\n    }\n    std::cout << \"\\n\";\n  }\n  HBF hbf = HBF();\n  HBF::maze_path get_path = hbf.search(\n    GRID,\n    START,\n    GOAL\n  );\n  std::vector<HBF::maze_s> show_path = hbf.reconstruct_path(\n    get_path.states_came_from, \n    START, \n    get_path.final\n  );\n  std::cout << \"Show path from start to finish\" << \"\\n\";\n  for (int i = show_path.size()-1; i >= 0; --i) {\n      HBF::maze_s step = show_path[i];\n      std::cout << \"##### step \" << step.g << \" #####\" << \"\\n\";\n      std::cout << \"x \" << step.x << \"\\n\";\n      std::cout << \"y \" << step.y << \"\\n\";\n      std::cout << \"theta \" << step.theta << \"\\n\";\n  }\n}","metadata":{"trusted":true},"execution_count":4,"outputs":[],"id":"e983fb64-56e5-4ed3-9277-59194f35c218"},{"cell_type":"markdown","source":"#### Testing the Hybrid A* with BFS","metadata":{},"id":"00f36f70-cb4d-4da1-bf25-cb2b22fbfc57"},{"cell_type":"code","source":"// From J. Moran's `2_tests.cc`","metadata":{"trusted":true},"execution_count":5,"outputs":[],"id":"20516f3d-e634-4330-a322-c111b1c72599"},{"cell_type":"code","source":"test_hybrid_breadth_first()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Finding path through grid:\n0,1,1,0,0,0,0,0,0,0,1,1,0,0,0,0\n0,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0\n0,1,1,0,0,0,0,0,1,1,0,0,0,0,0,0\n0,1,1,0,0,0,0,1,1,0,0,0,1,1,1,0\n0,1,1,0,0,0,1,1,0,0,0,1,1,1,0,0\n0,1,1,0,0,1,1,0,0,0,1,1,1,0,0,0\n0,1,1,0,1,1,0,0,0,1,1,1,0,0,0,0\n0,1,1,1,1,0,0,0,1,1,1,0,0,0,0,0\n0,1,1,1,0,0,0,1,1,1,0,0,0,0,0,0\n0,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1\n0,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1\n0,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1\n0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1\n0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0\n1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0\nFound path to goal in 9526 expansions\nShow path from start to finish\n##### step 1 #####\nx 1.45\ny 0\ntheta 0\n##### step 2 #####\nx 2.9\ny 0\ntheta 0\n##### step 3 #####\nx 4.35\ny 0\ntheta 0.511348\n##### step 4 #####\nx 5.61452\ny 0.709563\ntheta 6.01748\n##### step 5 #####\nx 7.01364\ny 0.328808\ntheta 6.52883\n##### step 6 #####\nx 8.42011\ny 0.681421\ntheta 6.27511\n##### step 7 #####\nx 9.87007\ny 0.669715\ntheta 7.6274\n##### step 8 #####\nx 10.1958\ny 2.08265\ntheta 7.37369\n##### step 9 #####\nx 10.8658\ny 3.3686\ntheta 8.72598\n##### step 10 #####\nx 9.75561\ny 4.30138\ntheta 8.21463\n##### step 11 #####\nx 9.24394\ny 5.6581\ntheta 8.72598\n##### step 12 #####\nx 8.13379\ny 6.59088\ntheta 8.21463\n##### step 13 #####\nx 7.62211\ny 7.9476\ntheta 9.27014\n##### step 14 #####\nx 6.18942\ny 8.17093\ntheta 8.7588\n##### step 15 #####\nx 5.04927\ny 9.06678\ntheta 7.98174\n##### step 16 #####\nx 4.86451\ny 10.505\ntheta 8.49309\n##### step 17 #####\nx 3.99962\ny 11.6688\ntheta 8.74681\n##### step 18 #####\nx 2.87029\ny 12.5782\ntheta 7.96976\n##### step 19 #####\nx 2.70279\ny 14.0185\ntheta 6.61746\n##### step 20 #####\nx 4.07252\ny 14.4943\ntheta 6.36375\n##### step 21 #####\nx 5.51782\ny 14.6109\ntheta 6.11003\n##### step 22 #####\nx 6.94614\ny 14.3611\ntheta 5.33298\n##### step 23 #####\nx 7.78933\ny 13.1815\ntheta 5.07926\n##### step 24 #####\nx 8.30944\ny 11.828\ntheta 5.33298\n##### step 25 #####\nx 9.15264\ny 10.6484\ntheta 5.58669\n##### step 26 #####\nx 10.2649\ny 9.71814\ntheta 5.58669\n##### step 27 #####\nx 11.3772\ny 8.78792\ntheta 5.33298\n##### step 28 #####\nx 12.2204\ny 7.60829\ntheta 5.84433\n##### step 29 #####\nx 13.533\ny 6.99217\ntheta 6.62138\n##### step 30 #####\nx 14.9009\ny 7.47326\ntheta 7.97367\n##### step 31 #####\nx 14.7277\ny 8.91289\ntheta 7.46232\n##### step 32 #####\nx 15.2812\ny 10.2531\ntheta 7.71604\n##### step 33 #####\nx 15.4806\ny 11.6893\ntheta 7.71604\n##### step 34 #####\nx 15.68\ny 13.1255\ntheta 8.77155\n##### step 35 #####\nx 14.5285\ny 14.0068\ntheta 7.41926\n##### step 36 #####\nx 15.1392\ny 15.3219\ntheta 5.74495\n","output_type":"stream"}],"id":"3cf0210d-5e28-46bb-b610-9d8871b2d36f"},{"cell_type":"markdown","source":"### 2.2. Quintic Polynomial Solver in C++","metadata":{},"id":"0842774d"},{"cell_type":"markdown","source":"In this exercise we solve the matrix equation from Sect. 1.2. using C++. Recall the matrix equation of the form $A\\mathrm{x} = b$:\n$$\n\\begin{align}\n\\begin{bmatrix}\n    t^{3}_{f} & t^{4}_{f} & t^{5}_{f} \\\\\n    3t^{2}_{f} & 4t^{3}_{f} & 5t^{4}_{f} \\\\\n    6t_{f} & 12t^{2}_{f} & 20t^{3}_{f} \\\\\n\\end{bmatrix} \\times \n    \\begin{bmatrix} \\alpha_{3} \\\\ \\alpha_{4} \\\\ \\alpha_{5} \\end{bmatrix}\n    = \\begin{bmatrix}\n        s_{f} - \\left(s_{i} + \\dot{s}_{i})t + \\frac{1}{2}\\ddot{s}_{i}t^{2}\\right) \\\\ \n        \\dot{s}_{f} - \\left(\\dot{s}_{i} + \\ddot{s}_{i}t\\right) \\\\ \n        \\ddot{s}_{f} - \\ddot{s}_{i} \\end{bmatrix}\n\\end{align}\n$$\n\nfor the 1D kinematic equations evaluated at $t = 0$. This yields the first set of knowns $\\left[\\alpha_{0}, \\alpha_{1}, \\alpha_{2}\\right] = \\left[s_{i}, \\dot{s}_{i}, \\frac{1}{2}\\ddot{s}_{i}\\right]$. The last three coefficients $\\left[\\alpha_{3}, \\alpha_{4}, \\alpha_{5}\\right]$ in the matrix equation above can be solved by evaluating the 1D kinematic equations for $t = t_{f}$, as carried out in the above.\n\nIn order to solve this quintic polynomial, we use the [Eigen](https://en.wikipedia.org/wiki/Eigen_(C%2B%2B_library)) C++ linear algebra library. To solve the system of the form $A\\mathrm{x} = b$, we multiply the vector $b$ by the matrix inverse of $A$ (assuming it exists). Knowing that the first three coefficients are given as $\\left[\\alpha_{0}, \\alpha_{1}, \\alpha_{2}\\right] = \\left[s_{i}, \\dot{s}_{i}, \\frac{1}{2}\\ddot{s}_{i}\\right]$, we compute the last three unknowns $\\left[\\alpha_{3}, \\alpha_{4}, \\alpha_{5}\\right]$ with the relation:\n$$\n\\begin{align}\n\\mathrm{x} &= A^{-1}b.\n\\end{align}\n$$","metadata":{},"id":"48814f81"},{"cell_type":"code","source":"// From J. Moran's `2_tests.cc`","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"execution_count":7,"outputs":[],"id":"5f205226"},{"cell_type":"code","source":"#include \"4-2-Trajectory-Generation/2_jerk_minimising_trajectory.h\"","metadata":{"trusted":true},"execution_count":8,"outputs":[],"id":"211cebbb-4ec0-45d1-9052-fd14c91c63a7"},{"cell_type":"code","source":"/* Tests the quintic polynomial solver using the test cases in `2_grader.h`.\n *\n * The `JMT` function in `2_jerk_minimising_trajectory.cc` returns the six\n * coefficient values corresponding to the quintic polynomial of the minimised\n * jerk trajectory. The matrix equation $Ax = b$ is solved using the inverse of\n * the matrix $A$ which is assumed to exist.\n * \n * This helper function tests the returned coefficient values against the\n * expected values up to a deviation amount `epsilon` defined in `2_grader.h`.\n */\nvoid test_jerk_minimising_trajectory() {\n  // Create the test cases\n  std::vector<test_case> tc = create_tests();\n  bool total_correct = true;\n  for (int i = 0; i < tc.size(); ++i) {\n    std::vector<double> jmt = JMT(\n        tc[i].start,\n        tc[i].end,\n        tc[i].T\n    );\n    bool correct = close_enough(jmt, answers[i]);\n    total_correct &= correct;\n  }\n  if (!total_correct) {\n    std::cout << \"Try again!\" << \"\\n\";\n  }\n  else {\n    std::cout << \"Nice work!\" << \"\\n\";\n  }\n}","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"execution_count":9,"outputs":[],"id":"43509068"},{"cell_type":"markdown","source":"#### Testing the Quintic Polynomial Solver in C++","metadata":{},"id":"3cc70b43"},{"cell_type":"code","source":"test_jerk_minimising_trajectory()","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Nice work!\n","output_type":"stream"}],"id":"b7376a03"},{"cell_type":"markdown","source":"## Credits","metadata":{},"id":"e2efaed4-d76f-451e-915c-0459990ca44f"},{"cell_type":"markdown","source":"This lesson has been prepared by Sebastian Thrun and Emmanuel Boidot, 2021 (link [here](https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)).\n\nReferences\n* [1] LaValle, S. M. Combinatorial Motion Planning. In: Planning Algorithms. Cambridge University Press. 2006. pp.206-256. [doi:10.1017/CBO9780511546877.008]().ISBN-13: 978-0521862059.\n* [2] Dolgov, D. et al. Practical Search Techniques in Path Planning for Autonomous Driving. Association for the Advancement of Artificial Intelligence. Pre-print. 2008. [https://www.aaai.org/Library/Workshops/2008/ws08-10-006.php](https://www.aaai.org/Papers/Workshops/2008/WS-08-10/WS08-10-006.pdf).\n* [3] Montemerlo, M. et al. Junior: The Stanford Entry in the Urban Challenge. Journal of Field Robotics. 2008. 25(9):569-597. [doi:10.1002/rob.20258](https://doi.org/10.1002/rob.20258).\n\nHelpful resources:\n* [Introduction to Optimal Control by Sumeet Singh | Princeton University ORF523 Lecture Notes](https://www.princeton.edu/~aaa/Public/Teaching/ORF523/ORF523_S21_Guest_Lecture.pdf)","metadata":{},"id":"30e049e6-eb91-4b5d-8b5e-fff9f4d483cc"}]}