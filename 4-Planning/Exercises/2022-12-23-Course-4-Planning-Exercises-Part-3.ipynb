{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6247af7",
   "metadata": {},
   "source": [
    "# Course 4: Planning\n",
    "## Part 3: Polynomial Trajectory Generation\n",
    "#### By Jonathan L. Moran (jonathan.moran107@gmail.com)\n",
    "From the Self-Driving Car Engineer Nanodegree programme offered at Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd7587",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6bb09",
   "metadata": {},
   "source": [
    "* Write a polynomial trajectory generator in Python;\n",
    "* Test the polynomial trajectory generator on two simulated vehicles;\n",
    "* Weight the provided cost functions appropriately so the behaviour of the test vehicle is ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ff366",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe67b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6b34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from typing import Callable, List, Tuple, TypedDict, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5673e6b",
   "metadata": {},
   "source": [
    "## 2. Programming Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1972e1",
   "metadata": {},
   "source": [
    "### 2.1. Polynomial Trajectory Generation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5dbdf1",
   "metadata": {},
   "source": [
    "#### Hyperparameters / constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2853bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20059b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10\n",
    "# Maximum speed limit (enforced for ego-vehicle)\n",
    "SPEED_LIMIT = 30\n",
    "# Radius of vehicle perimetre,\n",
    "# modelled as a circle to simplify collision detection \n",
    "VEHICLE_RADIUS = 1.5            # metres (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d102eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the ego-vehicle trajectory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6275565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitudinal distance kinematic state vector\n",
    "# i.e., $[s, \\dot{s}, \\ddot{s}]$\n",
    "SIGMA_S = [10.0, 4.0, 2.0]\n",
    "# Lateral distance kinematic state vector\n",
    "# i.e., $[d, \\dot{d}, \\ddot{d}]$\n",
    "SIGMA_D = [1.0, 1.0, 1.0]\n",
    "# Total elapsed time to complete manoeuvre\n",
    "SIGMA_T = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fa5119",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the vehicle kinematics (all actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bc2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum jerk and acceleration\n",
    "MAX_JERK = 10                   # m/s^3\n",
    "MAX_ACCEL = 10                  # m/s^2\n",
    "\n",
    "# Expected maximum jerk and acceleration allowed in one-second interval\n",
    "EXPECTED_JERK_IN_ONE_SEC = 2    # m/s^3\n",
    "EXPECTED_ACC_IN_ONE_SEC = 1     # m/s^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1daa87",
   "metadata": {},
   "source": [
    "#### `Vehicle` actor class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5609e",
   "metadata": {},
   "source": [
    "Below we define the `Vehicle` actor, i.e., a class with an assigned `start_state`. This `start_state` is a list of coefficients describing the vehicle boundary conditions at time $t = 0$. Therefore, `start_state` represents the following:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\texttt{start_state} = \\left[s, \\ \\dot{s}, \\ \\ddot{s}, \\ d, \\ \\dot{d}, \\ \\ddot{d}\\right].\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The member function `state_in` computes the kinematics state vector for the given time-step `t`, and returns the `state` corresponding to the 1D kinematics evaluated with respect to the starting boundary conditions.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46b8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From J. Moran's `helpers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45750804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle(object):\n",
    "    \"\"\"Defines the vehicle actor.\n",
    "    \n",
    "    Note: Non-ego vehicle move with constant acceleration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "            start: List[float]\n",
    "    ):\n",
    "        \"\"\"Initialises a `Vehicle` instance with `start` state.\n",
    "        \n",
    "        Here `state` is the starting kinematics state vector which has\n",
    "        the form: $[s, \\dot{s}, \\ddot{s}, d, \\dot{d}, \\ddot{d}]$.\n",
    "        \n",
    "        :param start: Vehicle starting kinematics state vector.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.start_state = start\n",
    "    \n",
    "    def state_in(self, \n",
    "            t: float\n",
    "    ) -> List[float]:\n",
    "        \"\"\"Returns the kinematics state vector for the given time-step.\n",
    "        \n",
    "        Here the returned `state` vector is the evaluated 1D kinematics\n",
    "        equations for longitudinal / lateral position along $s$- and $d$-axis\n",
    "        for the given time-step `t`.\n",
    "        \n",
    "        :param t: Time-step of the vehicle to evaluate kinematics w.r.t. \n",
    "        :return state: Kinematics state vector of the vehicle at time-step `t`.\n",
    "        \"\"\"\n",
    "        \n",
    "        s = self.start_state[:3]\n",
    "        d = self.start_state[3:]\n",
    "        state = [\n",
    "            s[0] + (s[1] * t) + s[2] * t**2 / 2.0,\n",
    "            s[1] + s[2] * t,\n",
    "            s[2],\n",
    "            d[0] + (d[1] * t) + d[2] * t**2 / 2.0,\n",
    "            d[1] + d[2] * t,\n",
    "            d[2],\n",
    "        ]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ad9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For typing hints\n",
    "Vehicles = TypedDict('Vehicles', v_id = int, vehicle = Vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82ad90",
   "metadata": {},
   "source": [
    "Note that in the cost functions below, `traj` is the single trajectory to evaluate the cost with respect to. Each `traj` is a `tuple` with three elements: the list of coefficients of the quintic polynomial describing $s(t)$ — the longitudinal motion of the trajectory, the list of coefficients of the quintic polynomial describing $d(t)$ — the lateral motion of the trajectory, and a `float` describing the total elapsed time (in seconds) the trajectory should be executed for in order to reach the goal state. This elapsed time is defined with respect to the assumed current time $t = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7f630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From J. Moran's `helpers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c57ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(\n",
    "        x: float\n",
    ") -> float:\n",
    "    \"\"\"Computes the sigmoid function.\n",
    "    \n",
    "    A function that returns a value between 0 and 1 for `x` in the \n",
    "    range [0, infinity] and -1 to 1 for x in the range [-infinity, infinity].\n",
    "\n",
    "    :param x: Value to evaluate the sigmoid function at.\n",
    "    :returns: Value computed by the sigmoid function.\n",
    "    \"\"\"\n",
    "    \n",
    "    return 2.0 / (1 + exp(-x)) - 1.0\n",
    "\n",
    "\n",
    "def to_equation(\n",
    "        coefficients: List[float]\n",
    ") -> Callable[[float], float]:\n",
    "    \"\"\"Returns a polynomial function with the given `coefficients`.\n",
    "    \n",
    "    :param coefficients: Set of coefficient values to use in the polynomial.\n",
    "    \"\"\"\n",
    "    \n",
    "    def f(t):\n",
    "        '''Returns a polynomial function w.r.t. time `t`.'''\n",
    "        total = 0.0\n",
    "        for i, c in enumerate(coefficients):\n",
    "            total += c * t ** i\n",
    "        return total\n",
    "    return f\n",
    "\n",
    "\n",
    "def differentiate(\n",
    "        coefficients: List[float]\n",
    ") -> List[float]:\n",
    "    \"\"\"Returns the coefficients of the derivative of the polynomial.\n",
    "    \n",
    "    :param coefficients: Set of coefficient values of the polynomial.\n",
    "    :returns: new_cos, Set of coefficients of the differentiated polynomial.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_cos = []\n",
    "    for deg, prev_co in enumerate(coefficients[1:]):\n",
    "        new_cos.append((deg + 1) * prev_co)\n",
    "    return new_cos\n",
    "\n",
    "\n",
    "def nearest_approach_to_any_vehicle(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        vehicles: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Returns the closest distance to any vehicle during the given trajectory.\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param vehicles: Dict of `Vehicle` instances to consider the distance to.\n",
    "    :returns: closest, Distance to the closest vehicle from this trajectory.\n",
    "    \"\"\"\n",
    "    \n",
    "    closest = sys.maxsize\n",
    "    for v in vehicles.values():\n",
    "        d = nearest_approach(traj, v)\n",
    "        if d < closest:\n",
    "            closest = d\n",
    "    return closest\n",
    "\n",
    "\n",
    "def nearest_approach(\n",
    "        traj: Tuple[List[float], List[float], float], \n",
    "        vehicle: Vehicle\n",
    ") -> float:\n",
    "    \"\"\"Returns the closest distance from ego to given vehicle during the trajectory.\n",
    "    \n",
    "    Here the distance to the `vehicle` from the ego is considered at all time-steps\n",
    "    in the trajectory. The closest distance from which the ego gets to the `vehicle`\n",
    "    is returned. \n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param vehicle: Single `Vehicle` to consider the distance to.\n",
    "    :returns: closest, Distance closest to the `vehicle` from this trajectory.\n",
    "    \"\"\"\n",
    "    \n",
    "    closest = sys.maxsize\n",
    "    s_,d_,T = traj\n",
    "    s = to_equation(s_)\n",
    "    d = to_equation(d_)\n",
    "    for i in range(100):\n",
    "        t = float(i) / 100 * T\n",
    "        cur_s = s(t)\n",
    "        cur_d = d(t)\n",
    "        targ_s, _, _, targ_d, _, _ = vehicle.state_in(t)\n",
    "        dist = sqrt((cur_s-targ_s)**2 + (cur_d-targ_d)**2)\n",
    "        if dist < closest:\n",
    "            closest = dist\n",
    "    return closest\n",
    "\n",
    "\n",
    "def show_trajectory(\n",
    "        s_coeffs: List[float],\n",
    "        d_coeffs: List[float], \n",
    "        T: float,\n",
    "        vehicle: Vehicle=None\n",
    "):\n",
    "    \"\"\"Displays the trajectory over time on a Matplotlib figure.\n",
    "    \n",
    "    :param s_coeffs: Coefficients of polynomial along the longitudinal distance axis.\n",
    "    :param d_coeffs: Coefficients of the polynomial along the lateral distance axis.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param vehicle: optional, Vehicle to render on the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = to_equation(s_coeffs)\n",
    "    d = to_equation(d_coeffs)\n",
    "    X = []\n",
    "    Y = []\n",
    "    if vehicle:\n",
    "        X2 = []\n",
    "        Y2 = []\n",
    "    t = 0\n",
    "    while t <= T + 0.01:\n",
    "        X.append(s(t))\n",
    "        Y.append(d(t))\n",
    "        if vehicle:\n",
    "            s_, _, _, d_, _, _ = vehicle.state_in(t)\n",
    "            X2.append(s_)\n",
    "            Y2.append(d_)\n",
    "        t += 0.25\n",
    "    plt.scatter(X, Y, color=\"blue\")\n",
    "    if vehicle:\n",
    "        plt.scatter(X2, Y2, color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def get_f_and_N_derivatives(\n",
    "        coeffs, \n",
    "        N=3\n",
    "):\n",
    "    \"\"\"Computes `N`th derivative of the polynomial formed by `coeffs`.\n",
    "    \n",
    "    :param coeffs: Coefficient values of the polynomial.\n",
    "    :param N: Number of times to differentiate the polynomial.\n",
    "    :returns: functions, coefficients of the polynomial for each differentiation step. \n",
    "    \"\"\"\n",
    "    \n",
    "    functions = [to_equation(coeffs)]\n",
    "    for i in range(N):\n",
    "        coeffs = differentiate(coeffs)\n",
    "        functions.append(to_equation(coeffs))\n",
    "    return functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8eaffe",
   "metadata": {},
   "source": [
    "#### Cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7586d",
   "metadata": {},
   "source": [
    "The following is a set of cost functions evaluating a variety of cases that arise during a typical highway driving scenario. Here we penalise trajectories which, for example, have at any point during their execution, a distance assumed to be within twice the radius of any neighbouring vehicles. On the other hand, we reward trajectories which, for example, have an average speed or elapsed time-to-goal that are close to their respective target values.\n",
    "\n",
    "Note that this is not a comprehensive list of all cost functions that should be considered in the real-world; here we neglect to consider scenarios such as merges, intersections, unexpected emergencies or road hazards, etc. We also omit the implementation of two of the provided cost functions — `stays_on_road_cost` and `exceeds speed limit_cost`, for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f234af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### From J. Moran's `cost_functions.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f8a9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the time-difference cost function.\n",
    "    \n",
    "    Penalises trajectories that span a duration which is longer or \n",
    "    shorter than the duration requested.\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Integer id of target vehicle state (not used).\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories. \n",
    "    :returns: Cost function evaluated for the given time-difference. \n",
    "    \"\"\"\n",
    "    \n",
    "    _, _, t = traj\n",
    "    return logistic(float(abs(t - T)) / T)\n",
    "\n",
    "\n",
    "def s_diff_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the longitudinal distance difference cost function.\n",
    "    \n",
    "    Penalises trajectories whose longitudinal distance, i.e., $s$-coordinate\n",
    "    and its derivatives, differ from the goal. \n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Cost function evaluated for the given longitudinal distance difference. \n",
    "    \"\"\"\n",
    "    \n",
    "    s, _, T = traj\n",
    "    target = predictions[target_vehicle].state_in(T)\n",
    "    target = list(np.array(target) + np.array(delta))\n",
    "    s_targ = target[:3]\n",
    "    S = [f(T) for f in get_f_and_N_derivatives(s, 2)]\n",
    "    cost = 0\n",
    "    for actual, expected, sigma in zip(S, s_targ, SIGMA_S):\n",
    "        diff = float(abs(actual - expected))\n",
    "        cost += logistic(diff / sigma)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def d_diff_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the lateral distance difference cost function.\n",
    "    \n",
    "    Penalises trajectories whose lateral distance, i.e., $d$-coordinate\n",
    "    and its derivatives, differ from the goal. \n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Cost function evaluated for the given lateral distance difference. \n",
    "    \"\"\"\n",
    "    \n",
    "    _, d_coeffs, T = traj\n",
    "    d_dot_coeffs = differentiate(d_coeffs)\n",
    "    d_ddot_coeffs = differentiate(d_dot_coeffs)\n",
    "    d = to_equation(d_coeffs)\n",
    "    d_dot = to_equation(d_dot_coeffs)\n",
    "    d_ddot = to_equation(d_ddot_coeffs)\n",
    "    D = [d(T), d_dot(T), d_ddot(T)]\n",
    "    target = predictions[target_vehicle].state_in(T)\n",
    "    target = list(np.array(target) + np.array(delta))\n",
    "    d_targ = target[3:]\n",
    "    cost = 0\n",
    "    for actual, expected, sigma in zip(D, d_targ, SIGMA_D):\n",
    "        diff = float(abs(actual - expected))\n",
    "        cost += logistic(diff / sigma)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def collision_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the collision cost function.\n",
    "    \n",
    "    Binary cost function which penalises an imminent collision.\n",
    "    Returns `1.0` if ego-vehicle is within distance less than twice\n",
    "    the radius of a neighbouring vehicle, otherwise `0.0`.\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Binary collision cost evaluated for the given trajectory.     \n",
    "    \"\"\"\n",
    "    \n",
    "    nearest = nearest_approach_to_any_vehicle(traj, predictions)\n",
    "    if nearest < 2 * VEHICLE_RADIUS:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "    \n",
    "def buffer_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the buffer cost function.\n",
    "    \n",
    "    Penalises trajectories which closely approach other vehicles.\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Binary collision cost evaluated for the given trajectory.     \n",
    "    \"\"\"\n",
    "    nearest = nearest_approach_to_any_vehicle(traj, predictions)\n",
    "    return logistic(2 * VEHICLE_RADIUS / nearest)\n",
    "\n",
    "\n",
    "def stays_on_road_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the road boundary cost function.\n",
    "    \n",
    "    NOTE: NOT YET IMPLEMENTED.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def exceeds_speed_limit_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the maximum speed cost function.\n",
    "    \n",
    "    NOTE: NOT YET IMPLEMENTED.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def efficiency_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the efficiency cost function.\n",
    "    \n",
    "    Rewards trajectories whose average speed closely matches target speed.\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Efficiency cost evaluated for the given trajectory.  \n",
    "    \"\"\"\n",
    "    \n",
    "    s, _, t = traj\n",
    "    s = to_equation(s)\n",
    "    avg_v = float(s(t)) / t\n",
    "    targ_s, _, _, _, _, _ = predictions[target_vehicle].state_in(t)\n",
    "    targ_v = float(targ_s) / t\n",
    "    return logistic(2 * float(targ_v - avg_v) / avg_v)\n",
    "\n",
    "\n",
    "def total_accel_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the total acceleration cost function.\n",
    "    \n",
    "    Penalises trajectories with acceleration above the expected\n",
    "    one-second acceleration value (`EXPECTED_ACC_IN_ONE_SEC`).\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Acceleration cost evaluated for the given trajectory. \n",
    "    \"\"\"\n",
    "    \n",
    "    s, d, t = traj\n",
    "    s_dot = differentiate(s)\n",
    "    s_d_dot = differentiate(s_dot)\n",
    "    a = to_equation(s_d_dot)\n",
    "    total_acc = 0\n",
    "    dt = float(T) / 100.0\n",
    "    for i in range(100):\n",
    "        t = dt * i\n",
    "        acc = a(t)\n",
    "        total_acc += abs(acc * dt)\n",
    "    acc_per_second = total_acc / T\n",
    "    return logistic(acc_per_second / EXPECTED_ACC_IN_ONE_SEC)\n",
    "\n",
    "\n",
    "def total_jerk_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evalautes the total jerk cost function.\n",
    "    \n",
    "    Penalises trajectories with jerk above the expected\n",
    "    one-second jerk value (`EXPECTED_JERK_IN_ONE_SEC`).\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Total jerk binary cost evaluated for the given trajectory. \n",
    "    \"\"\"\n",
    "    \n",
    "    s, d, t = traj\n",
    "    s_dot = differentiate(s)\n",
    "    s_d_dot = differentiate(s_dot)\n",
    "    jerk = to_equation(differentiate(s_d_dot))\n",
    "    total_jerk = 0\n",
    "    dt = float(T) / 100.0\n",
    "    for i in range(100):\n",
    "        t = dt * i\n",
    "        j = jerk(t)\n",
    "        total_jerk += abs(j * dt)\n",
    "    jerk_per_second = total_jerk / T\n",
    "    return logistic(jerk_per_second / EXPECTED_JERK_IN_ONE_SEC)\n",
    "\n",
    "\n",
    "def max_accel_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the maximum acceleration cost function.\n",
    "    \n",
    "    Binary cost penalising trajectories whose acceleration exceeds the\n",
    "    maximum allowed acceleration (`MAX_ACCEL`).\n",
    "    \n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Maximum accleration binary cost evaluated for the given trajectory. \n",
    "    \"\"\"\n",
    "    \n",
    "    s, d, t = traj\n",
    "    s_dot = differentiate(s)\n",
    "    s_d_dot = differentiate(s_dot)\n",
    "    a = to_equation(s_d_dot)\n",
    "    all_accs = [a(float(T) / 100 * i) for i in range(100)]\n",
    "    max_acc = max(all_accs, key=abs)\n",
    "    if abs(max_acc) > MAX_ACCEL:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def max_jerk_cost(\n",
    "        traj: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[float],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> float:\n",
    "    \"\"\"Evaluates the maximum jerk cost function.\n",
    "    \n",
    "    Binary cost penalising trajectories whose jerk exceeds the\n",
    "    maximum allowed jerk (`MAX_JERK`).\n",
    "\n",
    "    :param traj: Trajectory to evaluate.\n",
    "    :param target_vehicle: Target vehicle id from `predictions` to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param T: Total elapsed time (s) starting from $t = 0$.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Maximum jerk binary cost evaluated for the given trajectory. \n",
    "    \"\"\"\n",
    "    \n",
    "    s, d, t = traj\n",
    "    s_dot = differentiate(s)\n",
    "    s_d_dot = differentiate(s_dot)\n",
    "    jerk = differentiate(s_d_dot)\n",
    "    jerk = to_equation(jerk)\n",
    "    all_jerks = [jerk(float(T) / 100 * i) for i in range(100)]\n",
    "    max_jerk = max(all_jerks, key=abs)\n",
    "    if abs(max_jerk) > MAX_JERK:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240703d6",
   "metadata": {},
   "source": [
    "#### Cost function weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b08bba",
   "metadata": {},
   "source": [
    "Assigned below are the weight values multiplied to their respective returned cost function values for each given trajectory to consider. The weighted sum of the cost function returns will be calculated, and the trajectory whose total weighted sum is minimal will be selected for execution by the ego-vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "723e21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Adjust weights assigned to the existing cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c302f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTED_COST_FUNCTIONS = [\n",
    "    (time_diff_cost,    1),\n",
    "    (s_diff_cost,       1),\n",
    "    (d_diff_cost,       1),\n",
    "    (efficiency_cost,   1),\n",
    "    (max_jerk_cost,     1),\n",
    "    (total_jerk_cost,   1),\n",
    "    (collision_cost,    1),\n",
    "    (buffer_cost,       1),\n",
    "    (max_accel_cost,    1),\n",
    "    (total_accel_cost,  1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849dad1",
   "metadata": {},
   "source": [
    "#### Polynomial Trajectory Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b311273",
   "metadata": {},
   "source": [
    "Below we implement the Polynomial Trajectory Generator programme.\n",
    "\n",
    "The `PTG` function finds the best trajectory by computing the minimum weighted cost over all possible trajectory perturbations. Each trajectory from the start to goal state is described by a set of two quintic polynomials parameterised by the coefficients of the boundary conditions `start_s`, `start_d`. These starting kinematic state vectors are used along with the derived minimised-jerk trajectory equation to compute the trajectories in 1D with respect to the total elapsed time `T` to the goal state. \n",
    "\n",
    "Each quintic polynomial describes the motion of the ego-vehicle along either the longitudinal $s$-axis or lateral $d$-axis (using the [Frenet](https://fjp.at/posts/optimal-frenet/) coordinate frame). The trajectory, a tuple of\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\texttt{traj = (s_coefficients, d_coefficients, t)},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "describe the estimated jerk-minimum trajectory to the goal. The resulting quintic polynomials belonging to the trajectory are perturbed (deviated) using the [`random.gauss`](https://docs.python.org/3/library/random.html#random.gauss) floating-point number generator. Here we parameterise the Gaussian to sample from using the original coefficients of the quintic polynomials of either $s(t)$ or $d(t)$ as the `mean` parameter, and the `sigma` parameter is given as the pre-defined constant `SIGMA_S` or `SIGMA_D`, respectively.\n",
    "\n",
    "From these set of perturbed trajectories we select the cost-minimal to execute. In other words, we run each trajectory through the set of cost functions weighted by the values given in `WEIGHTED_COST_FUNCTIONS`, then return the single trajectory with the lowest weighted-sum cost score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1965ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from cost_functions import *\n",
    "#from constants import *\n",
    "\n",
    "\n",
    "def PTG(\n",
    "        start_s: List[float],\n",
    "        start_d: List[float],\n",
    "        target_vehicle: int,\n",
    "        delta: List[int],\n",
    "        T: float,\n",
    "        predictions: Vehicles\n",
    ") -> Tuple[List[float], List[float], float]:\n",
    "    \"\"\"Finds the best trajectory according to `WEIGHTED_COST_FUNCTIONS`.\n",
    "\n",
    "    :param start_s: Starting longitudinal motion state vector,\n",
    "        i.e., list of `[s, s_dot, s_ddot]` values.\n",
    "    :param start_d: Starting lateral motion state vector,\n",
    "        i.e., list of `[d, d_dot, d_ddot]` values.\n",
    "    :param target_vehicle: integer id of the leading vehicle which trajectories\n",
    "        are set relative to, used to retrieve the state from `predictions` dict.\n",
    "    :param delta: list of goal offset values between ego- and `target_vehicle`,\n",
    "        e.g., for `t=5`, we have `target_vehicle` at `[100, 10, 0, 0, 0, 0]` and\n",
    "        `delta` of `[-10, 0, 0, 4, 0, 0]`, then our goal state at `t=5` will be\n",
    "        `[90, 10, 0, 4, 0, 0]`. In other words, we describe the following goal:\n",
    "        \"follow 10 metres behind and 4 metres to the right of `target_vehicle`.\"\n",
    "    :param T: Total elapsed time at which the ego-vehicle will reach the goal,\n",
    "        relative to the current time-step assumed to be $t = 0$.\n",
    "    :param predictions: dict of `{v_id : vehicle}` instances. Each `Vehicle`\n",
    "        has method `vehicle.state_in(t)` which returns the expected kinematics,\n",
    "        i.e., `[s, s_dot, s_ddot, d, d_dot, d_ddot]`, at time `t`.\n",
    "    :returns: `(best_s, best_d, best_t)`, tuple of trajectory values s.t. `best_s`\n",
    "        and `best_d` are the quintic polynomial coefficient vectors of $s(t)$, $d(t)$,\n",
    "        respectively, and `best_t` is the elapsed time associated with the trajectory.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the target `Vehicle` state\n",
    "    target = predictions[target_vehicle]\n",
    "    # Generate alternative goal states\n",
    "    all_goals = []\n",
    "    timestep = 0.5\n",
    "    t = T - 4 * timestep\n",
    "    while t <= T + 4 * timestep:\n",
    "        target_state = np.array(target.state_in(t)) + np.array(delta)\n",
    "        goal_s = target_state[:3]\n",
    "        goal_d = target_state[3:]\n",
    "        goals = [(goal_s, goal_d, t)]\n",
    "        for _ in range(N_SAMPLES):\n",
    "            perturbed = perturb_goal(goal_s, goal_d)\n",
    "            goals.append((perturbed[0], perturbed[1], t))\n",
    "        all_goals += goals\n",
    "        t += timestep\n",
    "    # Find the best trajectory with minimised weighted cost\n",
    "    trajectories = []\n",
    "    for goal in all_goals:\n",
    "        s_goal, d_goal, t = goal\n",
    "        s_coefficients = JMT(start_s, s_goal, t)\n",
    "        d_coefficients = JMT(start_d, d_goal, t)\n",
    "        trajectories.append(tuple([s_coefficients, d_coefficients, t]))\n",
    "    best = min(\n",
    "        trajectories, \n",
    "        key=lambda tr: calculate_cost(\n",
    "            tr, target_vehicle, delta, T, predictions, WEIGHTED_COST_FUNCTIONS\n",
    "        )\n",
    "    )\n",
    "    # Compute the weighted cost of the best trajectory found\n",
    "    calculate_cost(\n",
    "        best, \n",
    "        target_vehicle, \n",
    "        delta, \n",
    "        T, \n",
    "        predictions, \n",
    "        WEIGHTED_COST_FUNCTIONS, \n",
    "        verbose=True\n",
    "    )\n",
    "    return best\n",
    "\n",
    "\n",
    "def calculate_cost(\n",
    "        trajectory: Tuple[List[float], List[float], float],\n",
    "        target_vehicle: int, \n",
    "        delta: List[float],\n",
    "        goal_t: float,\n",
    "        predictions: Vehicles,\n",
    "        cost_functions_with_weights: List[Union[\n",
    "            Callable[[Vehicle, int, float, float, Vehicles], float],\n",
    "            float\n",
    "        ]],\n",
    "        verbose=False\n",
    ") -> float:\n",
    "    \"\"\"Computes the weighted cost of the given cost functions.\n",
    "    \n",
    "    :param trajectory: Trajectory to compute the cost relative to.\n",
    "    :param target_vehicle: Target vehicle id to fetch the state of.\n",
    "    :param delta: List of offset values between ego- and `target_vehicle`.\n",
    "    :param goal_t: Total elapsed execution time (s) to complete the trajectory.\n",
    "    :param predictions: Dict of estimated vehicle trajectories.\n",
    "    :returns: Maximum jerk binary cost evaluated for the given trajectory. \n",
    "    \"\"\"\n",
    "    \n",
    "    cost = 0.0\n",
    "    for cf, weight in cost_functions_with_weights:\n",
    "        new_cost = weight * cf(trajectory, target_vehicle, delta, goal_t, predictions)\n",
    "        cost += new_cost\n",
    "        if verbose:\n",
    "            print(f\"cost for {cf.__name__} is \\t {new_cost}\")\n",
    "    return cost\n",
    "\n",
    "\n",
    "def perturb_goal(\n",
    "        goal_s: np.ndarray,\n",
    "        goal_d: np.ndarray\n",
    ") -> Tuple[List[float], List[float]]:\n",
    "    \"\"\"Returns a perturbed version of the goal state.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_s_goal = []\n",
    "    for mu, sig in zip(goal_s, SIGMA_S):\n",
    "        new_s_goal.append(random.gauss(mu, sig))\n",
    "    new_d_goal = []\n",
    "    for mu, sig in zip(goal_d, SIGMA_D):\n",
    "        new_d_goal.append(random.gauss(mu, sig))\n",
    "    return tuple([new_s_goal, new_d_goal])\n",
    "\n",
    "\n",
    "def JMT(\n",
    "        start: List[float],\n",
    "        end: List[float],\n",
    "        T: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Computes the jerk-minimising trajectory from the `start` to `end` states.\n",
    "    \n",
    "    :param start: Starting state vector to compute the trajectory from.\n",
    "    :param end: Final state vector to compute the trajectory to.\n",
    "    :param T: Total elapsed time to perform the trajectory relative to current $t = 0$.\n",
    "    :returns alphas: Set of coefficients $\\alpha_{0}$ through $\\alpha_{5}$ belonging to\n",
    "        the quintic polynomial of the minimised-jerk trajectory. \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Get the first three known coefficients\n",
    "    a_0, a_1, a_2 = start[0], start[1], start[2] / 2.0\n",
    "    ### Compute the integration constants\n",
    "    c_0 = a_0 + a_1 * T + a_2 * T**2\n",
    "    c_1 = a_1 + 2* a_2 * T\n",
    "    c_2 = 2 * a_2\n",
    "    ### Form the matrix equation\n",
    "    A = np.array([\n",
    "        [T**3, T**4, T**5],\n",
    "        [3 * T**2, 4 * T**3, 5 * T**4],\n",
    "        [6 * T, 12 * T**2, 20 * T**3],\n",
    "    ])\n",
    "    B = np.array([\n",
    "        end[0] - c_0,\n",
    "        end[1] - c_1,\n",
    "        end[2] - c_2\n",
    "    ])\n",
    "    ### Solve the matrix equation\n",
    "    a_3_4_5 = np.linalg.solve(A, B)\n",
    "    ### Append the last three computed coefficients to the first three knowns\n",
    "    alphas = np.concatenate([\n",
    "        np.array([a_0, a_1, a_2]), \n",
    "        a_3_4_5\n",
    "    ])\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29831fc4",
   "metadata": {},
   "source": [
    "#### Evaluating the Polynomial Trajectory Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c523baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_PTG(\n",
    "    start_s: List[float],\n",
    "    start_d: List[float],\n",
    "    target_vehicle: int,\n",
    "    delta: List[float],\n",
    "    T: float, \n",
    "    predictions: Vehicles\n",
    "):\n",
    "    \"\"\"Evaluates the Polynomial Trajectory Generator programme.\n",
    "    \n",
    "    :param start_s: Starting longitudinal motion state vector,\n",
    "        i.e., list of `[s, s_dot, s_ddot]` values.\n",
    "    :param start_d: Starting lateral motion state vector,\n",
    "        i.e., list of `[d, d_dot, d_ddot]` values.\n",
    "    :param target_vehicle: integer id of the leading vehicle which trajectories\n",
    "        are set relative to, used to retrieve the state from `predictions` dict.\n",
    "    :param delta: list of goal offset values between ego- and `target_vehicle`,\n",
    "        e.g., for `t=5`, we have `target_vehicle` at `[100, 10, 0, 0, 0, 0]` and\n",
    "        `delta` of `[-10, 0, 0, 4, 0, 0]`, then our goal state at `t=5` will be\n",
    "        `[90, 10, 0, 4, 0, 0]`. In other words, we describe the following goal:\n",
    "        \"follow 10 metres behind and 4 metres to the right of `target_vehicle`.\"\n",
    "    :param T: Total elapsed time at which the ego-vehicle will reach the goal,\n",
    "        relative to the current time-step assumed to be $t = 0$.\n",
    "    :param predictions: dict of `{v_id : vehicle}` instances. Each `Vehicle`\n",
    "        has method `vehicle.state_in(t)` which returns the expected kinematics,\n",
    "        i.e., `[s, s_dot, s_ddot, d, d_dot, d_ddot]`, at time `t`.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Compute the best (cost-minimal) trajectory\n",
    "    best = PTG(\n",
    "        start_s, \n",
    "        start_d, \n",
    "        target_vehicle, \n",
    "        delta, \n",
    "        T, \n",
    "        predictions\n",
    "    )\n",
    "    ### Display the best trajectory in a Matplotlib figure\n",
    "    show_trajectory(best[0], best[1], best[2], vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61da8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial 1D kinematics state vectors in Frenet coordinate frame\n",
    "# Boundary conditions along the longitudinal $s$-axis\n",
    "# i.e., $[s, \\dot{s}, \\ddot{s}]$\n",
    "start_s = [10, 10, 0]\n",
    "# Boundary conditions along the lateral $d$-axis\n",
    "# i.e., $[d, \\dot{d}, \\ddot{d}]$\n",
    "start_d = [4, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "546d326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Non-ego vehicle instance (with initial boundary conditions)\n",
    "vehicle = Vehicle([0, 10, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ec9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set of non-ego vehicle actors \n",
    "target = 0                          # id of the non-ego actor in `predictions`\n",
    "predictions = {target: vehicle}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89674806",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting state variables\n",
    "# List of offset values between ego- and `target_vehicle`\n",
    "delta = [0, 0, 0, 0, 0 ,0]\n",
    "# Elapsed time to complete manoeuvre\n",
    "T = 5.0                    # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7b50d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run the Polynomial Trajectory Generator programme with starting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17a42768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_PTG(\n",
    "    start_s,\n",
    "    start_d,\n",
    "    target,\n",
    "    delta,\n",
    "    T,\n",
    "    predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d89c8",
   "metadata": {},
   "source": [
    "In the above experiment run we see that the ego-vehicle (blue) fails to properly execute the intended manoeuvre; rather than wait and move _behind_ the other vehicle (shown in red), the ego-vehicle executes a trajectory that lands it a position directly in front of the traffic.\n",
    "\n",
    "In order to correct this manoeuvre, we will weight the cost functions appropriately such that the trajectory perturbation with best time-to-goal and expected-distance is prioritised. That way, we can better guarantee that our ego-vehicle completes the desired trajectory in the given amount of time `T` which is selected such that the other vehicle (in red) is likely to have already passed in front of the ego-vehicle.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
